# 配置管理

<cite>
**本文档引用的文件**
- [config.py](file://ai_correction/config.py)
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md)
- [local_runner.py](file://ai_correction/local_runner.py)
- [main.py](file://ai_correction/main.py)
- [llm_client.py](file://ai_correction/functions/llm_client.py)
- [init_database.py](file://ai_correction/init_database.py)
</cite>

## 目录
1. [概述](#概述)
2. [配置文件层次结构](#配置文件层次结构)
3. [核心配置参数](#核心配置参数)
4. [LLM提供商配置](#llm提供商配置)
5. [数据库配置](#数据库配置)
6. [运行环境配置](#运行环境配置)
7. [性能配置](#性能配置)
8. [缓存配置](#缓存配置)
9. [日志配置](#日志配置)
10. [部署环境配置示例](#部署环境配置示例)
11. [配置验证](#配置验证)
12. [安全最佳实践](#安全最佳实践)
13. [故障排除指南](#故障排除指南)

## 概述

AI智能批改系统采用灵活的环境变量配置机制，支持本地开发、测试和生产部署等多种场景。系统通过分层配置文件管理和默认值机制，确保配置的灵活性和安全性。

### 配置管理特点

- **分层配置**：支持多个配置文件按优先级加载
- **环境隔离**：不同环境使用独立配置
- **默认值机制**：提供合理的默认配置
- **类型安全**：自动类型转换和验证
- **环境变量优先**：支持运行时动态配置

## 配置文件层次结构

系统按照优先级从高到低支持以下配置文件：

```mermaid
flowchart TD
A[".env.local<br/>本地开发配置"] --> B[".env.development<br/>开发环境配置"]
B --> C[".env.test<br/>测试环境配置"]
C --> D[".env.production<br/>生产环境配置"]
D --> E[".env<br/>默认配置模板"]
F["环境变量覆盖"] --> G["运行时配置"]
A -.-> F
B -.-> F
C -.-> F
D -.-> F
E -.-> F
```

**图表来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L10-L15)

### 配置文件说明

| 文件名 | 用途 | 是否提交到Git | 优先级 |
|--------|------|---------------|--------|
| `.env.local` | 本地开发专用配置 | ❌ | 最高 |
| `.env.development` | 开发环境配置 | ❌ | 高 |
| `.env.test` | 测试环境配置 | ❌ | 中 |
| `.env.production` | 生产环境配置 | ❌ | 低 |
| `.env` | 默认配置模板 | ✅ | 最低 |

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L10-L15)

## 核心配置参数

### 基础配置

| 参数名 | 类型 | 默认值 | 描述 | 取值范围 |
|--------|------|--------|------|----------|
| `BASE_DIR` | Path | 当前目录 | 项目根目录 | 任意有效路径 |
| `UPLOAD_DIR` | Path | `uploads` | 文件上传目录 | 任意有效路径 |
| `MAX_FILE_SIZE` | int | `10485760` (10MB) | 最大文件大小 | 1KB - 1GB |
| `ALLOWED_EXTENSIONS` | list | `['.txt', '.md', '.json', '.csv']` | 允许的文件扩展名 | 有效的文件扩展名列表 |

### 应用程序配置

| 参数名 | 类型 | 默认值 | 描述 | 取值范围 |
|--------|------|--------|------|----------|
| `STREAMLIT_PORT` | int | `8501` | Streamlit应用端口 | 1024-65535 |
| `STREAMLIT_HOST` | str | `'0.0.0.0'` | Streamlit监听地址 | IP地址或域名 |
| `LOG_LEVEL` | str | `'INFO'` | 日志级别 | DEBUG, INFO, WARNING, ERROR |
| `LOG_FILE` | Path | `logs/app.log` | 日志文件路径 | 有效文件路径 |

**章节来源**
- [config.py](file://ai_correction/config.py#L10-L82)

## LLM提供商配置

系统支持三种主要的LLM提供商，每种都有独立的配置选项。

### LLM提供商选择

```mermaid
flowchart LR
A["LLM_PROVIDER"] --> B["OpenRouter"]
A --> C["OpenAI"]
A --> D["Gemini"]
B --> E["OPENROUTER_API_KEY<br/>OPENROUTER_MODEL"]
C --> F["OPENAI_API_KEY<br/>OPENAI_MODEL"]
D --> G["GEMINI_API_KEY<br/>GEMINI_MODEL"]
H["通用配置"] --> I["LLM_API_KEY<br/>LLM_MODEL"]
I --> B
I --> C
I --> D
```

**图表来源**
- [config.py](file://ai_correction/config.py#L31-L46)
- [llm_client.py](file://ai_correction/functions/llm_client.py#L25-L45)

### OpenRouter配置

| 参数名 | 类型 | 默认值 | 描述 | 必需 |
|--------|------|--------|------|------|
| `LLM_PROVIDER` | str | `'openrouter'` | LLM提供商 | 是 |
| `LLM_API_KEY` | str | `''` | 通用API密钥 | 否 |
| `OPENROUTER_API_KEY` | str | `LLM_API_KEY` | OpenRouter API密钥 | 是 |
| `OPENROUTER_MODEL` | str | `'google/gemini-2.5-flash-lite'` | 默认模型 | 否 |
| `OPENROUTER_BASE_URL` | str | `'https://openrouter.ai/api/v1'` | API基础URL | 否 |

### OpenAI配置

| 参数名 | 类型 | 默认值 | 描述 | 必需 |
|--------|------|--------|------|------|
| `OPENAI_API_KEY` | str | `LLM_API_KEY` | OpenAI API密钥 | 是 |
| `OPENAI_MODEL` | str | `'gpt-4'` | 默认模型 | 否 |
| `OPENAI_API_BASE` | str | `'https://api.openai.com/v1'` | API基础URL | 否 |

### Gemini配置

| 参数名 | 类型 | 默认值 | 描述 | 必需 |
|--------|------|--------|------|------|
| `GEMINI_API_KEY` | str | `LLM_API_KEY` | Gemini API密钥 | 否 |
| `GEMINI_MODEL` | str | `'gemini-2.0-flash-exp'` | 默认模型 | 否 |

### 模型选择指南

| 场景 | 推荐模型 | 性能特点 | 适用条件 |
|------|----------|----------|----------|
| 快速批改 | `google/gemini-2.5-flash-lite` | 速度快，成本低 | 对准确性要求不高 |
| 专业批改 | `gpt-4` | 准确性强，理解深入 | 对质量要求高 |
| 多模态处理 | `gemini-2.0-flash-exp` | 支持图像理解 | 包含图片的作业 |

**章节来源**
- [config.py](file://ai_correction/config.py#L31-L46)
- [llm_client.py](file://ai_correction/functions/llm_client.py#L25-L45)

## 数据库配置

系统支持多种数据库类型，具有智能默认配置机制。

### 数据库类型支持

```mermaid
flowchart TD
A["DATABASE_TYPE"] --> B["postgresql"]
A --> C["mysql"]
A --> D["json"]
B --> E["DATABASE_URL<br/>PGDATABASE"]
C --> F["DATABASE_URL<br/>MYSQL_URL"]
D --> G["JSON文件存储"]
H["通用配置"] --> I["DATABASE_URL"]
I --> B
I --> C
I --> D
```

**图表来源**
- [config.py](file://ai_correction/config.py#L13-L28)

### 数据库配置参数

| 参数名 | 类型 | 默认值 | 描述 | 示例 |
|--------|------|--------|------|------|
| `DATABASE_TYPE` | str | `'json'` | 数据库类型 | `postgresql`, `mysql`, `json` |
| `DATABASE_URL` | str | `''` | 数据库连接字符串 | 根据类型自动生成 |
| `PGDATABASE` | str | `'postgresql://postgres:password@localhost:5432/ai_correction'` | PostgreSQL默认配置 | 仅在未设置DATABASE_URL时使用 |
| `MYSQL_URL` | str | `'mysql://root:password@localhost:3306/ai_correction'` | MySQL默认配置 | 仅在未设置DATABASE_URL时使用 |

### 数据库配置示例

#### 本地开发（SQLite）
```bash
DATABASE_URL=sqlite:///ai_correction.db
```

#### 生产环境（PostgreSQL）
```bash
DATABASE_URL=postgresql://user:password@host:5432/dbname
```

#### Railway平台
```bash
DATABASE_URL=postgresql://user:pass@railway.app:5432/railway
```

**章节来源**
- [config.py](file://ai_correction/config.py#L13-L28)

## 运行环境配置

### 环境标识

| 环境 | `ENVIRONMENT` | 影响 | MemorySaver | 日志级别 | 优化级别 |
|------|---------------|------|-------------|----------|----------|
| 本地开发 | `development` | 详细调试信息 | ✅ | DEBUG | 无 |
| 测试环境 | `test` | 模拟外部调用 | ❌ | DEBUG | 模拟模式 |
| 生产环境 | `production` | 性能优化 | ❌ | WARNING | 最优 |

### 批改模式配置

| 模式 | `DEFAULT_MODE` | Token优化 | 详细程度 | 适用场景 |
|------|----------------|-----------|----------|----------|
| 高效模式 | `efficient` | 节省66% | 基础反馈 | 大批量处理 |
| 专业模式 | `professional` | 标准 | 详细分析 | 质量要求高的批改 |

### 批次处理配置

| 参数名 | 默认值 | 描述 | 计算公式 |
|--------|--------|------|----------|
| `EFFICIENT_MODE_THRESHOLD` | `6000` | 高效模式token上限 | `batch_size = threshold / 500` |
| `PROFESSIONAL_MODE_THRESHOLD` | `4000` | 专业模式token上限 | `batch_size = threshold / 1500` |
| `MAX_PARALLEL_WORKERS` | `4` | 最大并行worker数量 | 根据硬件配置调整 |

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L50-L85)

## 性能配置

### 超时和重试配置

| 参数名 | 默认值 | 描述 | 优化建议 |
|--------|--------|------|----------|
| `MAX_RETRIES` | `3` | API调用最大重试次数 | 生产环境：5-10次 |
| `REQUEST_TIMEOUT` | `30` | 请求超时时间（秒） | 生产环境：60秒 |
| `CHECKPOINT_INTERVAL` | `60` | Checkpoint保存间隔（秒） | 大任务：120秒 |

### 并行处理优化

```mermaid
flowchart TD
A["MAX_PARALLEL_WORKERS"] --> B["CPU核心数"]
A --> C["内存容量"]
A --> D["网络带宽"]
B --> E["本地开发: 2-4"]
C --> F["生产环境: 4-8"]
D --> G["大规模批改: 8-16"]
```

**图表来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L160-L180)

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L160-L190)

## 缓存配置

### 缓存系统配置

| 参数名 | 默认值 | 类型 | 描述 |
|--------|--------|------|------|
| `ENABLE_CACHE` | `'true'` | bool | 是否启用缓存 |
| `CACHE_TTL` | `3600` | int | 缓存生存时间（秒） |

### 缓存配置示例

```bash
# 启用缓存（默认）
ENABLE_CACHE=true
CACHE_TTL=3600  # 1小时

# 禁用缓存
ENABLE_CACHE=false

# 短期缓存（适用于频繁变化的数据）
CACHE_TTL=300  # 5分钟

# 长期缓存（适用于静态数据）
CACHE_TTL=86400  # 24小时
```

**章节来源**
- [config.py](file://ai_correction/config.py#L60-L62)

## 日志配置

### 日志级别配置

| 级别 | 数值 | 描述 | 使用场景 |
|------|------|------|----------|
| `DEBUG` | 10 | 详细调试信息 | 开发调试 |
| `INFO` | 20 | 关键步骤记录 | 日常监控 |
| `WARNING` | 30 | 警告信息 | 注意潜在问题 |
| `ERROR` | 40 | 错误信息 | 故障排查 |

### 日志配置参数

| 参数名 | 默认值 | 描述 |
|--------|--------|------|
| `LOG_LEVEL` | `'INFO'` | 日志级别 |
| `LOG_FILE` | `logs/app.log` | 日志文件路径 |

### 日志文件结构

```
logs/
├── ai_correction.log      # 主应用日志
├── local_run.log          # 本地运行日志
└── test.log               # 测试环境日志
```

**章节来源**
- [config.py](file://ai_correction/config.py#L64-L67)

## 部署环境配置示例

### 本地开发环境 (.env.local)

```bash
# 数据库配置
DATABASE_URL=sqlite:///ai_correction.db

# LLM配置
OPENAI_API_KEY=sk-your-key-here
OPENAI_API_BASE=https://api.openai.com/v1

# 运行环境
ENVIRONMENT=development
DEFAULT_MODE=professional

# 批次处理
EFFICIENT_MODE_THRESHOLD=6000
PROFESSIONAL_MODE_THRESHOLD=4000
MAX_PARALLEL_WORKERS=4

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=logs/ai_correction.log

# 其他配置
MAX_RETRIES=3
REQUEST_TIMEOUT=30
PUSH_ENABLED=false
```

### 测试环境 (.env.test)

```bash
# 数据库配置
DATABASE_URL=sqlite:///test_ai_correction.db

# LLM配置（使用模拟）
OPENAI_API_KEY=test-key
USE_MOCK_LLM=true

# 运行环境
ENVIRONMENT=test
DEFAULT_MODE=efficient

# 批次处理
EFFICIENT_MODE_THRESHOLD=6000
PROFESSIONAL_MODE_THRESHOLD=4000
MAX_PARALLEL_WORKERS=2

# 日志配置
LOG_LEVEL=DEBUG
LOG_FILE=logs/test.log

# 性能配置
MAX_RETRIES=1
REQUEST_TIMEOUT=10
PUSH_ENABLED=false
```

### 生产环境 (.env.production)

```bash
# 数据库配置
DATABASE_URL=postgresql://user:pass@railway.app:5432/railway

# LLM配置
OPENAI_API_KEY=${OPENAI_API_KEY}
OPENAI_API_BASE=https://api.openai.com/v1

# 运行环境
ENVIRONMENT=production
DEFAULT_MODE=professional

# 批次处理
EFFICIENT_MODE_THRESHOLD=8000
PROFESSIONAL_MODE_THRESHOLD=5000
MAX_PARALLEL_WORKERS=8

# 日志配置
LOG_LEVEL=WARNING
LOG_FILE=/var/log/ai_correction.log

# 班级系统集成
CLASS_SYSTEM_API_URL=https://class.example.com/api
CLASS_SYSTEM_API_KEY=${CLASS_API_KEY}
PUSH_ENABLED=true

# 性能优化
MAX_RETRIES=5
REQUEST_TIMEOUT=60
CHECKPOINT_INTERVAL=120
```

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L190-L320)

## 配置验证

### 自动验证工具

系统提供了专门的本地运行器来验证配置：

```bash
# 使用local_runner.py验证配置
python local_runner.py
```

验证内容包括：
- ✅ 必需依赖包检查
- ✅ 环境变量设置验证
- ✅ API密钥有效性检查
- ✅ 数据库连接测试

### 手动验证方法

#### 数据库连接验证

```python
from functions.database.models import check_database_connection

if check_database_connection():
    print("✅ 数据库连接正常")
else:
    print("❌ 数据库连接失败")
```

#### OpenAI API验证

```python
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

try:
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "test"}],
        max_tokens=5
    )
    print("✅ OpenAI API连接正常")
except Exception as e:
    print(f"❌ OpenAI API连接失败: {e}")
```

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L292-L320)
- [local_runner.py](file://ai_correction/local_runner.py#L20-L37)

## 安全最佳实践

### API密钥安全管理

#### 1. 环境变量使用
```bash
# 不要硬编码API密钥
OPENAI_API_KEY=${OPENAI_API_KEY}  # 使用环境变量引用
```

#### 2. Git忽略配置
```gitignore
# .gitignore
.env.local
.env.production
.env.*
```

#### 3. 密钥管理服务
- **AWS Secrets Manager**
- **Azure Key Vault**
- **GCP Secret Manager**

### 数据库安全配置

#### PostgreSQL安全设置
```bash
# 强密码策略
DATABASE_URL=postgresql://user:StrongPass123!@host:5432/dbname

# SSL连接
DATABASE_URL=postgresql://user:pass@host:5432/dbname?sslmode=require
```

#### 访问控制
```bash
# 限制数据库访问IP
# 在数据库服务器上配置防火墙规则
```

### 日志安全

#### 敏感信息过滤
```bash
# 不要在日志中记录敏感信息
LOG_LEVEL=WARNING  # 生产环境避免DEBUG级别
```

#### 日志文件权限
```bash
# 设置适当的文件权限
chmod 600 logs/app.log
chown www-data:www-data logs/app.log
```

### 网络安全

#### HTTPS配置
```bash
# 生产环境必须使用HTTPS
# 在Web服务器上配置SSL证书
```

#### CORS策略
```bash
# 限制跨域访问
# 在Streamlit配置中设置CORS
```

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L340-L380)

## 故障排除指南

### 常见配置问题

#### Q1: 如何切换不同环境？

**方法1**: 使用配置文件
```bash
# 复制对应环境配置
cp .env.production .env
```

**方法2**: 在代码中指定
```python
from dotenv import load_dotenv
load_dotenv('.env.production')
```

**方法3**: 设置环境变量
```bash
export ENVIRONMENT=production
```

#### Q2: 本地开发需要PostgreSQL吗？

**不需要**。本地开发推荐使用SQLite：
```bash
DATABASE_URL=sqlite:///ai_correction.db
```

#### Q3: 批改速度慢怎么办？

```bash
# 优化配置
MAX_PARALLEL_WORKERS=8
DEFAULT_MODE=efficient
EFFICIENT_MODE_THRESHOLD=10000
```

#### Q4: 如何启用调试日志？

```bash
LOG_LEVEL=DEBUG
```

查看详细日志：
```bash
tail -f logs/ai_correction.log
```

### 性能优化建议

#### 1. 批次处理优化
```bash
# 根据硬件配置调整
MAX_PARALLEL_WORKERS=4  # CPU核心数
EFFICIENT_MODE_THRESHOLD=8000  # 根据可用内存调整
```

#### 2. 缓存优化
```bash
# 启用缓存
ENABLE_CACHE=true
CACHE_TTL=3600

# 针对不同场景调整TTL
CACHE_TTL=300  # 频繁变化的数据
CACHE_TTL=86400  # 静态数据
```

#### 3. 数据库优化
```bash
# 生产环境使用PostgreSQL
DATABASE_TYPE=postgresql
DATABASE_URL=postgresql://user:pass@host:5432/dbname

# 启用连接池
# 在数据库配置中设置连接池参数
```

### 监控和维护

#### 日志监控
```bash
# 实时监控日志
tail -f logs/ai_correction.log

# 搜索错误信息
grep "ERROR" logs/ai_correction.log
```

#### 性能监控
```bash
# 监控系统资源使用
htop
iotop
```

#### 定期维护
```bash
# 清理旧日志
find logs/ -name "*.log" -mtime +7 -delete

# 优化数据库
# 根据数据库类型执行相应的优化命令
```

**章节来源**
- [ENVIRONMENT_VARIABLES.md](file://ai_correction/docs/ENVIRONMENT_VARIABLES.md#L320-L370)

## 总结

AI智能批改系统的配置管理采用了分层、灵活的设计理念，通过环境变量和配置文件的组合，实现了不同部署环境的无缝切换。系统提供了完善的默认配置机制，同时支持精细化的定制需求。

### 关键要点

1. **分层配置**：通过配置文件层次结构实现环境隔离
2. **LLM灵活性**：支持多种提供商，可根据需求切换
3. **性能优化**：提供丰富的性能调优参数
4. **安全考虑**：内置安全最佳实践指导
5. **验证机制**：提供完整的配置验证工具

### 部署建议

- **本地开发**：使用SQLite数据库，启用详细日志
- **测试环境**：模拟外部服务，使用测试数据
- **生产环境**：使用PostgreSQL，优化性能参数

通过遵循本文档的配置指南和最佳实践，可以确保系统在各种部署环境中稳定、高效地运行。