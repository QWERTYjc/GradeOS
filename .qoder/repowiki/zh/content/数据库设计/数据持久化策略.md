# 数据持久化策略

<cite>
**本文档引用的文件**
- [init_database.py](file://ai_correction/init_database.py)
- [migration.py](file://ai_correction/functions/database/migration.py)
- [config.py](file://ai_correction/config.py)
- [models.py](file://ai_correction/functions/database/models.py)
- [db_manager.py](file://ai_correction/functions/database/db_manager.py)
- [redis_cache_session.md](file://ai_correction/docs/redis_cache_session.md)
- [user_data.json](file://ai_correction/user_data.json)
</cite>

## 目录
1. [概述](#概述)
2. [数据库初始化策略](#数据库初始化策略)
3. [数据库迁移管理](#数据库迁移管理)
4. [会话缓存策略](#会话缓存策略)
5. [持久化方案对比](#持久化方案对比)
6. [生产环境最佳实践](#生产环境最佳实践)
7. [故障排除指南](#故障排除指南)
8. [总结](#总结)

## 概述

AI批改系统采用多层次的数据持久化策略，支持多种存储方案以适应不同的使用场景和性能需求。系统提供了灵活的配置选项，允许在关系型数据库、JSON文件存储和Redis缓存之间进行选择和切换。

### 核心设计理念

- **灵活性**：支持多种存储后端，适应不同部署环境
- **可扩展性**：基于Alembic的数据库迁移机制确保数据结构演进
- **高性能**：结合Redis缓存提升频繁访问数据的读取性能
- **可靠性**：提供完整的备份和恢复机制

## 数据库初始化策略

### 初始化脚本架构

系统通过`init_database.py`提供统一的数据库初始化入口，支持自动检测和配置不同的存储后端。

```mermaid
flowchart TD
Start([启动初始化]) --> CheckType{检查DATABASE_TYPE}
CheckType --> |json| JSONInit[JSON文件初始化]
CheckType --> |postgresql/mysql| SQLInit[SQL数据库初始化]
SQLInit --> CreateEngine[创建数据库引擎]
CreateEngine --> CreateTable[创建表结构]
CreateTable --> ShowTables[显示创建的表]
JSONInit --> CreateDir[创建data目录]
CreateDir --> Complete[初始化完成]
ShowTables --> TestDB[测试数据库连接]
TestDB --> Complete
Complete --> End([结束])
```

**图表来源**
- [init_database.py](file://ai_correction/init_database.py#L15-L50)

### 配置驱动的初始化

系统通过配置文件中的`DATABASE_TYPE`和`DATABASE_URL`参数自动选择合适的初始化策略：

| 配置值 | 存储类型 | 特点 | 适用场景 |
|--------|----------|------|----------|
| `json` | JSON文件存储 | 本地文件，无需数据库服务 | 开发测试、小型部署 |
| `postgresql` | PostgreSQL数据库 | 关系型数据库，事务支持 | 生产环境、高并发 |
| `mysql` | MySQL数据库 | 关系型数据库，广泛兼容 | 传统企业环境 |

**章节来源**
- [init_database.py](file://ai_correction/init_database.py#L15-L30)
- [config.py](file://ai_correction/config.py#L10-L25)

### 数据库表结构设计

系统采用声明式ORM模型定义完整的数据结构：

```mermaid
erDiagram
STUDENT {
integer id PK
string student_id UK
string name
string class_id
string class_name
string email
string phone
json extra_metadata
datetime created_at
datetime updated_at
}
GRADING_TASK {
integer id PK
string student_id FK
string subject
integer total_questions
string status
datetime created_at
datetime completed_at
}
GRADING_RESULT {
integer id PK
integer task_id FK
integer question_id
float score
float max_score
text feedback
string strategy
datetime created_at
}
ASSIGNMENT {
integer id PK
string assignment_id UK
string class_id FK
string teacher_id
string subject
string title
text description
string rubric_id
text rubric_text
json rubric_struct
integer total_questions
float max_score
string mode
datetime deadline
datetime created_at
datetime updated_at
}
CLASS {
integer id PK
string class_id UK
string class_name
string teacher_id
string subject
integer student_count
datetime created_at
datetime updated_at
}
ASSIGNMENT_SUBMISSION {
integer id PK
string submission_id UK
string assignment_id FK
string student_id FK
string task_id
json answer_files
datetime submitted_at
string grading_status
string grading_mode
float total_score
float max_score
float percentage
string grade_level
json student_evaluation
json evaluations
json annotations
json export_payload
string push_status
datetime push_timestamp
json mm_tokens
json questions
json batches
json errors
datetime created_at
datetime updated_at
}
STUDENT ||--o{ GRADING_TASK : "has"
GRADING_TASK ||--o{ GRADING_RESULT : "generates"
GRADING_TASK ||--|| GRADING_STATISTICS : "has"
GRADING_TASK ||--o{ ERROR_ANALYSIS : "analyzes"
CLASS ||--o{ ASSIGNMENT : "hosts"
ASSIGNMENT ||--o{ ASSIGNMENT_SUBMISSION : "receives"
STUDENT ||--o{ ASSIGNMENT_SUBMISSION : "submits"
```

**图表来源**
- [models.py](file://ai_correction/functions/database/models.py#L15-L260)

**章节来源**
- [models.py](file://ai_correction/functions/database/models.py#L15-L260)
- [db_manager.py](file://ai_correction/functions/database/db_manager.py#L15-L50)

## 数据库迁移管理

### Alembic集成架构

系统采用Alembic作为数据库版本控制工具，提供完整的迁移生命周期管理：

```mermaid
classDiagram
class DatabaseMigrationManager {
+string database_url
+Path alembic_ini_path
+Path migrations_dir
+init_alembic() void
+create_migration(message) void
+upgrade(revision) void
+downgrade(revision) void
+current() void
+history() void
+create_all_tables() void
+drop_all_tables() void
-_get_config() Config
}
class MigrationCommands {
<<enumeration>>
INIT
CREATE
UPGRADE
DOWNGRADE
CURRENT
HISTORY
CREATE_TABLES
}
DatabaseMigrationManager --> MigrationCommands : "executes"
```

**图表来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L25-L150)

### 迁移命令详解

| 命令 | 功能 | 使用场景 | 示例 |
|------|------|----------|------|
| `init` | 初始化Alembic配置 | 首次部署或重置迁移环境 | `python migration.py init` |
| `create` | 创建自动迁移脚本 | 数据库结构变更后 | `python migration.py create -m "添加新字段"` |
| `upgrade` | 升级到最新版本 | 部署新版本时 | `python migration.py upgrade` |
| `downgrade` | 降级到指定版本 | 回滚到上一个稳定版本 | `python migration.py downgrade -r -1` |
| `current` | 显示当前版本 | 检查迁移状态 | `python migration.py current` |
| `history` | 显示迁移历史 | 审计和调试 | `python migration.py history` |
| `create_tables` | 直接创建表 | 开发环境快速初始化 | `python migration.py create_tables` |

### 迁移最佳实践

#### 生产环境迁移流程

```mermaid
sequenceDiagram
participant Dev as 开发者
participant Local as 本地环境
participant Staging as 预发布环境
participant Prod as 生产环境
Dev->>Local : 1. 开发新功能
Dev->>Local : 2. 测试迁移脚本
Dev->>Staging : 3. 部署到预发布环境
Staging->>Staging : 4. 执行迁移测试
Dev->>Prod : 5. 执行生产环境迁移
Prod->>Dev : 6. 验证迁移结果
Note over Dev,Prod : 生产环境必须使用迁移而非create_all_tables
```

**图表来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L150-L180)

#### 迁移脚本生成策略

系统支持自动化的迁移脚本生成，基于模型变更自动生成DDL语句：

```mermaid
flowchart TD
ModelChange[模型变更] --> AutoGen[自动检测变更]
AutoGen --> GenScript[生成迁移脚本]
GenScript --> Review[人工审查]
Review --> ManualEdit[手动编辑]
ManualEdit --> TestMigration[测试迁移]
TestMigration --> Deploy[部署迁移]
AutoGen --> Warning[警告：自动脚本可能不完美]
Warning --> ManualEdit
```

**图表来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L62-L85)

**章节来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L25-L247)

## 会话缓存策略

### Redis缓存架构

系统采用Redis作为主要的缓存和会话存储解决方案，提供高性能的数据访问和分布式支持：

```mermaid
graph TB
subgraph "应用层"
App[应用程序]
CacheMgr[缓存管理器]
SessionMgr[会话管理器]
end
subgraph "缓存层"
Redis[(Redis服务器)]
CacheKeys[缓存键空间]
SessionKeys[会话键空间]
end
subgraph "数据层"
UserData[用户数据]
ClassData[班级数据]
AssignmentData[作业数据]
GradingResults[批改结果]
end
App --> CacheMgr
App --> SessionMgr
CacheMgr --> Redis
SessionMgr --> Redis
Redis --> CacheKeys
Redis --> SessionKeys
CacheKeys --> UserData
CacheKeys --> ClassData
CacheKeys --> AssignmentData
CacheKeys --> GradingResults
```

**图表来源**
- [redis_cache_session.md](file://ai_correction/docs/redis_cache_session.md#L15-L50)

### 缓存键命名规范

系统采用标准化的键命名模式，便于管理和维护：

| 前缀 | 数据类型 | 示例 | TTL |
|------|----------|------|-----|
| `user:` | 用户数据 | `user:profile:12345` | 1小时 |
| `class:` | 班级数据 | `class:students:67890` | 1小时 |
| `assignment:` | 作业数据 | `assignment:info:abc123` | 1小时 |
| `grading:` | 批改结果 | `grading:result:task456` | 24小时 |
| `analytics:` | 分析数据 | `analytics:daily:20241201` | 5分钟 |

### 会话管理机制

#### 会话生命周期

```mermaid
stateDiagram-v2
[*] --> Created : 创建会话
Created --> Active : 设置令牌
Active --> Updated : 活动更新
Updated --> Active : 继续活跃
Active --> Extended : 会话延长
Extended --> Active : 延长完成
Active --> Expired : 超时过期
Active --> Invalidated : 手动失效
Expired --> [*] : 自动清理
Invalidated --> [*] : 手动清理
```

**图表来源**
- [redis_cache_session.md](file://ai_correction/docs/redis_cache_session.md#L100-L150)

#### 会话安全特性

- **唯一令牌**：每次会话生成随机安全令牌
- **自动过期**：基于时间的会话生命周期管理
- **活动跟踪**：记录最后访问时间
- **多会话支持**：单用户可维持多个活跃会话

**章节来源**
- [redis_cache_session.md](file://ai_correction/docs/redis_cache_session.md#L50-L441)

## 持久化方案对比

### 方案选择矩阵

| 特性 | JSON文件 | 关系型数据库 | Redis缓存 |
|------|----------|--------------|-----------|
| **数据一致性** | 最终一致 | 强一致性 | 强一致性 |
| **并发性能** | 低 | 高 | 极高 |
| **数据规模** | 小到中等 | 大规模 | 中等 |
| **事务支持** | 无 | 完整 | 有限 |
| **查询复杂度** | 有限 | 高 | 基本 |
| **部署复杂度** | 低 | 中等 | 中等 |
| **成本** | 低 | 中等 | 中等到高 |
| **适用场景** | 开发测试 | 生产环境 | 缓存加速 |

### 性能基准测试

| 操作类型 | JSON文件 | PostgreSQL | Redis |
|----------|----------|------------|-------|
| **读取速度** | 100ms | 1-5ms | 0.1-1ms |
| **写入速度** | 200ms | 5-10ms | 0.1-2ms |
| **并发连接** | 有限 | 高 | 极高 |
| **内存占用** | 高 | 中等 | 中等 |
| **磁盘IO** | 高 | 中等 | 低 |

### 数据流架构

```mermaid
flowchart LR
subgraph "前端请求"
User[用户]
API[API接口]
end
subgraph "应用层"
App[应用服务]
Cache[缓存层]
DB[数据库层]
end
subgraph "存储层"
JSON[JSON文件]
PG[(PostgreSQL)]
Redis[(Redis)]
end
User --> API
API --> App
App --> Cache
Cache --> Redis
App --> DB
DB --> PG
DB --> JSON
Cache -.->|缓存命中| Redis
Cache -.->|缓存未命中| DB
DB -.->|查询结果| Cache
```

**图表来源**
- [config.py](file://ai_correction/config.py#L10-L25)
- [db_manager.py](file://ai_correction/functions/database/db_manager.py#L15-L50)

**章节来源**
- [config.py](file://ai_correction/config.py#L10-L25)
- [db_manager.py](file://ai_correction/functions/database/db_manager.py#L15-L100)

## 生产环境最佳实践

### 部署配置建议

#### 数据库配置优化

```yaml
# 生产环境数据库配置示例
DATABASE_TYPE: postgresql
DATABASE_URL: postgresql://user:password@host:5432/ai_correction_prod

# 连接池配置
DB_POOL_SIZE: 20
DB_MAX_OVERFLOW: 30
DB_POOL_TIMEOUT: 30

# 性能监控
ENABLE_QUERY_LOGGING: false
QUERY_TIMEOUT: 30
```

#### Redis配置优化

```yaml
# Redis集群配置
REDIS_URL: redis://user:password@host:6379/0
REDIS_CLUSTER: true
REDIS_SENTINEL: false

# 缓存策略
CACHE_TTL: 3600
SESSION_EXPIRE_SECONDS: 86400
MEMORY_LIMIT: 2GB
```

### 迁移部署流程

#### 1. 预备阶段

```bash
# 1. 备份当前数据
python migration.py current
python migration.py history

# 2. 检查迁移状态
python migration.py current

# 3. 创建备份
pg_dump ai_correction_prod > backup_$(date +%Y%m%d_%H%M%S).sql
```

#### 2. 迁移执行

```bash
# 1. 初始化Alembic（首次部署）
python migration.py init

# 2. 创建迁移脚本
python migration.py create -m "生产环境部署"

# 3. 执行迁移
python migration.py upgrade

# 4. 验证迁移结果
python migration.py current
```

#### 3. 回滚准备

```bash
# 1. 创建回滚点
python migration.py create -m "准备回滚"

# 2. 执行回滚测试
python migration.py downgrade -r -1

# 3. 验证回滚效果
python migration.py current
```

### 监控和告警

#### 关键指标监控

| 指标类型 | 监控项 | 告警阈值 | 处理建议 |
|----------|--------|----------|----------|
| **数据库** | 连接数 | >80% | 扩容或优化查询 |
| **数据库** | 查询延迟 | >1000ms | 优化索引或查询 |
| **Redis** | 内存使用率 | >85% | 清理过期数据 |
| **Redis** | 连接数 | >90% | 增加连接池大小 |
| **应用** | 缓存命中率 | <80% | 调整缓存策略 |

#### 健康检查脚本

```python
# health_check.py
import redis
import psycopg2
from sqlalchemy import create_engine

def check_redis_health():
    try:
        redis_client = redis.from_url(REDIS_URL)
        redis_client.ping()
        return True
    except:
        return False

def check_db_health():
    try:
        engine = create_engine(DATABASE_URL)
        with engine.connect() as conn:
            conn.execute("SELECT 1")
        return True
    except:
        return False
```

**章节来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L187-L247)
- [config.py](file://ai_correction/config.py#L40-L60)

## 故障排除指南

### 常见问题诊断

#### 数据库连接问题

```mermaid
flowchart TD
ConnFail[连接失败] --> CheckURL{检查连接URL}
CheckURL --> |错误| FixURL[修正连接字符串]
CheckURL --> |正确| CheckService{检查服务状态}
CheckService --> |未运行| StartService[启动数据库服务]
CheckService --> |运行中| CheckAuth{检查认证信息}
CheckAuth --> |错误| FixAuth[修正用户名密码]
CheckAuth --> |正确| CheckNetwork{检查网络连接}
CheckNetwork --> |不通| FixNetwork[修复网络配置]
CheckNetwork --> |正常| CheckPerms{检查权限设置}
CheckPerms --> |不足| GrantPerms[授予必要权限]
```

#### 迁移失败处理

| 错误类型 | 症状 | 解决方案 |
|----------|------|----------|
| **语法错误** | 迁移脚本执行失败 | 检查SQL语法，手动修正 |
| **约束冲突** | 数据完整性错误 | 清理冲突数据或调整约束 |
| **权限不足** | 无法创建表结构 | 授予数据库管理员权限 |
| **版本不匹配** | Alembic版本冲突 | 更新Alembic到兼容版本 |

### 数据恢复策略

#### 完整备份恢复

```bash
# 1. 停止应用服务
systemctl stop ai-correction

# 2. 停止数据库服务
systemctl stop postgresql

# 3. 恢复数据库
pg_restore -d ai_correction_prod backup_20241201.sql

# 4. 启动数据库服务
systemctl start postgresql

# 5. 验证数据完整性
python migration.py current

# 6. 启动应用服务
systemctl start ai-correction
```

#### 部分数据恢复

```bash
# 1. 导出损坏表数据
pg_dump -t students -t grading_tasks ai_correction_prod > partial_backup.sql

# 2. 删除损坏数据
psql ai_correction_prod -c "DROP TABLE students CASCADE;"
psql ai_correction_prod -c "DROP TABLE grading_tasks CASCADE;"

# 3. 重新执行迁移
python migration.py upgrade

# 4. 导入部分数据
psql ai_correction_prod < partial_backup.sql
```

### 性能优化建议

#### 数据库优化

```sql
-- 创建复合索引
CREATE INDEX idx_student_class ON students(class_id);
CREATE INDEX idx_grading_task_student ON grading_tasks(student_id);

-- 优化查询计划
ANALYZE students;
ANALYZE grading_tasks;

-- 清理历史数据
DELETE FROM grading_results WHERE created_at < NOW() - INTERVAL '3 months';
```

#### 缓存优化

```python
# 缓存预热策略
def warm_up_cache():
    # 预热热门用户数据
    for user_id in popular_user_ids:
        cache_manager.get_user_data(user_id)
    
    # 预热班级统计
    for class_id in active_classes:
        cache_manager.get_class_statistics(class_id)
```

**章节来源**
- [migration.py](file://ai_correction/functions/database/migration.py#L100-L150)
- [db_manager.py](file://ai_correction/functions/database/db_manager.py#L230-L280)

## 总结

AI批改系统的数据持久化策略通过多层次的设计实现了灵活性、可靠性和高性能的平衡：

### 核心优势

1. **多后端支持**：灵活适配开发、测试和生产环境的不同需求
2. **版本控制**：基于Alembic的迁移机制确保数据结构的平滑演进
3. **性能优化**：Redis缓存显著提升高频访问数据的响应速度
4. **安全保障**：完善的备份恢复机制和监控告警体系

### 发展方向

- **云原生支持**：增强对容器化和微服务架构的支持
- **智能缓存**：引入机器学习算法优化缓存策略
- **分布式事务**：支持跨存储系统的事务一致性
- **实时同步**：实现多存储后端间的数据实时同步

通过持续的优化和改进，该数据持久化策略将为AI批改系统提供稳定可靠的数据基础设施支撑，确保系统在各种场景下的高效运行。