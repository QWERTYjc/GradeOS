# æ‰§è¡Œæµç¨‹æ§åˆ¶

<cite>
**æœ¬æ–‡æ¡£å¼•ç”¨çš„æ–‡ä»¶**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py)
- [state.py](file://ai_correction/functions/langgraph/state.py)
- [checkpointer.py](file://ai_correction/functions/langgraph/checkpointer.py)
- [streaming.py](file://ai_correction/functions/langgraph/streaming.py)
- [routing.py](file://ai_correction/functions/langgraph/routing.py)
- [workflow.py](file://ai_correction/functions/langgraph/workflow.py)
- [test_multimodal_grading.py](file://ai_correction/test_multimodal_grading.py)
</cite>

## ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
3. [MultiModalGradingWorkflow ç±»è¯¦è§£](#multimodalgradingworkflow-ç±»è¯¦è§£)
4. [execute å¼‚æ­¥æ–¹æ³•æ·±åº¦åˆ†æ](#execute-å¼‚æ­¥æ–¹æ³•æ·±åº¦åˆ†æ)
5. [çŠ¶æ€ç®¡ç†ç³»ç»Ÿ](#çŠ¶æ€ç®¡ç†ç³»ç»Ÿ)
6. [æµå¼æ‰§è¡Œä¸çŠ¶æ€æ›´æ–°](#æµå¼æ‰§è¡Œä¸çŠ¶æ€æ›´æ–°)
7. [é…ç½®ä¸ä»»åŠ¡éš”ç¦»](#é…ç½®ä¸ä»»åŠ¡éš”ç¦»)
8. [æ—¥å¿—è®°å½•ä¸è¿½è¸ª](#æ—¥å¿—è®°å½•ä¸è¿½è¸ª)
9. [å¼‚å¸¸å¤„ç†æœºåˆ¶](#å¼‚å¸¸å¤„ç†æœºåˆ¶)
10. [æ£€æŸ¥ç‚¹ä¸æ¢å¤æœºåˆ¶](#æ£€æŸ¥ç‚¹ä¸æ¢å¤æœºåˆ¶)
11. [æ€§èƒ½ç›‘æ§ä¸è¶…æ—¶å¤„ç†](#æ€§èƒ½ç›‘æ§ä¸è¶…æ—¶å¤„ç†)
12. [è°ƒç”¨é“¾åˆ†æ](#è°ƒç”¨é“¾åˆ†æ)
13. [æœ€ä½³å®è·µæŒ‡å—](#æœ€ä½³å®è·µæŒ‡å—)

## æ¦‚è¿°

MultiModalGradingWorkflow æ˜¯ä¸€ä¸ªåŸºäº LangGraph çš„æ·±åº¦åä½œå¤šæ¨¡æ€æ‰¹æ”¹å·¥ä½œæµç³»ç»Ÿï¼Œé‡‡ç”¨çŠ¶æ€æœºæ¨¡å¼å®ç°å¤æ‚çš„æ‰¹æ”¹æµç¨‹æ§åˆ¶ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¼‚æ­¥æ‰§è¡Œã€æµå¼å¤„ç†ã€çŠ¶æ€æŒä¹…åŒ–å’Œæ™ºèƒ½è·¯ç”±ç­‰æœºåˆ¶ï¼Œå®ç°äº†é«˜æ•ˆã€å¯é ã€å¯ç›‘æ§çš„æ‰¹æ”¹æœåŠ¡ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **æ·±åº¦åä½œæ¶æ„**ï¼š8ä¸ªä¸“ä¸šAgentååŒå·¥ä½œï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†
- **å¤šæ¨¡æ€å¤„ç†**ï¼šåŸç”Ÿæ”¯æŒå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ–‡ä»¶æ ¼å¼
- **çŠ¶æ€æŒä¹…åŒ–**ï¼šåŸºäºæ£€æŸ¥ç‚¹çš„å®Œæ•´çŠ¶æ€æ¢å¤æœºåˆ¶
- **æµå¼æ‰§è¡Œ**ï¼šå®æ—¶è¿›åº¦ç›‘æ§å’ŒçŠ¶æ€æ›´æ–°
- **æ™ºèƒ½è·¯ç”±**ï¼šæ ¹æ®æ¡ä»¶åŠ¨æ€è°ƒæ•´æ‰§è¡Œè·¯å¾„
- **å¼‚å¸¸æ¢å¤**ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

## æ ¸å¿ƒæ¶æ„

```mermaid
graph TB
subgraph "å·¥ä½œæµæ¶æ„"
A[OrchestratorAgent<br/>ä»»åŠ¡ç¼–æ’] --> B[MultiModalInputAgent<br/>å¤šæ¨¡æ€è¾“å…¥]
B --> C[QuestionUnderstandingAgent<br/>é¢˜ç›®ç†è§£]
B --> D[AnswerUnderstandingAgent<br/>ç­”æ¡ˆç†è§£]
B --> E[RubricInterpreterAgent<br/>è¯„åˆ†æ ‡å‡†è§£æ]
C --> F[StudentDetectionAgent<br/>å­¦ç”Ÿä¿¡æ¯è¯†åˆ«]
D --> F
E --> F
F --> G[BatchPlanningAgent<br/>æ‰¹æ¬¡è§„åˆ’]
G --> H[RubricMasterAgent<br/>è¯„åˆ†æ ‡å‡†ä¸»æ§]
G --> I[QuestionContextAgent<br/>é¢˜ç›®ä¸Šä¸‹æ–‡]
H --> J[GradingWorkerAgent<br/>æ‰¹æ”¹å·¥ä½œ]
I --> J
J --> K[ResultAggregatorAgent<br/>ç»“æœèšåˆ]
K --> L[ClassAnalysisAgent<br/>ç­çº§åˆ†æ]
L --> M[Finalize<br/>æœ€ç»ˆåŒ–]
end
subgraph "çŠ¶æ€ç®¡ç†"
N[GradingState<br/>çŠ¶æ€æ¨¡å‹] --> O[MemorySaver<br/>å†…å­˜æ£€æŸ¥ç‚¹]
P[CheckpointManager<br/>æ£€æŸ¥ç‚¹ç®¡ç†å™¨] --> O
end
subgraph "æµå¼ç›‘æ§"
Q[ProgressMonitor<br/>è¿›åº¦ç›‘æ§] --> R[StreamingWorkflowRunner<br/>æµå¼è¿è¡Œå™¨]
S[WebSocketProgressPusher<br/>WebSocketæ¨é€å™¨] --> Q
T[SSEProgressPusher<br/>SSEæ¨é€å™¨] --> Q
end
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L39-L99)

## MultiModalGradingWorkflow ç±»è¯¦è§£

MultiModalGradingWorkflow æ˜¯æ•´ä¸ªæ‰¹æ”¹ç³»ç»Ÿçš„æ ¸å¿ƒæ§åˆ¶å™¨ï¼Œè´Ÿè´£åè°ƒå„ä¸ªAgentçš„æ‰§è¡Œå’ŒçŠ¶æ€ç®¡ç†ã€‚

### ç±»ç»“æ„æ¦‚è§ˆ

```mermaid
classDiagram
class MultiModalGradingWorkflow {
+StateGraph graph
+MemorySaver checkpointer
+__init__()
+_build_workflow()
+execute(initial_state) GradingState
+_finalize_results(state) GradingState
}
class GradingState {
+str task_id
+str user_id
+str[] question_files
+str[] answer_files
+str[] marking_files
+Dict~str,Any~ student_info
+Dict[] students_info
+Dict[] batches_info
+Dict~str,Any~ batch_rubric_packages
+Dict~str,Any~ question_context_packages
+Dict[] grading_results
+Dict[] student_reports
+Dict~str,Any~ class_analysis
+str current_step
+float progress_percentage
+str completion_status
+Dict[] errors
+str[] warnings
}
class CheckpointManager {
+save_checkpoint(task_id, state, metadata)
+load_checkpoint(task_id)
+list_checkpoints(task_id)
+delete_checkpoint(task_id)
}
class ProgressMonitor {
+monitor_stream(graph, initial_state, config)
+_parse_chunk(node_name, state_update)
+_create_event(event_type, data)
}
MultiModalGradingWorkflow --> GradingState : "ç®¡ç†"
MultiModalGradingWorkflow --> CheckpointManager : "ä½¿ç”¨"
MultiModalGradingWorkflow --> ProgressMonitor : "ç›‘æ§"
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L39-L265)
- [state.py](file://ai_correction/functions/langgraph/state.py#L44-L268)

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L39-L265)
- [state.py](file://ai_correction/functions/langgraph/state.py#L44-L268)

## execute å¼‚æ­¥æ–¹æ³•æ·±åº¦åˆ†æ

`execute` æ–¹æ³•æ˜¯å·¥ä½œæµçš„æ ¸å¿ƒæ‰§è¡Œå¼•æ“ï¼Œè´Ÿè´£åˆå§‹åŒ–çŠ¶æ€ã€æ‰§è¡Œå·¥ä½œæµå¹¶å¤„ç†å¼‚å¸¸ã€‚

### æ–¹æ³•ç­¾åä¸èŒè´£

```mermaid
sequenceDiagram
participant Client as å®¢æˆ·ç«¯
participant Workflow as MultiModalGradingWorkflow
participant Graph as StateGraph
participant Monitor as ProgressMonitor
participant Checkpoint as CheckpointManager
Client->>Workflow : execute(initial_state)
Workflow->>Workflow : åˆå§‹åŒ–å¿…è¦å­—æ®µ
Workflow->>Workflow : è®¾ç½®åˆå§‹çŠ¶æ€
Workflow->>Monitor : åˆ›å»ºè¿›åº¦ç›‘æ§å™¨
Workflow->>Graph : astream(initial_state, config)
loop æµå¼æ‰§è¡Œ
Graph->>Monitor : çŠ¶æ€æ›´æ–°
Monitor->>Monitor : è§£æè¿›åº¦äº‹ä»¶
Monitor->>Client : æ¨é€è¿›åº¦
end
Graph->>Workflow : æœ€ç»ˆçŠ¶æ€
Workflow->>Workflow : æ ‡è®°å®Œæˆ
Workflow->>Checkpoint : ä¿å­˜æœ€ç»ˆçŠ¶æ€
Workflow->>Client : è¿”å›ç»“æœ
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L131-L216)

### å­—æ®µåˆå§‹åŒ–ç­–ç•¥

execute æ–¹æ³•é‡‡ç”¨é˜²å¾¡æ€§ç¼–ç¨‹ç­–ç•¥ï¼Œç¡®ä¿æ‰€æœ‰å¿…è¦çš„çŠ¶æ€å­—æ®µéƒ½è¢«æ­£ç¡®åˆå§‹åŒ–ï¼š

#### åŸºç¡€çŠ¶æ€å­—æ®µ
- **é”™è¯¯è®°å½•**ï¼š`errors` - å­˜å‚¨æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°çš„æ‰€æœ‰é”™è¯¯
- **æ­¥éª¤ç»“æœ**ï¼š`step_results` - è®°å½•æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œç»“æœ
- **è­¦å‘Šä¿¡æ¯**ï¼š`warnings` - å­˜å‚¨éè‡´å‘½çš„è­¦å‘Šä¿¡æ¯
- **å¤šæ¨¡æ€æ–‡ä»¶**ï¼š`question_multimodal_files`ã€`answer_multimodal_files`ã€`marking_multimodal_files`
- **è¯„ä¼°ç»“æœ**ï¼š`criteria_evaluations` - åŸºäºè¯„åˆ†æ ‡å‡†çš„è¯„ä¼°ç»“æœ

#### æ·±åº¦åä½œç›¸å…³å­—æ®µ
- **å­¦ç”Ÿä¿¡æ¯**ï¼š`students_info` - å­¦ç”ŸåŸºæœ¬ä¿¡æ¯åˆ—è¡¨
- **æ‰¹æ¬¡ä¿¡æ¯**ï¼š`batches_info` - æ‰¹æ¬¡è§„åˆ’è¯¦ç»†ä¿¡æ¯
- **æ‰¹æ”¹åŒ…**ï¼š`batch_rubric_packages` - æ‰¹æ¬¡ä¸“å±è¯„åˆ†åŒ…
- **ä¸Šä¸‹æ–‡åŒ…**ï¼š`question_context_packages` - æ‰¹æ¬¡ä¸“å±é¢˜ç›®ä¸Šä¸‹æ–‡
- **æ‰¹æ”¹ç»“æœ**ï¼š`grading_results` - æ‰€æœ‰æ‰¹æ”¹çš„å…·ä½“ç»“æœ
- **å­¦ç”ŸæŠ¥å‘Š**ï¼š`student_reports` - ä¸ªæ€§åŒ–çš„å­¦ç”ŸæŠ¥å‘Š
- **ç­çº§åˆ†æ**ï¼š`class_analysis` - ç­çº§æ•´ä½“åˆ†ææŠ¥å‘Š

### çŠ¶æ€è®¾ç½®ä¸è¿›åº¦è·Ÿè¸ª

```mermaid
flowchart TD
A[å¼€å§‹æ‰§è¡Œ] --> B[åˆå§‹åŒ–å­—æ®µ]
B --> C[è®¾ç½®åˆå§‹çŠ¶æ€]
C --> D[é…ç½®çº¿ç¨‹ID]
D --> E[å¯åŠ¨æµå¼æ‰§è¡Œ]
E --> F{çŠ¶æ€æ›´æ–°?}
F --> |æ˜¯| G[æ›´æ–°è¿›åº¦]
F --> |å¦| H[ç­‰å¾…ä¸‹ä¸€ä¸ªçŠ¶æ€]
G --> I[è®°å½•å½“å‰èŠ‚ç‚¹]
H --> F
I --> J{æ‰§è¡Œå®Œæˆ?}
J --> |æ˜¯| K[æ ‡è®°å®Œæˆ]
J --> |å¦| E
K --> L[è¿”å›æœ€ç»ˆçŠ¶æ€]
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L131-L216)

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L131-L216)

## çŠ¶æ€ç®¡ç†ç³»ç»Ÿ

GradingState æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼ŒåŒ…å«äº†æ‰¹æ”¹è¿‡ç¨‹ä¸­çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯ã€‚

### çŠ¶æ€å­—æ®µåˆ†ç±»

| å­—æ®µç±»åˆ« | ä¸»è¦å­—æ®µ | åŠŸèƒ½æè¿° |
|---------|---------|---------|
| **åŸºç¡€ä¿¡æ¯** | `task_id`, `user_id`, `timestamp` | ä»»åŠ¡æ ‡è¯†å’Œå…ƒæ•°æ® |
| **æ–‡ä»¶ä¿¡æ¯** | `question_files`, `answer_files`, `marking_files` | åŸå§‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨ |
| **å¤šæ¨¡æ€æ•°æ®** | `question_multimodal_files`, `mm_tokens` | å¤šæ¨¡æ€å¤„ç†ç»“æœ |
| **ç†è§£ç»“æœ** | `question_understanding`, `answer_understanding` | AIç†è§£è¾“å‡º |
| **æ‰¹æ”¹å‚æ•°** | `strictness_level`, `language`, `mode` | æ‰¹æ”¹é…ç½®å‚æ•° |
| **è¯„åˆ†æ ‡å‡†** | `rubric_struct`, `scoring_criteria` | ç»“æ„åŒ–è¯„åˆ†è§„åˆ™ |
| **æ‰¹æ”¹ç»“æœ** | `evaluations`, `criteria_evaluations` | è¯„åˆ†ç»“æœåˆ—è¡¨ |
| **æ·±åº¦åä½œ** | `students_info`, `batches_info` | åä½œç›¸å…³ä¿¡æ¯ |
| **å¤„ç†çŠ¶æ€** | `current_step`, `progress_percentage` | æ‰§è¡Œè¿›åº¦è·Ÿè¸ª |
| **é”™è¯¯è®°å½•** | `errors`, `warnings` | é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯ |

### çŠ¶æ€æ¼”è¿›æµç¨‹

```mermaid
stateDiagram-v2
[*] --> pending : åˆå§‹åŒ–
pending --> in_progress : å¼€å§‹æ‰§è¡Œ
in_progress --> step_execution : æ‰§è¡Œå…·ä½“æ­¥éª¤
step_execution --> step_execution : ç»§ç»­æ‰§è¡Œ
step_execution --> in_progress : æ­¥éª¤å®Œæˆ
in_progress --> completed : æ‰§è¡ŒæˆåŠŸ
in_progress --> failed : æ‰§è¡Œå¤±è´¥
completed --> [*]
failed --> [*]
note right of in_progress
progress_percentage : 0-100
current_step : å½“å‰æ‰§è¡Œæ­¥éª¤
end note
```

**å›¾è¡¨æ¥æº**
- [state.py](file://ai_correction/functions/langgraph/state.py#L146-L148)

**ç« èŠ‚æ¥æº**
- [state.py](file://ai_correction/functions/langgraph/state.py#L44-L268)

## æµå¼æ‰§è¡Œä¸çŠ¶æ€æ›´æ–°

ç³»ç»Ÿé‡‡ç”¨ LangGraph çš„ `astream` æ–¹æ³•å®ç°æµå¼æ‰§è¡Œï¼Œèƒ½å¤Ÿå®æ—¶è·å–çŠ¶æ€æ›´æ–°å¹¶è¿›è¡Œè¿›åº¦ç›‘æ§ã€‚

### astream æ–¹æ³•å·¥ä½œæœºåˆ¶

```mermaid
sequenceDiagram
participant Caller as è°ƒç”¨è€…
participant Workflow as Workflow
participant Graph as StateGraph
participant Monitor as ProgressMonitor
participant Callback as å›è°ƒå‡½æ•°
Caller->>Workflow : execute(initial_state)
Workflow->>Graph : astream(initial_state, config)
loop æµå¼å¤„ç†å¾ªç¯
Graph->>Monitor : çŠ¶æ€æ›´æ–°(chunk)
Monitor->>Monitor : è§£æçŠ¶æ€æ›´æ–°
Monitor->>Callback : è°ƒç”¨è¿›åº¦å›è°ƒ
Monitor->>Caller : æ¨é€è¿›åº¦äº‹ä»¶
Graph->>Workflow : ä¸‹ä¸€ä¸ªçŠ¶æ€
end
Graph->>Workflow : æœ€ç»ˆçŠ¶æ€
Workflow->>Caller : è¿”å›ç»“æœ
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L187-L200)
- [streaming.py](file://ai_correction/functions/langgraph/streaming.py#L47-L110)

### çŠ¶æ€æ›´æ–°è§£æ

ProgressMonitor ç±»è´Ÿè´£è§£ææ¥è‡ª `astream` çš„çŠ¶æ€æ›´æ–°ï¼š

#### äº‹ä»¶ç±»å‹è¯†åˆ«
- **STEP_STARTED**ï¼šæ­¥éª¤å¼€å§‹äº‹ä»¶
- **PROGRESS_UPDATE**ï¼šè¿›åº¦æ›´æ–°äº‹ä»¶  
- **ERROR**ï¼šé”™è¯¯äº‹ä»¶
- **STEP_COMPLETED**ï¼šæ­¥éª¤å®Œæˆäº‹ä»¶
- **COMPLETED**ï¼šæ‰§è¡Œå®Œæˆäº‹ä»¶
- **FAILED**ï¼šæ‰§è¡Œå¤±è´¥äº‹ä»¶

#### çŠ¶æ€è§£æé€»è¾‘

```mermaid
flowchart TD
A[çŠ¶æ€æ›´æ–°] --> B{æ£€æŸ¥current_step}
B --> |å˜åŒ–| C[STEP_STARTEDäº‹ä»¶]
B --> |ç›¸åŒ| D{æ£€æŸ¥progress}
D --> |> 0| E[PROGRESS_UPDATEäº‹ä»¶]
D --> |= 0| F{æ£€æŸ¥errors}
F --> |æœ‰é”™è¯¯| G[ERRORäº‹ä»¶]
F --> |æ— é”™è¯¯| H[å¿½ç•¥æ›´æ–°]
C --> I[æ›´æ–°current_step]
E --> J[æ›´æ–°è¿›åº¦]
G --> K[è®°å½•é”™è¯¯]
I --> L[è§¦å‘å›è°ƒ]
J --> L
K --> L
H --> M[ç»§ç»­ç›‘å¬]
L --> M
```

**å›¾è¡¨æ¥æº**
- [streaming.py](file://ai_correction/functions/langgraph/streaming.py#L111-L153)

**ç« èŠ‚æ¥æº**
- [streaming.py](file://ai_correction/functions/langgraph/streaming.py#L47-L153)

## é…ç½®ä¸ä»»åŠ¡éš”ç¦»

ç³»ç»Ÿé€šè¿‡ configurable é…ç½®å®ç°ä»»åŠ¡çº§åˆ«çš„éš”ç¦»ï¼Œç¡®ä¿ä¸åŒä»»åŠ¡ä¹‹é—´çš„çŠ¶æ€ä¸ä¼šç›¸äº’å¹²æ‰°ã€‚

### configurable é…ç½®æœºåˆ¶

```mermaid
graph LR
A[åˆå§‹çŠ¶æ€] --> B[é…ç½®ç”Ÿæˆ]
B --> C[thread_id: task_id]
C --> D[LangGraphé…ç½®]
D --> E[å·¥ä½œæµæ‰§è¡Œ]
E --> F[çŠ¶æ€éš”ç¦»]
subgraph "ä»»åŠ¡éš”ç¦»"
G[Task A] -.-> H[Thread ID: task_a_001]
I[Task B] -.-> J[Thread ID: task_b_002]
K[Task C] -.-> L[Thread ID: task_c_003]
end
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L187-L188)

### ä»»åŠ¡éš”ç¦»å®ç°

#### Thread ID ç”Ÿæˆç­–ç•¥
- **é»˜è®¤å€¼**ï¼šå¦‚æœ `task_id` ä¸å­˜åœ¨ï¼Œä½¿ç”¨ `'default'`
- **å”¯ä¸€æ€§**ï¼šç¡®ä¿æ¯ä¸ªä»»åŠ¡éƒ½æœ‰å”¯ä¸€çš„ thread_id
- **æŒä¹…æ€§**ï¼šthread_id åœ¨æ•´ä¸ªæ‰§è¡Œå‘¨æœŸå†…ä¿æŒä¸å˜

#### éš”ç¦»æœºåˆ¶
1. **çŠ¶æ€éš”ç¦»**ï¼šæ¯ä¸ª thread_id å¯¹åº”ç‹¬ç«‹çš„çŠ¶æ€ç©ºé—´
2. **æ£€æŸ¥ç‚¹éš”ç¦»**ï¼šæ£€æŸ¥ç‚¹æŒ‰ thread_id åˆ†ç»„å­˜å‚¨
3. **å¹¶å‘å®‰å…¨**ï¼šLangGraph è‡ªåŠ¨ä¿è¯å¹¶å‘è®¿é—®çš„å®‰å…¨æ€§

### configurable é…ç½®ç¤ºä¾‹

```python
# é…ç½®ç¤ºä¾‹
config = {
    "configurable": {
        "thread_id": "task_12345_abcde",
        "metadata": {
            "user_id": "user_67890",
            "priority": "high",
            "created_at": "2024-01-01T12:00:00Z"
        }
    }
}

# æ‰§è¡Œå·¥ä½œæµ
async for state in graph.astream(initial_state, config=config):
    # å®æ—¶çŠ¶æ€æ›´æ–°
    pass
```

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L187-L188)

## æ—¥å¿—è®°å½•ä¸è¿½è¸ª

ç³»ç»Ÿå®ç°äº†å®Œæ•´çš„æ—¥å¿—è®°å½•å’Œè¿½è¸ªæœºåˆ¶ï¼Œæ”¯æŒè°ƒè¯•ã€ç›‘æ§å’Œæ•…éšœæ’æŸ¥ã€‚

### æ—¥å¿—å±‚çº§ç»“æ„

```mermaid
graph TD
A[ç³»ç»Ÿæ—¥å¿—] --> B[å·¥ä½œæµæ—¥å¿—]
A --> C[Agentæ—¥å¿—]
A --> D[çŠ¶æ€æ—¥å¿—]
A --> E[é”™è¯¯æ—¥å¿—]
B --> F[å·¥ä½œæµå¯åŠ¨]
B --> G[å·¥ä½œæµå®Œæˆ]
B --> H[èŠ‚ç‚¹æ‰§è¡Œ]
C --> I[Agentå¼€å§‹]
C --> J[Agentå®Œæˆ]
C --> K[Agenté”™è¯¯]
D --> L[çŠ¶æ€æ›´æ–°]
D --> M[è¿›åº¦è·Ÿè¸ª]
D --> N[æ£€æŸ¥ç‚¹æ“ä½œ]
E --> O[å¼‚å¸¸æ•è·]
E --> P[é”™è¯¯æ¢å¤]
E --> Q[å¤±è´¥æ ‡è®°]
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L133-L216)

### å…³é”®æ—¥å¿—äº‹ä»¶

#### å·¥ä½œæµç”Ÿå‘½å‘¨æœŸæ—¥å¿—
- **å·¥ä½œæµå¯åŠ¨**ï¼šè®°å½•ä»»åŠ¡IDå’Œåˆå§‹çŠ¶æ€
- **èŠ‚ç‚¹æ‰§è¡Œ**ï¼šè®°å½•å½“å‰æ‰§è¡Œçš„AgentèŠ‚ç‚¹
- **å·¥ä½œæµå®Œæˆ**ï¼šè®°å½•æœ€ç»ˆç»“æœå’Œå¤„ç†æ—¶é—´
- **å¼‚å¸¸å‘ç”Ÿ**ï¼šè®°å½•é”™è¯¯è¯¦æƒ…å’Œæ¢å¤ç­–ç•¥

#### çŠ¶æ€å˜æ›´æ—¥å¿—
- **çŠ¶æ€åˆå§‹åŒ–**ï¼šè®°å½•æ‰€æœ‰å­—æ®µçš„åˆå§‹å€¼
- **è¿›åº¦æ›´æ–°**ï¼šè®°å½•æ‰§è¡Œè¿›åº¦å’Œå½“å‰æ­¥éª¤
- **é”™è¯¯è®°å½•**ï¼šè®°å½•é”™è¯¯å‘ç”Ÿçš„æ—¶é—´å’Œä¸Šä¸‹æ–‡
- **è­¦å‘Šä¿¡æ¯**ï¼šè®°å½•éè‡´å‘½é—®é¢˜å’Œå»ºè®®

### æ—¥å¿—æ ¼å¼è§„èŒƒ

```python
# å·¥ä½œæµå¯åŠ¨æ—¥å¿—
logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œå¤šæ¨¡æ€æ‰¹æ”¹å·¥ä½œæµï¼Œä»»åŠ¡ID: {task_id}")

# èŠ‚ç‚¹æ‰§è¡Œæ—¥å¿—  
logger.info(f"ğŸ“ å½“å‰èŠ‚ç‚¹: {current_node}")

# å·¥ä½œæµå®Œæˆæ—¥å¿—
logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œæ€»åˆ†: {total_score}")

# é”™è¯¯æ—¥å¿—
logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {error_message}")
```

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L133-L216)

## å¼‚å¸¸å¤„ç†æœºåˆ¶

ç³»ç»Ÿå®ç°äº†å¤šå±‚æ¬¡çš„å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿åœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹éƒ½èƒ½ä¿æŒçŠ¶æ€çš„å®Œæ•´æ€§å’Œç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚

### å¼‚å¸¸å¤„ç†å±‚æ¬¡

```mermaid
flowchart TD
A[å¼‚å¸¸å‘ç”Ÿ] --> B{å¼‚å¸¸ç±»å‹}
B --> |å·¥ä½œæµå¼‚å¸¸| C[executeæ–¹æ³•æ•è·]
B --> |Agentå¼‚å¸¸| D[Agentå†…éƒ¨å¤„ç†]
B --> |ç½‘ç»œå¼‚å¸¸| E[é‡è¯•æœºåˆ¶]
B --> |ç³»ç»Ÿå¼‚å¸¸| F[é™çº§å¤„ç†]
C --> G[è®°å½•é”™è¯¯ä¿¡æ¯]
G --> H[è®¾ç½®å¤±è´¥çŠ¶æ€]
H --> I[è¿”å›é”™è¯¯çŠ¶æ€]
D --> J[é”™è¯¯æ¢å¤]
J --> K{æ˜¯å¦å¯æ¢å¤}
K --> |æ˜¯| L[ç»§ç»­æ‰§è¡Œ]
K --> |å¦| M[æ ‡è®°å¤±è´¥]
E --> N{é‡è¯•æ¬¡æ•°æ£€æŸ¥}
N --> |æœªè¶…é™| O[å»¶è¿Ÿé‡è¯•]
N --> |å·²è¶…é™| P[æ ‡è®°å¤±è´¥]
F --> Q[ç®€åŒ–å¤„ç†]
Q --> R[è¿”å›åŸºç¡€ç»“æœ]
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L201-L216)

### å¼‚å¸¸å¤„ç†ç­–ç•¥

#### 1. å·¥ä½œæµçº§åˆ«å¼‚å¸¸å¤„ç†
åœ¨ `execute` æ–¹æ³•ä¸­æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œç¡®ä¿çŠ¶æ€çš„å®Œæ•´æ€§ï¼š

```python
try:
    # å·¥ä½œæµæ‰§è¡Œé€»è¾‘
    final_state = await self.graph.astream(initial_state, config)
except Exception as e:
    # å¼‚å¸¸å¤„ç†
    error_msg = f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}"
    logger.error(error_msg)
    
    # è®¾ç½®å¤±è´¥çŠ¶æ€
    initial_state['completion_status'] = "failed"
    initial_state['errors'].append({
        'step': 'workflow_execution',
        'error': error_msg,
        'timestamp': str(datetime.now())
    })
    
    return initial_state
```

#### 2. Agentçº§åˆ«å¼‚å¸¸å¤„ç†
æ¯ä¸ªAgentéƒ½åº”è¯¥æœ‰è‡ªå·±çš„å¼‚å¸¸å¤„ç†é€»è¾‘ï¼Œå®ç°å±€éƒ¨æ¢å¤ï¼š

```python
# Agentå†…éƒ¨å¼‚å¸¸å¤„ç†ç¤ºä¾‹
try:
    result = await self.process(state)
    return result
except TimeoutError:
    logger.warning("Agentå¤„ç†è¶…æ—¶ï¼Œå°è¯•é‡è¯•")
    return await self.retry_with_fallback(state)
except Exception as e:
    logger.error(f"Agentæ‰§è¡Œå¤±è´¥: {e}")
    state['errors'].append({
        'step': self.name,
        'error': str(e),
        'timestamp': str(datetime.now())
    })
    return state
```

#### 3. é”™è¯¯è·¯ç”±æœºåˆ¶
ç³»ç»Ÿæä¾›äº†æ™ºèƒ½çš„é”™è¯¯è·¯ç”±æœºåˆ¶ï¼Œæ ¹æ®é”™è¯¯ç±»å‹å†³å®šå¤„ç†ç­–ç•¥ï¼š

```mermaid
flowchart TD
A[é”™è¯¯å‘ç”Ÿ] --> B[æ£€æŸ¥é”™è¯¯ç±»å‹]
B --> C{å…³é”®æ­¥éª¤é”™è¯¯?}
C --> |æ˜¯| D{é‡è¯•æ¬¡æ•°æ£€æŸ¥}
C --> |å¦| E[ç»§ç»­æ‰§è¡Œ]
D --> F{æœªè¶…é™?}
F --> |æ˜¯| G[é‡è¯•å½“å‰æ­¥éª¤]
F --> |å¦| H[æ ‡è®°å¤±è´¥]
G --> I[å¢åŠ é‡è¯•è®¡æ•°]
I --> J[é‡æ–°æ‰§è¡Œ]
E --> K[è®°å½•è­¦å‘Š]
H --> L[ç»ˆæ­¢æ‰§è¡Œ]
```

**å›¾è¡¨æ¥æº**
- [routing.py](file://ai_correction/functions/langgraph/routing.py#L156-L191)

### å¼‚å¸¸æ¢å¤ç­–ç•¥

#### 1. è‡ªåŠ¨é‡è¯•æœºåˆ¶
å¯¹äºä¸´æ—¶æ€§é”™è¯¯ï¼ˆå¦‚ç½‘ç»œè¶…æ—¶ã€æ¨¡å‹å“åº”æ…¢ï¼‰ï¼Œç³»ç»Ÿæ”¯æŒè‡ªåŠ¨é‡è¯•ï¼š

```python
# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’

# é‡è¯•é€»è¾‘
async def execute_with_retry(self, state: GradingState):
    for attempt in range(MAX_RETRIES):
        try:
            return await self.execute(state)
        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY * (attempt + 1))
                continue
            raise e
```

#### 2. é™çº§å¤„ç†
å½“æŸäº›åŠŸèƒ½ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°é™çº§æ¨¡å¼ï¼š

```python
# é™çº§å¤„ç†ç¤ºä¾‹
if not self.is_advanced_feature_available():
    state['mode'] = 'efficient'  # åˆ‡æ¢åˆ°é«˜æ•ˆæ¨¡å¼
    state['warnings'].append("é«˜çº§åŠŸèƒ½ä¸å¯ç”¨ï¼Œå·²åˆ‡æ¢åˆ°é«˜æ•ˆæ¨¡å¼")
```

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L201-L216)
- [routing.py](file://ai_correction/functions/langgraph/routing.py#L156-L191)

## æ£€æŸ¥ç‚¹ä¸æ¢å¤æœºåˆ¶

ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„çŠ¶æ€æŒä¹…åŒ–å’Œæ¢å¤æœºåˆ¶ï¼Œæ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡å’Œæ„å¤–ä¸­æ–­åçš„æ¢å¤ã€‚

### æ£€æŸ¥ç‚¹æ¶æ„

```mermaid
graph TB
subgraph "æ£€æŸ¥ç‚¹ç®¡ç†"
A[CheckpointerFactory] --> B[MemorySaver]
A --> C[PostgresSaver]
D[CheckpointManager] --> A
end
subgraph "å·¥ä½œæµé›†æˆ"
E[MultiModalGradingWorkflow] --> D
F[StateGraph] --> D
end
subgraph "æŒä¹…åŒ–å­˜å‚¨"
B --> G[å†…å­˜å­˜å‚¨]
C --> H[PostgreSQL]
end
subgraph "æ¢å¤æœºåˆ¶"
I[ä»»åŠ¡æ¢å¤] --> J[çŠ¶æ€åŠ è½½]
J --> K[ç»§ç»­æ‰§è¡Œ]
end
```

**å›¾è¡¨æ¥æº**
- [checkpointer.py](file://ai_correction/functions/langgraph/checkpointer.py#L23-L246)

### æ£€æŸ¥ç‚¹å·¥å‚æ¨¡å¼

CheckpointerFactory æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å­˜å‚¨åç«¯ï¼š

#### ç¯å¢ƒé…ç½®ç­–ç•¥
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šä½¿ç”¨ PostgreSQL å­˜å‚¨ï¼Œæ”¯æŒé«˜å¯ç”¨å’Œæ•°æ®æŒä¹…åŒ–
- **å¼€å‘ç¯å¢ƒ**ï¼šä¼˜å…ˆå°è¯• PostgreSQLï¼Œå¤±è´¥åˆ™å›é€€åˆ°å†…å­˜å­˜å‚¨
- **æµ‹è¯•ç¯å¢ƒ**ï¼šå¼ºåˆ¶ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼Œä¾¿äºå¿«é€Ÿæµ‹è¯•

#### å­˜å‚¨åç«¯ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | MemorySaver | PostgresSaver |
|------|-------------|---------------|
| **æŒä¹…æ€§** | âŒ å†…å­˜ä¸­ï¼Œé‡å¯ä¸¢å¤± | âœ… æŒä¹…åŒ–å­˜å‚¨ |
| **å¹¶å‘æ€§** | âŒ ä¸æ”¯æŒå¹¶å‘ | âœ… æ”¯æŒå¹¶å‘è®¿é—® |
| **å¯é æ€§** | âŒ æ˜“ä¸¢å¤± | âœ… é«˜å¯é æ€§ |
| **æ€§èƒ½** | âœ… æå¿« | âš ï¸ ä¸­ç­‰ |
| **éƒ¨ç½²å¤æ‚åº¦** | âœ… æ— ä¾èµ– | âš ï¸ éœ€è¦æ•°æ®åº“ |

### æ£€æŸ¥ç‚¹ç®¡ç†å™¨

CheckpointManager æä¾›äº†ç»Ÿä¸€çš„æ£€æŸ¥ç‚¹ç®¡ç†æ¥å£ï¼š

#### æ ¸å¿ƒåŠŸèƒ½
- **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼šè‡ªåŠ¨ä¿å­˜å½“å‰çŠ¶æ€
- **åŠ è½½æ£€æŸ¥ç‚¹**ï¼šä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½çŠ¶æ€
- **åˆ—è¡¨æ£€æŸ¥ç‚¹**ï¼šåˆ—å‡ºå¯ç”¨çš„æ£€æŸ¥ç‚¹
- **åˆ é™¤æ£€æŸ¥ç‚¹**ï¼šæ¸…ç†è¿‡æœŸçš„æ£€æŸ¥ç‚¹

#### æ£€æŸ¥ç‚¹ç”Ÿå‘½å‘¨æœŸ

```mermaid
stateDiagram-v2
[*] --> Created : åˆ›å»ºä»»åŠ¡
Created --> Saving : æ‰§è¡Œä¸­
Saving --> Saved : ä¿å­˜æˆåŠŸ
Saved --> Loading : æ¢å¤ä»»åŠ¡
Loading --> Loaded : åŠ è½½æˆåŠŸ
Loaded --> Executing : ç»§ç»­æ‰§è¡Œ
Executing --> Saving : ç»§ç»­ä¿å­˜
Saved --> Deleting : æ¸…ç†æ£€æŸ¥ç‚¹
Deleting --> [*] : åˆ é™¤å®Œæˆ
```

### æ¢å¤æœºåˆ¶å®ç°

#### è‡ªåŠ¨æ¢å¤æµç¨‹
1. **ä»»åŠ¡å¯åŠ¨**ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„æ£€æŸ¥ç‚¹
2. **çŠ¶æ€åŠ è½½**ï¼šä»æ£€æŸ¥ç‚¹æ¢å¤å®Œæ•´çŠ¶æ€
3. **ç»§ç»­æ‰§è¡Œ**ï¼šä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œ
4. **çŠ¶æ€æ›´æ–°**ï¼šå®šæœŸä¿å­˜æ–°çš„æ£€æŸ¥ç‚¹

#### æ‰‹åŠ¨æ¢å¤ç¤ºä¾‹

```python
# æ£€æŸ¥ç‚¹ç®¡ç†å™¨ä½¿ç”¨ç¤ºä¾‹
manager = CheckpointManager(get_checkpointer())

# ä¿å­˜æ£€æŸ¥ç‚¹
await manager.save_checkpoint(
    task_id="task_12345",
    state=current_state,
    metadata={"step": "batch_planning"}
)

# åŠ è½½æ£€æŸ¥ç‚¹
loaded_state = await manager.load_checkpoint("task_12345")

# åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
checkpoints = await manager.list_checkpoints("task_12345")

# åˆ é™¤æ£€æŸ¥ç‚¹
await manager.delete_checkpoint("task_12345")
```

**ç« èŠ‚æ¥æº**
- [checkpointer.py](file://ai_correction/functions/langgraph/checkpointer.py#L23-L246)

## æ€§èƒ½ç›‘æ§ä¸è¶…æ—¶å¤„ç†

ç³»ç»Ÿæä¾›äº†å…¨é¢çš„æ€§èƒ½ç›‘æ§å’Œè¶…æ—¶å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿æ‰¹æ”¹ä»»åŠ¡åœ¨åˆç†æ—¶é—´å†…å®Œæˆã€‚

### æ€§èƒ½ç›‘æ§ä½“ç³»

```mermaid
graph TB
subgraph "ç›‘æ§ç»´åº¦"
A[æ‰§è¡Œæ—¶é—´ç›‘æ§] --> B[Tokenä½¿ç”¨ç›‘æ§]
B --> C[å†…å­˜ä½¿ç”¨ç›‘æ§]
C --> D[å¹¶å‘åº¦ç›‘æ§]
end
subgraph "ç›‘æ§æŒ‡æ ‡"
E[å¤„ç†æ—¶é—´] --> F[ååé‡]
F --> G[é”™è¯¯ç‡]
G --> H[èµ„æºåˆ©ç”¨ç‡]
end
subgraph "å‘Šè­¦æœºåˆ¶"
I[é˜ˆå€¼å‘Šè­¦] --> J[è¶‹åŠ¿åˆ†æ]
J --> K[è‡ªåŠ¨æ‰©å®¹]
end
A --> E
B --> F
C --> G
D --> H
```

### è¶…æ—¶å¤„ç†ç­–ç•¥

#### 1. ä»»åŠ¡çº§åˆ«è¶…æ—¶
```python
import asyncio

async def execute_with_timeout(workflow, state, timeout=3600):
    """å¸¦è¶…æ—¶çš„æ‰§è¡Œ"""
    try:
        return await asyncio.wait_for(
            workflow.execute(state),
            timeout=timeout  # 1å°æ—¶è¶…æ—¶
        )
    except asyncio.TimeoutError:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼Œä»»åŠ¡ID: {state.get('task_id')}")
        state['errors'].append({
            'step': 'timeout',
            'error': f'æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)',
            'timestamp': str(datetime.now())
        })
        return state
```

#### 2. Agentçº§åˆ«è¶…æ—¶
```python
async def execute_with_agent_timeout(agent, state, timeout=300):
    """å•ä¸ªAgentçš„è¶…æ—¶æ§åˆ¶"""
    try:
        return await asyncio.wait_for(agent(state), timeout=timeout)
    except asyncio.TimeoutError:
        logger.warning(f"Agentæ‰§è¡Œè¶…æ—¶: {agent.__name__}")
        state['errors'].append({
            'step': agent.__name__,
            'error': f'Agentæ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)',
            'timestamp': str(datetime.now())
        })
        return state
```

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. Tokenä¼˜åŒ–
ç³»ç»Ÿå®ç°äº†å¤šç§Tokenä¼˜åŒ–æŠ€æœ¯ï¼š

```python
# çŠ¶æ€å‹ç¼© - å‡å°‘ä¸å¿…è¦çš„å­—æ®µ
def compress_state_for_scoring(state: GradingState) -> GradingState:
    """å‹ç¼©çŠ¶æ€ä»¥å‡å°‘Tokenä½¿ç”¨"""
    compressed_state = state.copy()
    
    # åªä¿ç•™è¯„åˆ†å¿…éœ€çš„å­—æ®µ
    essential_fields = [
        'task_id', 'user_id', 'mode', 'strictness_level', 'language',
        'question_files', 'answer_files', 'marking_files',
        'rubric_data', 'scoring_criteria'
    ]
    
    # æˆªæ–­é•¿æ–‡æœ¬å†…å®¹
    if 'ocr_results' in compressed_state:
        for key, content in compressed_state['ocr_results'].items():
            if isinstance(content, str) and len(content) > 1000:
                compressed_state['ocr_results'][key] = content[:1000] + "...[æˆªæ–­]"
    
    return compressed_state
```

#### 2. å¹¶è¡Œå¤„ç†ä¼˜åŒ–
```python
# å¹¶è¡Œæ‰¹æ¬¡å¤„ç†
async def process_batches_in_parallel(batches, worker_func):
    """å¹¶è¡Œå¤„ç†å¤šä¸ªæ‰¹æ¬¡"""
    tasks = []
    for batch in batches:
        task = asyncio.create_task(worker_func(batch))
        tasks.append(task)
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†å¼‚å¸¸ç»“æœ
    successful_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"æ‰¹æ¬¡{i}å¤„ç†å¤±è´¥: {result}")
        else:
            successful_results.append(result)
    
    return successful_results
```

#### 3. ç¼“å­˜æœºåˆ¶
```python
# OCRç»“æœç¼“å­˜
@lru_cache(maxsize=100)
def cached_ocr_processing(file_path: str) -> Dict:
    """ç¼“å­˜OCRå¤„ç†ç»“æœ"""
    # å®é™…çš„OCRå¤„ç†é€»è¾‘
    pass

# æ–‡ä»¶å“ˆå¸Œç¼“å­˜
_file_hash_cache = {}

def get_file_hash(file_path: str) -> str:
    """è·å–æ–‡ä»¶å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
    if file_path not in _file_hash_cache:
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        _file_hash_cache[file_path] = calculate_hash(file_path)
    return _file_hash_cache[file_path]
```

**ç« èŠ‚æ¥æº**
- [workflow.py](file://ai_correction/functions/langgraph/workflow.py#L221-L238)
- [workflow.py](file://ai_correction/functions/langgraph/workflow.py#L240-L246)

## è°ƒç”¨é“¾åˆ†æ

ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„è°ƒç”¨é“¾åˆ†æèƒ½åŠ›ï¼Œä»å¤–éƒ¨è°ƒç”¨åˆ°å†…éƒ¨æ‰§è¡Œçš„å…¨è¿‡ç¨‹è¿½è¸ªã€‚

### å¤–éƒ¨è°ƒç”¨å…¥å£

```mermaid
sequenceDiagram
participant API as APIå±‚
participant Service as æœåŠ¡å±‚
participant Workflow as å·¥ä½œæµ
participant Monitor as ç›‘æ§å™¨
participant Storage as å­˜å‚¨
API->>Service : è¯·æ±‚æ‰¹æ”¹ä»»åŠ¡
Service->>Service : éªŒè¯è¯·æ±‚å‚æ•°
Service->>Workflow : åˆ›å»ºåˆå§‹çŠ¶æ€
Service->>Monitor : åˆ›å»ºè¿›åº¦ç›‘æ§
Service->>Workflow : æ‰§è¡Œå·¥ä½œæµ
loop æµå¼æ‰§è¡Œ
Workflow->>Monitor : çŠ¶æ€æ›´æ–°
Monitor->>API : æ¨é€è¿›åº¦
end
Workflow->>Storage : ä¿å­˜æœ€ç»ˆçŠ¶æ€
Workflow->>Service : è¿”å›ç»“æœ
Service->>API : è¿”å›å“åº”
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L267-L373)

### run_multimodal_grading ä¾¿æ·å‡½æ•°

`run_multimodal_grading` æ˜¯ç³»ç»Ÿçš„ä¸»è¦å¤–éƒ¨å…¥å£ï¼Œæä¾›äº†ç®€æ´çš„APIæ¥å£ï¼š

#### å‡½æ•°ç­¾å
```python
async def run_multimodal_grading(
    task_id: str,
    user_id: str,
    question_files: list,
    answer_files: list,
    marking_files: list,
    strictness_level: str = "ä¸­ç­‰",
    language: str = "zh"
) -> Dict[str, Any]:
```

#### å‚æ•°è¯´æ˜
- **task_id**ï¼šå”¯ä¸€ä»»åŠ¡æ ‡è¯†ç¬¦
- **user_id**ï¼šç”¨æˆ·æ ‡è¯†ç¬¦
- **question_files**ï¼šé¢˜ç›®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
- **answer_files**ï¼šç­”æ¡ˆæ–‡ä»¶è·¯å¾„åˆ—è¡¨
- **marking_files**ï¼šè¯„åˆ†æ ‡å‡†æ–‡ä»¶è·¯å¾„åˆ—è¡¨
- **strictness_level**ï¼šæ‰¹æ”¹ä¸¥æ ¼ç¨‹åº¦
- **language**ï¼šå¤„ç†è¯­è¨€

#### æ‰§è¡Œæµç¨‹

```mermaid
flowchart TD
A[run_multimodal_gradingè°ƒç”¨] --> B[åˆ›å»ºåˆå§‹çŠ¶æ€]
B --> C[å¡«å……åŸºç¡€å­—æ®µ]
C --> D[å¡«å……æ–‡ä»¶ä¿¡æ¯]
D --> E[è®¾ç½®æ‰¹æ”¹å‚æ•°]
E --> F[åˆå§‹åŒ–ç©ºå­—æ®µ]
F --> G[è·å–å·¥ä½œæµå®ä¾‹]
G --> H[è°ƒç”¨executeæ–¹æ³•]
H --> I[ç­‰å¾…æ‰§è¡Œå®Œæˆ]
I --> J[æ•´ç†è¿”å›ç»“æœ]
J --> K[è¿”å›æ‰¹æ”¹ç»“æœ]
subgraph "è¿”å›ç»“æœç»“æ„"
L[task_id] --> M[status]
M --> N[total_score]
N --> O[grade_level]
O --> P[detailed_feedback]
P --> Q[criteria_evaluations]
Q --> R[errors]
R --> S[warnings]
end
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L267-L373)

### å†…éƒ¨æ‰§è¡Œè°ƒç”¨é“¾

#### 1. å·¥ä½œæµæ„å»ºé˜¶æ®µ
```python
# 1. åˆ›å»ºå·¥ä½œæµå®ä¾‹
workflow = MultiModalGradingWorkflow()

# 2. æ„å»ºçŠ¶æ€å›¾
workflow._build_workflow()

# 3. æ³¨å†ŒAgentèŠ‚ç‚¹
workflow.graph.add_node("orchestrator", OrchestratorAgent())
workflow.graph.add_node("multimodal_input", MultiModalInputAgent())
# ... å…¶ä»–èŠ‚ç‚¹

# 4. è®¾ç½®æ‰§è¡Œè·¯å¾„
workflow.graph.set_entry_point("orchestrator")
workflow.graph.add_edge("orchestrator", "multimodal_input")
# ... è·¯å¾„é…ç½®
```

#### 2. æ‰§è¡Œé˜¶æ®µè°ƒç”¨é“¾
```mermaid
sequenceDiagram
participant Main as ä¸»ç¨‹åº
participant Workflow as MultiModalGradingWorkflow
participant Graph as StateGraph
participant Orchestrator as OrchestratorAgent
participant Input as MultiModalInputAgent
participant Others as å…¶ä»–Agents
Main->>Workflow : execute(initial_state)
Workflow->>Graph : astream(initial_state, config)
loop æµå¼æ‰§è¡Œ
Graph->>Orchestrator : æ‰§è¡Œç¼–æ’
Orchestrator->>Input : å¤„ç†å¤šæ¨¡æ€è¾“å…¥
Input->>Others : å¹¶è¡Œç†è§£ä»»åŠ¡
Others->>Graph : çŠ¶æ€æ›´æ–°
end
Graph->>Workflow : æœ€ç»ˆçŠ¶æ€
Workflow->>Main : è¿”å›ç»“æœ
```

**å›¾è¡¨æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L131-L216)

### è°ƒç”¨é“¾ç›‘æ§

ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„è°ƒç”¨é“¾ç›‘æ§èƒ½åŠ›ï¼š

#### 1. è°ƒç”¨é“¾è¿½è¸ª
```python
# è°ƒç”¨é“¾è¿½è¸ªè£…é¥°å™¨
def trace_execution(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        task_id = kwargs.get('task_id', 'unknown')
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
        
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {duration:.2f}ç§’, é”™è¯¯: {e}")
            raise
    
    return wrapper
```

#### 2. æ€§èƒ½åˆ†æ
```python
# æ€§èƒ½åˆ†æå·¥å…·
class PerformanceAnalyzer:
    def __init__(self):
        self.execution_times = {}
        self.memory_usage = {}
    
    def record_start(self, task_id: str, step: str):
        """è®°å½•æ­¥éª¤å¼€å§‹æ—¶é—´"""
        key = f"{task_id}_{step}"
        self.execution_times[key] = time.time()
    
    def record_end(self, task_id: str, step: str):
        """è®°å½•æ­¥éª¤ç»“æŸæ—¶é—´å’Œå†…å­˜ä½¿ç”¨"""
        key = f"{task_id}_{step}"
        if key in self.execution_times:
            duration = time.time() - self.execution_times[key]
            memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            logger.info(f"æ­¥éª¤ {step} å®Œæˆï¼Œè€—æ—¶: {duration:.2f}s, å†…å­˜: {memory:.2f}MB")
```

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L267-L373)

## æœ€ä½³å®è·µæŒ‡å—

åŸºäºå¯¹ç³»ç»Ÿçš„æ·±å…¥åˆ†æï¼Œä»¥ä¸‹æ˜¯ä½¿ç”¨ MultiModalGradingWorkflow çš„æœ€ä½³å®è·µæŒ‡å—ã€‚

### 1. çŠ¶æ€åˆå§‹åŒ–æœ€ä½³å®è·µ

#### å®Œæ•´çŠ¶æ€åˆå§‹åŒ–æ¨¡æ¿
```python
def create_initial_state(
    task_id: str,
    user_id: str,
    question_files: List[str],
    answer_files: List[str],
    marking_files: List[str],
    **kwargs
) -> GradingState:
    """åˆ›å»ºå®Œæ•´çš„åˆå§‹çŠ¶æ€"""
    return GradingState(
        task_id=task_id,
        user_id=user_id,
        assignment_id=f"assignment_{task_id}",
        timestamp=datetime.now(),
        question_files=question_files,
        answer_files=answer_files,
        marking_files=marking_files,
        images=[],  # å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
        strictness_level=kwargs.get('strictness_level', 'ä¸­ç­‰'),
        language=kwargs.get('language', 'zh'),
        mode=kwargs.get('mode', 'efficient'),
        
        # å¤šæ¨¡æ€å­—æ®µ
        question_multimodal_files=[],
        answer_multimodal_files=[],
        marking_multimodal_files=[],
        question_understanding=None,
        answer_understanding=None,
        rubric_understanding=None,
        criteria_evaluations=[],
        
        # æ·±åº¦åä½œå­—æ®µ
        students_info=[],
        batches_info=[],
        batch_rubric_packages={},
        question_context_packages={},
        grading_results=[],
        student_reports=[],
        class_analysis={},
        
        # å¤„ç†çŠ¶æ€
        current_step="åˆå§‹åŒ–",
        progress_percentage=0.0,
        completion_status="pending",
        completed_at="",
        
        # é”™è¯¯å’Œè­¦å‘Š
        errors=[],
        warnings=[],
        step_results={},
        
        # ç»“æœå­—æ®µ
        total_score=0.0,
        section_scores={},
        final_score=0.0,
        grade_level="",
        processing_time=0.0,
        model_versions={},
        quality_metrics={}
    )
```

### 2. å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

#### åˆ†å±‚å¼‚å¸¸å¤„ç†ç­–ç•¥
```python
class GradingWorkflowException(Exception):
    """æ‰¹æ”¹å·¥ä½œæµå¼‚å¸¸åŸºç±»"""
    def __init__(self, step: str, error: str, task_id: str = None):
        self.step = step
        self.error = error
        self.task_id = task_id
        super().__init__(f"[{step}] {error}")

async def robust_workflow_execution(
    workflow: MultiModalGradingWorkflow,
    state: GradingState,
    max_retries: int = 3
) -> GradingState:
    """å¥å£®çš„å·¥ä½œæµæ‰§è¡Œ"""
    for attempt in range(max_retries):
        try:
            # åˆ›å»ºè¿›åº¦ç›‘æ§
            monitor = ProgressMonitor()
            runner = StreamingWorkflowRunner(workflow.graph, monitor)
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = await runner.run_with_progress(state)
            
            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if result.get('completion_status') == 'completed':
                return result
            elif result.get('completion_status') == 'failed':
                raise GradingWorkflowException(
                    step=result.get('current_step', 'unknown'),
                    error=str(result.get('errors', [])),
                    task_id=state.get('task_id')
                )
                
        except GradingWorkflowException as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                # ç­‰å¾…é‡è¯•
                await asyncio.sleep(2 ** attempt)
                continue
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•è¯¦ç»†é”™è¯¯
                state['errors'].append({
                    'step': e.step,
                    'error': e.error,
                    'task_id': e.task_id,
                    'timestamp': str(datetime.now())
                })
                return state
                
        except Exception as e:
            logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
            state['errors'].append({
                'step': 'unknown',
                'error': str(e),
                'timestamp': str(datetime.now())
            })
            return state
```

### 3. æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

#### 1. å¹¶è¡Œå¤„ç†ä¼˜åŒ–
```python
async def parallel_batch_processing(
    workflow: MultiModalGradingWorkflow,
    batches: List[Dict],
    batch_size: int = 5
) -> List[Dict]:
    """æ‰¹é‡å¹¶è¡Œå¤„ç†ä¼˜åŒ–"""
    
    # åˆ†ç»„å¤„ç†
    batch_groups = [
        batches[i:i + batch_size] 
        for i in range(0, len(batches), batch_size)
    ]
    
    all_results = []
    
    for group in batch_groups:
        # å¹¶è¡Œå¤„ç†å½“å‰ç»„
        tasks = []
        for batch in group:
            task_state = create_initial_state(
                task_id=f"batch_{batch['batch_index']}",
                user_id="parallel_user",
                question_files=batch['question_files'],
                answer_files=batch['answer_files'],
                marking_files=batch['marking_files']
            )
            tasks.append(workflow.execute(task_state))
        
        # ç­‰å¾…ç»„å†…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        group_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        for i, result in enumerate(group_results):
            if isinstance(result, Exception):
                logger.error(f"æ‰¹æ¬¡ {group[i]['batch_index']} å¤„ç†å¤±è´¥: {result}")
            else:
                all_results.append(result)
    
    return all_results
```

#### 2. ç¼“å­˜ç­–ç•¥
```python
class GradingCache:
    """æ‰¹æ”¹ç»“æœç¼“å­˜"""
    def __init__(self):
        self.cache = {}
        self.cache_lock = asyncio.Lock()
    
    async def get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜ç»“æœ"""
        async with self.cache_lock:
            if cache_key in self.cache:
                result = self.cache[cache_key]
                logger.info(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
                return result
        return None
    
    async def set_cached_result(self, cache_key: str, result: Dict):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        async with self.cache_lock:
            self.cache[cache_key] = result
            logger.info(f"ç¼“å­˜è®¾ç½®: {cache_key}")
    
    def generate_cache_key(self, state: GradingState) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        file_keys = []
        for file_list in [state['question_files'], state['answer_files'], state['marking_files']]:
            file_keys.extend([Path(f).name for f in file_list])
        
        return f"grading_{hash(tuple(sorted(file_keys)))}"

# ä½¿ç”¨ç¤ºä¾‹
cache = GradingCache()

async def cached_workflow_execution(workflow, state):
    cache_key = cache.generate_cache_key(state)
    cached_result = await cache.get_cached_result(cache_key)
    
    if cached_result:
        return cached_result
    
    result = await workflow.execute(state)
    await cache.set_cached_result(cache_key, result)
    return result
```

### 4. ç›‘æ§å’Œè°ƒè¯•æœ€ä½³å®è·µ

#### 1. å®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ
```python
class GradingWorkflowMonitor:
    """æ‰¹æ”¹å·¥ä½œæµç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.metrics = {
            'execution_times': {},
            'success_rates': {},
            'error_counts': {},
            'resource_usage': {}
        }
    
    def record_execution_time(self, task_id: str, step: str, duration: float):
        """è®°å½•æ‰§è¡Œæ—¶é—´"""
        key = f"{task_id}_{step}"
        self.metrics['execution_times'][key] = duration
    
    def record_success_rate(self, task_id: str, success: bool):
        """è®°å½•æˆåŠŸç‡"""
        if success:
            self.metrics['success_rates'][task_id] = self.metrics.get('success_rates', {}).get(task_id, 0) + 1
        else:
            self.metrics['success_rates'][task_id] = 0
    
    def record_error(self, task_id: str, error_type: str):
        """è®°å½•é”™è¯¯"""
        if task_id not in self.metrics['error_counts']:
            self.metrics['error_counts'][task_id] = {}
        self.metrics['error_counts'][task_id][error_type] = \
            self.metrics['error_counts'][task_id].get(error_type, 0) + 1
    
    def get_dashboard_data(self) -> Dict:
        """è·å–ç›‘æ§ä»ªè¡¨æ¿æ•°æ®"""
        return {
            'metrics': self.metrics,
            'active_tasks': len(self.metrics['execution_times']),
            'average_execution_time': sum(self.metrics['execution_times'].values()) / len(self.metrics['execution_times']) if self.metrics['execution_times'] else 0,
            'overall_success_rate': sum(v > 0 for v in self.metrics['success_rates'].values()) / len(self.metrics['success_rates']) if self.metrics['success_rates'] else 0
        }
```

#### 2. è°ƒè¯•å·¥å…·
```python
class GradingDebugger:
    """æ‰¹æ”¹å·¥ä½œæµè°ƒè¯•å·¥å…·"""
    
    def __init__(self):
        self.debug_log = []
    
    def log_state_change(self, task_id: str, old_state: Dict, new_state: Dict):
        """è®°å½•çŠ¶æ€å˜åŒ–"""
        changes = {}
        for key in set(old_state.keys()) | set(new_state.keys()):
            if old_state.get(key) != new_state.get(key):
                changes[key] = {
                    'old': old_state.get(key),
                    'new': new_state.get(key)
                }
        
        if changes:
            self.debug_log.append({
                'task_id': task_id,
                'changes': changes,
                'timestamp': str(datetime.now())
            })
    
    def export_debug_info(self, filename: str):
        """å¯¼å‡ºè°ƒè¯•ä¿¡æ¯"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.debug_log, f, indent=2, ensure_ascii=False)
    
    def analyze_performance(self) -> Dict:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        slow_steps = sorted(
            [(k, v) for k, v in self.metrics['execution_times'].items() if v > 10.0],
            key=lambda x: x[1],
            reverse=True
        )
        
        return {
            'slow_steps': slow_steps[:10],  # æœ€æ…¢çš„10ä¸ªæ­¥éª¤
            'total_steps': len(self.metrics['execution_times']),
            'average_time': sum(self.metrics['execution_times'].values()) / len(self.metrics['execution_times']) if self.metrics['execution_times'] else 0
        }
```

### 5. éƒ¨ç½²å’Œè¿ç»´æœ€ä½³å®è·µ

#### 1. ç¯å¢ƒé…ç½®
```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
PRODUCTION_CONFIG = {
    'environment': 'production',
    'checkpointer': 'postgres',
    'max_concurrent_tasks': 10,
    'timeout_seconds': 3600,
    'enable_monitoring': True,
    'log_level': 'INFO'
}

# å¼€å‘ç¯å¢ƒé…ç½®
DEVELOPMENT_CONFIG = {
    'environment': 'development',
    'checkpointer': 'memory',
    'max_concurrent_tasks': 1,
    'timeout_seconds': 1800,
    'enable_monitoring': True,
    'log_level': 'DEBUG'
}
```

#### 2. å¥åº·æ£€æŸ¥
```python
class HealthChecker:
    """å¥åº·æ£€æŸ¥æœåŠ¡"""
    
    def __init__(self, workflow: MultiModalGradingWorkflow):
        self.workflow = workflow
        self.health_status = {
            'workflow_ready': False,
            'checkpointer_available': False,
            'memory_available': True,
            'last_check': None
        }
    
    async def check_health(self) -> Dict:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å°±ç»ª
            self.health_status['workflow_ready'] = self.workflow.graph is not None
            
            # æ£€æŸ¥æ£€æŸ¥ç‚¹å­˜å‚¨
            try:
                test_state = GradingState(
                    task_id='health_check',
                    user_id='system',
                    assignment_id='health_check',
                    timestamp=datetime.now(),
                    question_files=[],
                    answer_files=[],
                    marking_files=[],
                    images=[],
                    strictness_level='ä¸­ç­‰',
                    language='zh',
                    mode='efficient',
                    mm_tokens=[],
                    student_info={},
                    rubric_text='',
                    rubric_struct={},
                    rubric_data={},
                    scoring_criteria=[],
                    questions=[],
                    batches=[],
                    evaluations=[],
                    scoring_results={},
                    detailed_feedback=[],
                    annotations=[],
                    coordinate_annotations=[],
                    error_regions=[],
                    cropped_regions=[],
                    knowledge_points=[],
                    error_analysis={},
                    learning_suggestions=[],
                    difficulty_assessment={},
                    total_score=0.0,
                    section_scores={},
                    student_evaluation={},
                    class_evaluation={},
                    export_payload={},
                    final_report={},
                    export_data={},
                    visualization_data={},
                    current_step="å¥åº·æ£€æŸ¥",
                    progress_percentage=0.0,
                    completion_status="pending",
                    completed_at="",
                    errors=[],
                    warnings=[],
                    step_results={},
                    final_score=0.0,
                    grade_level="",
                    processing_time=0.0,
                    model_versions={},
                    quality_metrics={}
                )
                
                # æµ‹è¯•æ‰§è¡Œ
                result = await self.workflow.execute(test_state)
                self.health_status['checkpointer_available'] = result.get('completion_status') == 'completed'
                
            except Exception as e:
                logger.error(f"æ£€æŸ¥ç‚¹å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                self.health_status['checkpointer_available'] = False
            
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            mem_info = psutil.virtual_memory()
            self.health_status['memory_available'] = mem_info.percent < 80
            
            # æ›´æ–°æ£€æŸ¥æ—¶é—´
            self.health_status['last_check'] = str(datetime.now())
            
            return self.health_status
            
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'workflow_ready': False,
                'checkpointer_available': False,
                'memory_available': False,
                'last_check': str(datetime.now()),
                'error': str(e)
            }
```

é€šè¿‡éµå¾ªè¿™äº›æœ€ä½³å®è·µï¼Œå¼€å‘è€…å¯ä»¥å……åˆ†åˆ©ç”¨ MultiModalGradingWorkflow çš„å¼ºå¤§åŠŸèƒ½ï¼Œæ„å»ºç¨³å®šã€é«˜æ•ˆã€å¯ç›‘æ§çš„æ‰¹æ”¹ç³»ç»Ÿã€‚

**ç« èŠ‚æ¥æº**
- [workflow_multimodal.py](file://ai_correction/functions/langgraph/workflow_multimodal.py#L267-L373)
- [state.py](file://ai_correction/functions/langgraph/state.py#L44-L268)
- [checkpointer.py](file://ai_correction/functions/langgraph/checkpointer.py#L23-L246)
- [streaming.py](file://ai_correction/functions/langgraph/streaming.py#L47-L337)