"""ÊâπÈáèÊèê‰∫§ API Ë∑ØÁî± - ‰ΩøÁî® LangGraph Orchestrator

Ê≠£Á°ÆÁöÑÊû∂ÊûÑÔºö
1. ‰ΩøÁî® LangGraph Orchestrator ÂêØÂä®ÊâπÊîπÊµÅÁ®ã
2. ÈÄöËøá LangGraph ÁöÑÊµÅÂºè API ÂÆûÊó∂Êé®ÈÄÅËøõÂ∫¶
3. Âà©Áî® PostgreSQL Checkpointer ÂÆûÁé∞ÊåÅ‰πÖÂåñÂíåÊñ≠ÁÇπÊÅ¢Â§ç
"""

import uuid
import logging
import tempfile
import asyncio
import base64
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, WebSocket, WebSocketDisconnect, Depends
from starlette.websockets import WebSocketState
from pydantic import BaseModel, Field
import fitz
from PIL import Image
import os

from src.models.enums import SubmissionStatus
from src.orchestration.base import Orchestrator
from src.api.dependencies import get_orchestrator
from src.utils.image import to_jpeg_bytes, pil_to_jpeg_bytes
from src.db.sqlite import (
    save_grading_history, 
    save_student_result, 
    GradingHistory, 
    StudentGradingResult,
    update_homework_submission_status
)


logger = logging.getLogger(__name__)
router = APIRouter(prefix="/batch", tags=["ÊâπÈáèÊèê‰∫§"])

# Â≠òÂÇ®Ê¥ªË∑ÉÁöÑ WebSocket ËøûÊé•
active_connections: Dict[str, List[WebSocket]] = {}
# ÁºìÂ≠òÂõæÁâáÔºåÈÅøÂÖç images_ready Êó©‰∫é WebSocket ËøûÊé•ÂØºËá¥ÂâçÁ´Ø‰∏¢Â§±
batch_image_cache: Dict[str, Dict[str, dict]] = {}
DEBUG_LOG_PATH = os.getenv("GRADEOS_DEBUG_LOG_PATH")
TEACHER_MAX_ACTIVE_RUNS = int(os.getenv("TEACHER_MAX_ACTIVE_RUNS", "3"))
_TEACHER_SEMAPHORE_LOCK = asyncio.Lock()
_TEACHER_SEMAPHORES: Dict[str, asyncio.Semaphore] = {}


def _is_ws_connected(websocket: WebSocket) -> bool:
    return (
        websocket.client_state == WebSocketState.CONNECTED
        and websocket.application_state == WebSocketState.CONNECTED
    )


def _write_debug_log(payload: Dict[str, Any]) -> None:
    if not DEBUG_LOG_PATH:
        return
    try:
        Path(DEBUG_LOG_PATH).parent.mkdir(parents=True, exist_ok=True)
        with open(DEBUG_LOG_PATH, "a", encoding="utf-8") as log_file:
            log_file.write(json.dumps(payload, ensure_ascii=False) + "\n")
    except Exception as exc:
        logger.debug(f"Failed to write debug log: {exc}")


def _safe_to_jpeg_bytes(image_bytes: bytes, label: str) -> bytes:
    try:
        return to_jpeg_bytes(image_bytes)
    except Exception as exc:
        logger.warning(f"Failed to convert image to JPEG ({label}): {exc}")
        return image_bytes



def _normalize_teacher_key(teacher_id: Optional[str]) -> str:
    if teacher_id and teacher_id.strip():
        return teacher_id.strip()
    return "anonymous"


async def _get_teacher_semaphore(teacher_key: str) -> asyncio.Semaphore:
    async with _TEACHER_SEMAPHORE_LOCK:
        semaphore = _TEACHER_SEMAPHORES.get(teacher_key)
        if not semaphore:
            semaphore = asyncio.Semaphore(max(1, TEACHER_MAX_ACTIVE_RUNS))
            _TEACHER_SEMAPHORES[teacher_key] = semaphore
    return semaphore


class BatchSubmissionResponse(BaseModel):
    """ÊâπÈáèÊèê‰∫§ÂìçÂ∫î"""
    batch_id: str = Field(..., description="ÊâπÊ¨° ID")
    status: SubmissionStatus = Field(..., description="Áä∂ÊÄÅ")
    total_pages: int = Field(..., description="ÊÄªÈ°µÊï∞")
    estimated_completion_time: int = Field(..., description="È¢ÑËÆ°ÂÆåÊàêÊó∂Èó¥ÔºàÁßíÔºâ")


class BatchStatusResponse(BaseModel):
    """ÊâπÈáèÁä∂ÊÄÅÊü•ËØ¢ÂìçÂ∫î"""
    batch_id: str
    exam_id: str
    status: str
    total_students: int = Field(0, description="ËØÜÂà´Âà∞ÁöÑÂ≠¶ÁîüÊï∞")
    completed_students: int = Field(0, description="Â∑≤ÂÆåÊàêÊâπÊîπÁöÑÂ≠¶ÁîüÊï∞")
    unidentified_pages: int = Field(0, description="Êú™ËØÜÂà´Â≠¶ÁîüÁöÑÈ°µÊï∞")
    results: Optional[List[dict]] = Field(None, description="ÊâπÊîπÁªìÊûú")


class RubricReviewContextResponse(BaseModel):
    """ÂâçÁ´Ø rubric review ‰∏ä‰∏ãÊñá"""
    batch_id: str
    status: Optional[str] = None
    current_stage: Optional[str] = None
    parsed_rubric: Optional[dict] = None
    rubric_images: List[str] = []


class ResultsReviewContextResponse(BaseModel):
    """ÂâçÁ´Ø results review ‰∏ä‰∏ãÊñá"""
    batch_id: str
    status: Optional[str] = None
    current_stage: Optional[str] = None
    student_results: List[dict] = []
    answer_images: List[str] = []


def _pdf_to_images(pdf_path: str, dpi: int = 150) -> List[bytes]:
    """Â∞Ü PDF ËΩ¨Êç¢‰∏∫ÂõæÂÉèÂàóË°®"""
    pdf_doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(pdf_doc)):
        page = pdf_doc[page_num]
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        images.append(pil_to_jpeg_bytes(img))
    
    pdf_doc.close()
    return images


async def broadcast_progress(batch_id: str, message: dict):
    """ÂêëÊâÄÊúâËøûÊé•ÁöÑ WebSocket ÂÆ¢Êà∑Á´ØÂπøÊí≠ËøõÂ∫¶"""
    # #region agent log - ÂÅáËÆæJ: broadcast_progress Ë¢´Ë∞ÉÁî®
    msg_type = message.get("type", "unknown")
    if msg_type in ("images_ready", "rubric_images_ready", "review_required"):
        cached = batch_image_cache.setdefault(batch_id, {})
        cached[msg_type] = message
    if msg_type == "llm_stream_chunk":
        node_id = message.get("nodeId") or ""
        if node_id in ("rubric_parse", "rubric_review"):
            cached = batch_image_cache.setdefault(batch_id, {})
            stream_cache = cached.setdefault("llm_stream_cache", {})
            cache_key = f"{node_id}:{message.get('agentId') or 'all'}:{message.get('streamType') or 'output'}"
            existing = stream_cache.get(cache_key, {})
            chunk_data = message.get("chunk", "") or ""
            if isinstance(chunk_data, list):
                chunk_data = "".join([str(c) for c in chunk_data])
            else:
                chunk_data = str(chunk_data)
            
            existing_chunk = existing.get("chunk", "") or ""
            combined = existing_chunk + chunk_data
            max_chars = 12000
            if len(combined) > max_chars:
                combined = combined[-max_chars:]
            stream_cache[cache_key] = {
                **message,
                "chunk": combined,
            }
    if msg_type in ("review_completed", "workflow_completed"):
        cached = batch_image_cache.get(batch_id)
        if cached and "review_required" in cached:
            cached.pop("review_required", None)
        if cached and "llm_stream_cache" in cached:
            cached.pop("llm_stream_cache", None)
    if msg_type == "workflow_completed":
        import traceback as _tb_j
        stack = ''.join(_tb_j.format_stack()[-5:-1])  # Ëé∑ÂèñË∞ÉÁî®Ê†à
        _write_debug_log({
            "hypothesisId": "J",
            "location": "batch_langgraph.py:broadcast_progress",
            "message": "broadcast_progressÂèëÈÄÅworkflow_completed",
            "data": {
                "batch_id": batch_id,
                "results_count": len(message.get("results", [])),
                "stack_trace": stack[:500],
            },
            "timestamp": int(datetime.now().timestamp() * 1000),
            "sessionId": "debug-session",
        })
    # #endregion
    if batch_id in active_connections:
        disconnected = []
        for ws in active_connections[batch_id]:
            if not _is_ws_connected(ws):
                disconnected.append(ws)
                continue
            try:
                await ws.send_json(message)
            except Exception as e:
                logger.error(f"WebSocket ÂèëÈÄÅÂ§±Ë¥•: {e}")
                disconnected.append(ws)
        
        # ÁßªÈô§Êñ≠ÂºÄÁöÑËøûÊé•
        for ws in disconnected:
            if ws in active_connections[batch_id]:
                active_connections[batch_id].remove(ws)



async def _start_run_with_teacher_limit(
    *,
    teacher_key: str,
    batch_id: str,
    payload: Dict[str, Any],
    orchestrator: Orchestrator,
    class_id: Optional[str],
    homework_id: Optional[str],
    student_mapping: List[dict],
) -> Optional[str]:
    semaphore = await _get_teacher_semaphore(teacher_key)
    await semaphore.acquire()
    run_id: Optional[str] = None
    try:
        run_id = await orchestrator.start_run(
            graph_name="batch_grading",
            payload=payload,
            idempotency_key=batch_id
        )
        logger.info(
            f"LangGraph ??????? "
            f"batch_id={batch_id}, "
            f"run_id={run_id}"
        )
        asyncio.create_task(
            stream_langgraph_progress(
                batch_id=batch_id,
                run_id=run_id,
                orchestrator=orchestrator,
                class_id=class_id,
                homework_id=homework_id,
                student_mapping=student_mapping,
                teacher_key=teacher_key,
                teacher_semaphore=semaphore,
            )
        )
        return run_id
    except Exception as exc:
        logger.error(f"????????: {exc}", exc_info=True)
        semaphore.release()
        await broadcast_progress(batch_id, {
            "type": "workflow_update",
            "nodeId": "rubric_parse",
            "status": "failed",
            "message": "Queued run failed to start"
        })
        return None


@router.post("/submit", response_model=BatchSubmissionResponse)
async def submit_batch(
    exam_id: Optional[str] = Form(None, description="ËÄÉËØï ID"),
    rubrics: List[UploadFile] = File(default=[], description="ËØÑÂàÜÊ†áÂáÜ PDFÔºàÂèØÈÄâÔºâ"),
    files: List[UploadFile] = File(..., description="Â≠¶Áîü‰ΩúÁ≠î PDF"),
    api_key: Optional[str] = Form(None, description="LLM API Key"),
    teacher_id: Optional[str] = Form(None, description="?? ID"),
    auto_identify: bool = Form(True, description="ÊòØÂê¶Ëá™Âä®ËØÜÂà´Â≠¶ÁîüË∫´‰ªΩ"),
    student_boundaries: Optional[str] = Form(None, description="ÊâãÂä®ËÆæÁΩÆÁöÑÂ≠¶ÁîüËæπÁïå (JSON List of page indices)"),
    expected_students: Optional[int] = Form(None, description="È¢ÑÊúüÂ≠¶ÁîüÊï∞ÈáèÔºàÂº∫ÁÉàÂª∫ËÆÆÊèê‰æõÔºåÁî®‰∫éÊõ¥ÂáÜÁ°ÆÁöÑÂàÜÂâ≤Ôºâ"),
    # Êñ∞Â¢ûÔºöÁè≠Á∫ßÊâπÊîπ‰∏ä‰∏ãÊñá
    class_id: Optional[str] = Form(None, description="Áè≠Á∫ß IDÔºàÁî®‰∫éÊàêÁª©ÂÜôÂõûÔºâ"),
    homework_id: Optional[str] = Form(None, description="‰Ωú‰∏ö IDÔºàÁî®‰∫éÊàêÁª©ÂÜôÂõûÔºâ"),
    student_mapping_json: Optional[str] = Form(None, description="Â≠¶ÁîüÊò†Â∞Ñ JSON [{studentId, studentName, startIndex, endIndex}]"),
    enable_review: bool = Form(True, description="ÊòØÂê¶ÂêØÁî®‰∫∫Â∑•‰∫§‰∫í"),
    grading_mode: Optional[str] = Form(None, description="grading mode: standard/assist_teacher/assist_student/auto"),
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    ÊâπÈáèÊèê‰∫§ËØïÂç∑Âπ∂ËøõË°åÊâπÊîπÔºà‰ΩøÁî® LangGraph OrchestratorÔºâ
    
    Ê≠£Á°ÆÁöÑÊû∂ÊûÑÔºö
    1. ‰ΩøÁî® LangGraph Orchestrator ÂêØÂä® batch_grading Graph
    2. Graph Ëá™Âä®Â§ÑÁêÜÔºöËæπÁïåÊ£ÄÊµã ‚Üí Âπ∂Ë°åÊâπÊîπ ‚Üí ËÅöÂêà ‚Üí ÊåÅ‰πÖÂåñ ‚Üí ÈÄöÁü•
    3. ÈÄöËøá WebSocket ÂÆûÊó∂Êé®ÈÄÅ LangGraph ÁöÑÊâßË°åËøõÂ∫¶
    
    Args:
        exam_id: ËÄÉËØï ID
        rubrics: ËØÑÂàÜÊ†áÂáÜ PDF Êñá‰ª∂ÂàóË°®
        files: Â≠¶Áîü‰ΩúÁ≠î PDF Êñá‰ª∂ÂàóË°®
        api_key: LLM API Key
        auto_identify: ÊòØÂê¶ÂêØÁî®Ëá™Âä®Â≠¶ÁîüËØÜÂà´
        orchestrator: LangGraph OrchestratorÔºà‰æùËµñÊ≥®ÂÖ•Ôºâ
        
    Returns:
        BatchSubmissionResponse: ÊâπÊ¨°‰ø°ÊÅØ
    """
    # #region agent log - ÂÅáËÆæK: submit_batch Ë¢´Ë∞ÉÁî®
    _write_debug_log({
        "hypothesisId": "K",
        "location": "batch_langgraph.py:submit_batch:entry",
        "message": "submit_batchÁ´ØÁÇπË¢´Ë∞ÉÁî®",
        "data": {"files_count": len(files), "rubrics_count": len(rubrics)},
        "timestamp": int(datetime.now().timestamp() * 1000),
        "sessionId": "debug-session",
    })
    # #endregion
    # Ê£ÄÊü• orchestrator ÊòØÂê¶ÂèØÁî®
    if not orchestrator:
        raise HTTPException(
            status_code=503, 
            detail="ÊâπÊîπÊúçÂä°Êú™ÂàùÂßãÂåñÔºåËØ∑Á®çÂêéÈáçËØïÊàñÊ£ÄÊü•ÊúçÂä°ÈÖçÁΩÆ"
        )
    
    if not api_key:
        api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        raise HTTPException(
            status_code=400,
            detail="Êú™Êèê‰æõ API KeyÔºåËØ∑Âú®ËØ∑Ê±Ç‰∏≠Êèê‰æõÊàñÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè LLM_API_KEY/OPENROUTER_API_KEY"
        )


    
    # Ëß£ÊûêÂ≠¶ÁîüËæπÁïå
    parsed_boundaries = []
    if student_boundaries:
        try:
            logger.info(f"Êé•Êî∂Âà∞ÂéüÂßã student_boundaries: {student_boundaries} (type: {type(student_boundaries)})")
            import json
            parsed_boundaries = json.loads(student_boundaries)
            logger.info(f"Ëß£ÊûêÂêéÁöÑ manual_boundaries: {parsed_boundaries}")
        except Exception as e:
            logger.warning(f"Ëß£ÊûêÊâãÂä®Â≠¶ÁîüËæπÁïåÂ§±Ë¥•: {e}")

    if not exam_id:
        exam_id = str(uuid.uuid4())

    batch_id = str(uuid.uuid4())
    
    logger.info(
        f"Êî∂Âà∞ÊâπÈáèÊèê‰∫§ÔºàLangGraphÔºâ: "
        f"batch_id={batch_id}, "
        f"exam_id={exam_id}, "
        f"auto_identify={auto_identify}"
    )
    
    temp_dir = None
    try:
        # ÂàõÂª∫‰∏¥Êó∂ÁõÆÂΩï
        temp_dir = tempfile.mkdtemp()
        temp_path = Path(temp_dir)
        
        # === Â§ÑÁêÜÁ≠îÈ¢òÊñá‰ª∂ÔºàÊîØÊåÅÂõæÁâáÂàóË°®ÊàñÂçï‰∏™ PDFÔºâ===
        answer_images = []
        
        for idx, file in enumerate(files):
            file_name = file.filename or f"file_{idx}"
            content = await file.read()
            
            # Ê£ÄÊü•Êñá‰ª∂Á±ªÂûã
            if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.gif')):
                # ÂõæÁâáÊñá‰ª∂ÔºöÁõ¥Êé•‰ΩøÁî®ÂÜÖÂÆπ
                answer_images.append(_safe_to_jpeg_bytes(content, file_name))
                logger.debug(f"ËØªÂèñÂõæÁâáÊñá‰ª∂: {file_name}, Â§ßÂ∞è: {len(content)} bytes")
            elif file_name.lower().endswith('.pdf'):
                # PDF Êñá‰ª∂ÔºöËΩ¨Êç¢‰∏∫ÂõæÂÉè
                pdf_path = temp_path / f"answer_{idx}.pdf"
                with open(pdf_path, "wb") as f:
                    f.write(content)
                loop = asyncio.get_event_loop()
                pdf_images = await loop.run_in_executor(None, _pdf_to_images, str(pdf_path), 150)
                answer_images.extend(pdf_images)
                logger.info(f"PDF Êñá‰ª∂ {file_name} ËΩ¨Êç¢‰∏∫ {len(pdf_images)} È°µÂõæÁâá")
            elif file_name.lower().endswith('.txt'):
                # ÊñáÊú¨Êñá‰ª∂ÔºöÁõ¥Êé•‰ΩøÁî®ÂÜÖÂÆπ
                answer_images.append(content)
                logger.info(f"ÊñáÊú¨Êñá‰ª∂Â§ÑÁêÜÂÆåÊàê: {file_name}, ÂÜÖÂÆπÈïøÂ∫¶={len(content)}")
            else:
                # Â∞ùËØï‰Ωú‰∏∫ÂõæÁâáÂ§ÑÁêÜÔºàÂèØËÉΩÊ≤°ÊúâÊâ©Â±ïÂêçÔºâ
                answer_images.append(_safe_to_jpeg_bytes(content, file_name))
                logger.warning(f"Êú™Áü•Êñá‰ª∂Á±ªÂûã {file_name}ÔºåÂ∞ùËØï‰Ωú‰∏∫ÂõæÁâáÂ§ÑÁêÜ")
        
        total_pages = len(answer_images)
        logger.info(f"Á≠îÈ¢òÊñá‰ª∂Â§ÑÁêÜÂÆåÊàê: batch_id={batch_id}, ÊÄªÈ°µÊï∞={total_pages}")
        
        # === Â§ÑÁêÜËØÑÂàÜÊ†áÂáÜÔºàÂèØÈÄâÔºâ===
        # Convert images to base64 and cache them immediately
        # (Fix: Rubric images not displaying on frontend)
        if answer_images:
            try:
                base64_images = [base64.b64encode(img).decode('utf-8') for img in answer_images]
                
                # Cache for direct WebSocket connection
                batch_image_cache.setdefault(batch_id, {})["images_ready"] = {
                    "type": "images_ready",
                    "images": base64_images
                }
                
                # Broadcast (though no clients connected yet usually)
                await broadcast_progress(batch_id, {
                    "type": "images_ready",
                    "images": base64_images
                })
                logger.info(f"Â∑≤ÁºìÂ≠ò {len(base64_images)} Âº†ÂõæÁâáÁî®‰∫éÂâçÁ´ØÊòæÁ§∫")
            except Exception as e:
                logger.error(f"ÂõæÁâá Base64 ËΩ¨Êç¢Â§±Ë¥•: {e}")

        # === Â§ÑÁêÜËØÑÂàÜÊ†áÂáÜÔºàÂèØÈÄâÔºâ===
        rubric_images = []
        if rubrics and len(rubrics) > 0:
            for idx, rubric_file in enumerate(rubrics):
                rubric_name = rubric_file.filename or f"rubric_{idx}"
                rubric_content = await rubric_file.read()
                
                if rubric_name.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.gif')):
                    rubric_images.append(_safe_to_jpeg_bytes(rubric_content, rubric_name))
                elif rubric_name.lower().endswith('.pdf'):
                    rubric_path = temp_path / f"rubric_{idx}.pdf"
                    with open(rubric_path, "wb") as f:
                        f.write(rubric_content)
                    loop = asyncio.get_event_loop()
                    pdf_rubric_images = await loop.run_in_executor(None, _pdf_to_images, str(rubric_path), 150)
                    rubric_images.extend(pdf_rubric_images)
                else:
                    rubric_images.append(_safe_to_jpeg_bytes(rubric_content, rubric_name))
            
            logger.info(f"ËØÑÂàÜÊ†áÂáÜÂ§ÑÁêÜÂÆåÊàê: batch_id={batch_id}, ÊÄªÈ°µÊï∞={len(rubric_images)}")
            if rubric_images:
                try:
                    base64_rubric_images = [base64.b64encode(img).decode("utf-8") for img in rubric_images]
                    batch_image_cache.setdefault(batch_id, {})["rubric_images_ready"] = {
                        "type": "rubric_images_ready",
                        "images": base64_rubric_images
                    }
                    await broadcast_progress(batch_id, {
                        "type": "rubric_images_ready",
                        "images": base64_rubric_images
                    })
                    logger.info(f"Â∑≤ÁºìÂ≠ò {len(base64_rubric_images)} Âº†ËØÑÂàÜÊ†áÂáÜÂõæÁâáÁî®‰∫éÂâçÁ´ØÊòæÁ§∫")
                except Exception as e:
                    logger.error(f"ËØÑÂàÜÊ†áÂáÜ Base64 ËΩ¨Êç¢Â§±Ë¥•: {e}")
        else:
            logger.info(f"Êú™Êèê‰æõËØÑÂàÜÊ†áÂáÜÔºåÂ∞Ü‰ΩøÁî®ÈªòËÆ§ËØÑÂàÜ: batch_id={batch_id}")
        
        logger.info(
            f"Êñá‰ª∂Â§ÑÁêÜÂÆåÊàê: "
            f"batch_id={batch_id}, "
            f"rubric_pages={len(rubric_images)}, "
            f"answer_pages={total_pages}"
        )
        
        # üöÄ ‰ΩøÁî® LangGraph Orchestrator ÂêØÂä®ÊâπÊîπÊµÅÁ®ã
        
        # Ëß£ÊûêÂ≠¶ÁîüÊò†Â∞ÑÔºàÁè≠Á∫ßÊâπÊîπÊ®°ÂºèÔºâ
        student_mapping = []
        if student_mapping_json:
            try:
                import json
                student_mapping = json.loads(student_mapping_json)
                logger.info(f"Áè≠Á∫ßÊâπÊîπÊ®°Âºè: class_id={class_id}, homework_id={homework_id}, Â≠¶ÁîüÊï∞={len(student_mapping)}")
            except Exception as e:
                logger.warning(f"Ëß£ÊûêÂ≠¶ÁîüÊò†Â∞ÑÂ§±Ë¥•: {e}")
        
        payload = {
            "batch_id": batch_id,
            "exam_id": exam_id,
            "temp_dir": str(temp_path),  # ‰∏¥Êó∂ÁõÆÂΩïÔºàÁî®‰∫éÊ∏ÖÁêÜÔºâ
            "rubric_images": rubric_images,
            "answer_images": answer_images,
            "api_key": api_key,
            # Áè≠Á∫ßÊâπÊîπ‰∏ä‰∏ãÊñáÔºàÂèØÈÄâÔºâ
            "class_id": class_id,
            "homework_id": homework_id,
            "student_mapping": student_mapping,
            "inputs": {
                "rubric": "rubric_content",  # TODO: Ëß£Êûê rubric
                "auto_identify": auto_identify,
                "manual_boundaries": parsed_boundaries,  # ‰º†ÈÄí‰∫∫Â∑•ËæπÁïå
                "expected_students": expected_students if expected_students else 2,  # üî• ÈªòËÆ§ 2 ÂêçÂ≠¶Áîü
                "enable_review": enable_review,
                "grading_mode": grading_mode or "auto",
            }
        }
        
        # ÂêØÂä® LangGraph batch_grading Graph
        teacher_key = _normalize_teacher_key(teacher_id)
        teacher_semaphore = await _get_teacher_semaphore(teacher_key)
        if teacher_semaphore.locked():
            await broadcast_progress(batch_id, {
                "type": "workflow_update",
                "nodeId": "rubric_parse",
                "status": "pending",
                "message": "Queued: waiting for teacher slot"
            })
        asyncio.create_task(
            _start_run_with_teacher_limit(
                teacher_key=teacher_key,
                batch_id=batch_id,
                payload=payload,
                orchestrator=orchestrator,
                class_id=class_id,
                homework_id=homework_id,
                student_mapping=student_mapping,
            )
        )

        return BatchSubmissionResponse(
            batch_id=batch_id,
            status=SubmissionStatus.UPLOADED,
            total_pages=total_pages,
            estimated_completion_time=total_pages * 3  # Estimated: 3s per page
        )
        
    except Exception as e:
        logger.error(f"ÊâπÈáèÊèê‰∫§Â§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ÊâπÈáèÊèê‰∫§Â§±Ë¥•: {str(e)}")


async def stream_langgraph_progress(
    batch_id: str,
    run_id: str,
    orchestrator: Orchestrator,
    class_id: Optional[str] = None,
    homework_id: Optional[str] = None,
    student_mapping: Optional[List[dict]] = None,
    teacher_key: Optional[str] = None,
    teacher_semaphore: Optional[asyncio.Semaphore] = None
):
    """
    ÊµÅÂºèÁõëÂê¨ LangGraph ÊâßË°åËøõÂ∫¶Âπ∂Êé®ÈÄÅÂà∞ WebSocket
    
    ËøôÊòØÂÆûÁé∞ÂÆûÊó∂ËøõÂ∫¶Êé®ÈÄÅÁöÑÂÖ≥ÈîÆÂáΩÊï∞ÔºÅ
    
    Args:
        batch_id: ÊâπÊ¨° ID
        run_id: LangGraph ËøêË°å ID
        orchestrator: LangGraph Orchestrator
    """
    # #region agent log - ÂÅáËÆæG: stream_langgraph_progress ÂÖ•Âè£
    _write_debug_log({
        "hypothesisId": "G",
        "location": "batch_langgraph.py:stream_langgraph_progress:entry",
        "message": "stream_langgraph_progressÂáΩÊï∞Ë¢´Ë∞ÉÁî®",
        "data": {"batch_id": batch_id, "run_id": run_id},
        "timestamp": int(datetime.now().timestamp() * 1000),
        "sessionId": "debug-session",
    })
    # #endregion
    logger.info(f"ÂºÄÂßãÊµÅÂºèÁõëÂê¨ LangGraph ËøõÂ∫¶: batch_id={batch_id}, run_id={run_id}")
    
    try:
        # üî• ‰ΩøÁî® LangGraph ÁöÑÊµÅÂºè API
        async for event in orchestrator.stream_run(run_id):
            event_type = event.get("type")
            node_name = event.get("node")
            data = event.get("data", {})
            
            logger.debug(
                f"LangGraph ‰∫ã‰ª∂: "
                f"batch_id={batch_id}, "
                f"type={event_type}, "
                f"node={node_name}"
            )
            
            # Â∞Ü LangGraph ‰∫ã‰ª∂ËΩ¨Êç¢‰∏∫ÂâçÁ´Ø WebSocket Ê∂àÊÅØ
            if event_type == "node_start":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "running",
                    "message": f"Running {_get_node_display_name(node_name)}..."
                })
            
            elif event_type == "node_end":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "completed",
                    "message": f"{_get_node_display_name(node_name)} completed"
                })
                
                # Â§ÑÁêÜËäÇÁÇπËæìÂá∫
                output = data.get("output", {})
                if isinstance(output, dict):
                    interrupt_payload = output.get("__interrupt__")
                    if interrupt_payload:
                        review_type = interrupt_payload.get("type") if isinstance(interrupt_payload, dict) else "review_required"
                        await broadcast_progress(batch_id, {
                            "type": "review_required",
                            "reviewType": review_type,
                            "payload": interrupt_payload,
                            "nodeId": _map_node_to_frontend("rubric_review") if "rubric" in review_type else _map_node_to_frontend("review"),
                        })
                    # ËØÑÂàÜÊ†áÂáÜËß£ÊûêÂÆåÊàê
                    if node_name == "rubric_parse" and output.get("parsed_rubric"):
                        parsed = output["parsed_rubric"]
                        await broadcast_progress(batch_id, {
                            "type": "rubric_parsed",
                            "totalQuestions": parsed.get("total_questions", 0),
                            "totalScore": parsed.get("total_score", 0),
                            "generalNotes": parsed.get("general_notes", ""),
                            "rubricFormat": parsed.get("rubric_format", ""),
                            "questions": [
                                {
                                    "questionId": q.get("question_id", ""),
                                    "maxScore": q.get("max_score", 0),
                                    "questionText": q.get("question_text", ""),
                                    "standardAnswer": q.get("standard_answer", ""),
                                    "gradingNotes": q.get("grading_notes", ""),
                                    "sourcePages": q.get("source_pages") or q.get("sourcePages") or [],
                                    "scoringPoints": [
                                        {
                                            "pointId": sp.get("point_id") or sp.get("pointId") or f"{q.get('question_id')}.{idx + 1}",
                                            "description": sp.get("description", ""),
                                            "expectedValue": sp.get("expected_value") or sp.get("expectedValue", ""),
                                            "keywords": sp.get("keywords") or [],
                                            "score": sp.get("score", 0),
                                            "isRequired": sp.get("is_required", True),
                                        }
                                        for idx, sp in enumerate(q.get("scoring_points", []))
                                    ],
                                    "deductionRules": [
                                        {
                                            "ruleId": dr.get("rule_id") or dr.get("ruleId") or f"{q.get('question_id')}.d{idx + 1}",
                                            "description": dr.get("description", ""),
                                            "deduction": dr.get("deduction", dr.get("score", 0)),
                                            "conditions": dr.get("conditions") or dr.get("when") or "",
                                        }
                                        for idx, dr in enumerate(q.get("deduction_rules") or q.get("deductionRules") or [])
                                    ],
                                    "alternativeSolutions": [
                                        {
                                            "description": alt.get("description", ""),
                                            "scoringCriteria": alt.get("scoring_criteria", ""),
                                            "note": alt.get("note", ""),
                                        }
                                        for alt in q.get("alternative_solutions", [])
                                    ]
                                }
                                for q in parsed.get("questions", [])
                            ]
                        })
                    
                    # ÊâπÊîπÊâπÊ¨°ÂÆåÊàê
                    if node_name == "grade_batch" and output.get("grading_results"):
                        results = output["grading_results"]
                        completed = sum(1 for r in results if r.get("status") == "completed")
                        
                        await broadcast_progress(batch_id, {
                            "type": "batch_complete",
                            "batchSize": len(results),
                            "successCount": completed,
                            "totalScore": sum(r.get("score", 0) for r in results if r.get("status") == "completed"),
                            "pages": [r.get("page_index") for r in results]
                        })
                    
                    # Á¥¢ÂºïÂÆåÊàêÔºàÂ≠¶ÁîüËØÜÂà´Ôºâ
                    if node_name == "index" and output.get("student_boundaries"):
                        boundaries = output["student_boundaries"]
                        await broadcast_progress(batch_id, {
                            "type": "students_identified",
                            "studentCount": len(boundaries),
                            "students": [
                                {
                                    "studentKey": b.get("student_key", ""),
                                    "startPage": b.get("start_page", 0),
                                    "endPage": b.get("end_page", 0),
                                    "confidence": b.get("confidence", 0),
                                    "needsConfirmation": b.get("needs_confirmation", False)
                                }
                                for b in boundaries
                            ]
                        })
                    
                    # ÂÆ°Ê†∏ÂÆåÊàê
                    if node_name == "review" and output.get("review_summary"):
                        await broadcast_progress(batch_id, {
                            "type": "review_completed",
                            "summary": output["review_summary"]
                        })
                    
                    # Ë∑®È°µÈ¢òÁõÆÂêàÂπ∂ÂÆåÊàê
                    if node_name == "cross_page_merge":
                        cross_page_questions = output.get("cross_page_questions", [])
                        merged_questions = output.get("merged_questions", [])
                        if cross_page_questions:
                            await broadcast_progress(batch_id, {
                                "type": "cross_page_detected",
                                "questions": cross_page_questions,
                                "mergedCount": len(merged_questions),
                                "crossPageCount": len(cross_page_questions)
                            })
            
            elif event_type == "paused":
                # Â§ÑÁêÜ Graph ‰∏≠Êñ≠/ÊöÇÂÅúÔºàÈÄöÂ∏∏ÊòØÈúÄË¶Å‰∫∫Â∑•ÂÆ°Ê†∏Ôºâ
                data = event.get("data", {})
                interrupt_value = data.get("interrupt_value")
                
                logger.info(f"LangGraph ÊöÇÂÅú: batch_id={batch_id}, interrupt_value={interrupt_value}")
                
                if interrupt_value:
                    # Â¶ÇÊûúÊúâ‰∏≠Êñ≠ payloadÔºåÂπøÊí≠ review_required
                    review_type = interrupt_value.get("type") if isinstance(interrupt_value, dict) else "review_required"
                    await broadcast_progress(batch_id, {
                        "type": "review_required",
                        "reviewType": review_type,
                        "payload": interrupt_value,
                        "nodeId": _map_node_to_frontend("rubric_review") if "rubric" in review_type else _map_node_to_frontend("review"),
                    })
                else:
                    # Â¶ÇÊûúÊ≤°Êúâ payloadÔºåËá≥Â∞ëÈÄöÁü•Áä∂ÊÄÅÂèòÊõ¥
                    await broadcast_progress(batch_id, {
                        "type": "workflow_update",
                        "status": "paused",
                        "message": "Workflow paused (awaiting input)"
                    })

            elif event_type == "state_update":
                # Êé®ÈÄÅÁä∂ÊÄÅÊõ¥Êñ∞
                state = data.get("state", {})
                
                # ÊâπÊ¨°ËøõÂ∫¶Êõ¥Êñ∞
                if state.get("progress"):
                    progress = state["progress"]
                    await broadcast_progress(batch_id, {
                        "type": "batch_progress",
                        "batchIndex": progress.get("current_batch", 0),
                        "totalBatches": progress.get("total_batches", 1),
                        "successCount": progress.get("success_count", 0),
                        "failureCount": progress.get("failure_count", 0)
                    })
                
                # ÁôæÂàÜÊØîËøõÂ∫¶
                if state.get("percentage"):
                    await broadcast_progress(batch_id, {
                        "type": "grading_progress",
                        "percentage": state["percentage"],
                        "currentStage": state.get("current_stage", "")
                    })
            
            elif event_type == "llm_stream":
                # Real-time LLM token streaming
                node_name = event.get("node") or data.get("node", "")
                chunk = data.get("chunk") or data.get("content") or ""
                await broadcast_progress(batch_id, {
                    "type": "llm_stream_chunk",
                    "nodeId": _map_node_to_frontend(node_name) if node_name else None,
                    "nodeName": _get_node_display_name(node_name) if node_name else None,
                    "chunk": chunk,
                })

            elif event_type == "error":
                await broadcast_progress(batch_id, {
                    "type": "workflow_error",
                    "message": data.get("error", "Unknown error")
                })
            
            elif event_type == "completed":
                # #region agent log - ÂÅáËÆæH: completed ‰∫ã‰ª∂
                _write_debug_log({
                    "hypothesisId": "H",
                    "location": "batch_langgraph.py:event_completed",
                    "message": "Êî∂Âà∞completed‰∫ã‰ª∂",
                    "data": {
                        "event_type": event_type,
                        "data_keys": list(data.keys()) if isinstance(data, dict) else str(type(data)),
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "sessionId": "debug-session",
                })
                # #endregion
                # Â∑•‰ΩúÊµÅÂÆåÊàê - Ëé∑ÂèñÂÆåÊï¥ÁöÑÊúÄÁªàÁä∂ÊÄÅ
                final_state = data.get("state", {})
                
                # ‰ªé student_results Ëé∑ÂèñÁªìÊûú
                student_results = final_state.get("student_results", [])
                
                # #region agent log - ÂÅáËÆæI: student_results ÂéüÂßãÊï∞ÊçÆ
                _write_debug_log({
                    "hypothesisId": "I",
                    "location": "batch_langgraph.py:student_results_raw",
                    "message": "student_resultsÂéüÂßãÊï∞ÊçÆ",
                    "data": {
                        "count": len(student_results),
                        "students": [{"key": r.get("student_key"), "score": r.get("total_score")} for r in student_results],
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "sessionId": "debug-session",
                })
                # #endregion
                
                # Â¶ÇÊûúÊ≤°Êúâ student_resultsÔºåÂ∞ùËØï‰ªé orchestrator Ëé∑ÂèñÊúÄÁªàËæìÂá∫
                if not student_results:
                    try:
                        final_output = await orchestrator.get_final_output(run_id)
                        if final_output:
                            student_results = final_output.get("student_results", [])
                            logger.info(f"‰ªé orchestrator Ëé∑ÂèñÂà∞ {len(student_results)} ‰∏™Â≠¶ÁîüÁªìÊûú")
                    except Exception as e:
                        logger.warning(f"Ëé∑ÂèñÊúÄÁªàËæìÂá∫Â§±Ë¥•: {e}")
                
                formatted_results = _format_results_for_frontend(student_results)
                class_report = final_state.get("class_report")
                if not class_report and final_state.get("export_data"):
                    class_report = final_state.get("export_data", {}).get("class_report")
                
                # üöÄ Áè≠Á∫ßÊâπÊîπÊ®°ÂºèÔºö‰øùÂ≠òÊàêÁª©Âà∞Êï∞ÊçÆÂ∫ì
                if class_id and homework_id:
                    try:
                        logger.info(f"‰øùÂ≠òÁè≠Á∫ßÊâπÊîπÁªìÊûú: class_id={class_id}, homework_id={homework_id}")
                        
                        # 1. ‰øùÂ≠òÊâπÊîπÂéÜÂè≤
                        history_id = str(uuid.uuid4())
                        now = datetime.now().isoformat()
                        history = GradingHistory(
                            id=history_id,
                            batch_id=batch_id,
                            status="completed",
                            class_ids=[class_id],
                            created_at=now,
                            completed_at=now,
                            total_students=len(formatted_results),
                            average_score=class_report.get("average_score") if class_report else None,
                            result_data={
                                "summary": class_report,
                                "class_id": class_id,
                                "homework_id": homework_id,
                            } if class_report or class_id or homework_id else None,
                        )
                        save_grading_history(history)
                        
                        # 2. Êò†Â∞ÑÂ≠¶ÁîüÂπ∂‰øùÂ≠òÁªìÊûú
                        # student_mapping: [{studentId, studentName, startIndex, endIndex}]
                        # formatted_results: [{studentId, studentName, score, ...}] (studentId is generic 'student_1')
                        
                        student_map_lookup = {} # index -> student_info
                        if student_mapping:
                            for idx, mapping in enumerate(student_mapping):
                                student_map_lookup[idx] = mapping
                                
                        for idx, result in enumerate(formatted_results):
                            # Â∞ùËØïÂåπÈÖçÁúüÂÆûÂ≠¶Áîü
                            real_student = student_map_lookup.get(idx)
                            student_id = real_student["studentId"] if real_student else None
                            student_name = real_student["studentName"] if real_student else result.get("studentName")
                            
                            # ‰øùÂ≠òÂ≠¶ÁîüÁªìÊûú
                            student_summary = result.get("studentSummary") or result.get("student_summary") or {}
                            self_audit = result.get("selfAudit") or result.get("self_audit") or {}
                            student_result = StudentGradingResult(
                                id=str(uuid.uuid4()),
                                grading_history_id=history_id,
                                student_key=student_name or result.get("studentName") or f"Student {idx + 1}",
                                score=result.get("score"),
                                max_score=result.get("maxScore") or result.get("max_score"),
                                class_id=class_id,
                                student_id=student_id,
                                summary=student_summary.get("overall") if isinstance(student_summary, dict) else None,
                                self_report=self_audit.get("summary") if isinstance(self_audit, dict) else None,
                                result_data=result,
                            )
                            save_student_result(student_result)
                            
                            # Êõ¥Êñ∞‰Ωú‰∏öÊèê‰∫§Áä∂ÊÄÅ
                            if student_id:
                                update_homework_submission_status(
                                    class_id=class_id,
                                    homework_id=homework_id,
                                    student_id=student_id,
                                    status="graded",
                                    grading_batch_id=batch_id
                                )
                                
                        logger.info(f"Áè≠Á∫ßÊâπÊîπÁªìÊûúÂ∑≤‰øùÂ≠ò: history_id={history_id}")
                        
                    except Exception as e:
                        logger.error(f"‰øùÂ≠òÁè≠Á∫ßÊâπÊîπÁªìÊûúÂ§±Ë¥•: {e}", exc_info=True)

                # #region agent log - ÂÅáËÆæE: WebSocket Ê∂àÊÅØÂèëÈÄÅ
                _write_debug_log({
                    "hypothesisId": "E",
                    "location": "batch_langgraph.py:workflow_completed",
                    "message": "ÂèëÈÄÅworkflow_completed",
                    "data": {
                        "student_count": len(formatted_results),
                        "students": [{"name": f.get("studentName"), "score": f.get("score")} for f in formatted_results],
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "sessionId": "debug-session",
                })
                # #endregion
                
                await broadcast_progress(batch_id, {
                    "type": "workflow_completed",
                    "message": f"Grading completed, processed {len(formatted_results)} students",
                    "results": formatted_results,
                    "classReport": class_report
                })
        
        logger.info(f"LangGraph ËøõÂ∫¶ÊµÅÂºè‰º†ËæìÂÆåÊàê: batch_id={batch_id}")
        
    except Exception as e:
        logger.error(
            f"ÊµÅÂºè‰º†ËæìÂ§±Ë¥•: batch_id={batch_id}, error={str(e)}",
            exc_info=True
        )
        await broadcast_progress(batch_id, {
            "type": "workflow_error",
            "message": f"ÊµÅÂºè‰º†ËæìÂ§±Ë¥•: {str(e)}"
        })

    finally:
        if teacher_semaphore:
            try:
                run_info = await orchestrator.get_status(run_id)
                status_value = run_info.status.value if hasattr(run_info.status, "value") else str(run_info.status)
                if status_value in ("completed", "failed", "cancelled"):
                    teacher_semaphore.release()
            except Exception:
                teacher_semaphore.release()


def _map_node_to_frontend(node_name: str) -> str:
    """Â∞Ü LangGraph ËäÇÁÇπÂêçÁß∞Êò†Â∞ÑÂà∞ÂâçÁ´ØËäÇÁÇπ ID
    
    ÂâçÁ´ØÂ∑•‰ΩúÊµÅËäÇÁÇπÔºàconsoleStore.ts initialNodesÔºâÔºö
    - intake: Êé•Êî∂Êñá‰ª∂
    - rubric_parse: Ëß£ÊûêËØÑÂàÜÊ†áÂáÜ
    - grade_batch: ÂàÜÊâπÂπ∂Ë°åÊâπÊîπÔºàisParallelContainerÔºâ
    - cross_page_merge: Ë∑®È°µÈ¢òÁõÆÂêàÂπ∂
    - index: ÊâπÊîπÂâçÁ¥¢Âºï
    - index_merge: Á¥¢ÂºïËÅöÂêà
    - export: ÂØºÂá∫ÁªìÊûú
    """
    mapping = {
        # ‰∏ªË¶ÅËäÇÁÇπÔºà‰∏éÂêéÁ´Ø batch_grading.py ÂÆåÂÖ®ÂØπÂ∫îÔºâ
        "intake": "intake",
        "rubric_parse": "rubric_parse",
        "rubric_review": "rubric_review",
        "grade_batch": "grade_batch",
        "cross_page_merge": "cross_page_merge",
        "index": "index",
        "index_merge": "index_merge",
        "segment": "index_merge",
        "review": "review",
        "logic_review": "logic_review",
        "export": "export",
        # ÂÖºÂÆπÊóßÂêçÁß∞
        "detect_boundaries": "index",
        "grade_student": "grade_batch",
        "grading": "grade_batch",
        "aggregate": "review",
        "batch_persist": "export",
        "batch_notify": "export"
    }
    return mapping.get(node_name, node_name)


def _get_node_display_name(node_name: str) -> str:
    """Ëé∑ÂèñËäÇÁÇπÁöÑÊòæÁ§∫ÂêçÁß∞Ôºà‰∏≠ÊñáÔºâ"""
    display_names = {
        "intake": "Ingest",
        "preprocess": "Preprocess",
        "index": "Index",
        "rubric_parse": "Rubric Parse",
        "rubric_review": "Rubric Review",
        "grading_fanout": "Batch Fanout",
        "grade_batch": "Batch Grading",
        "cross_page_merge": "Cross-Page Merge",
        "logic_review": "Logic Review",
        "index_merge": "Index Merge",
        "segment": "Index Merge",
        "review": "Final Review",
        "export": "Export"
    }
    return display_names.get(node_name, node_name)


def _safe_float(value: Any, default: float = 0.0) -> float:
    try:
        if value is None:
            return default
        return float(value)
    except (TypeError, ValueError):
        return default


def _format_results_for_frontend(results: List[Dict]) -> List[Dict]:
    """Ê†ºÂºèÂåñÊâπÊîπÁªìÊûú‰∏∫ÂâçÁ´ØÊ†ºÂºè"""
    # #region agent log - ÂÅáËÆæD: _format_results_for_frontend ËæìÂÖ•
    _write_debug_log({
        "hypothesisId": "D",
        "location": "batch_langgraph.py:_format_results_for_frontend:input",
        "message": "ËæìÂÖ•ÁöÑresults",
        "data": {
            "count": len(results),
            "students": [{"key": r.get("student_key"), "score": r.get("total_score")} for r in results],
        },
        "timestamp": int(datetime.now().timestamp() * 1000),
        "sessionId": "debug-session",
    })
    # #endregion
    formatted = []
    for r in results:
        # Â§ÑÁêÜ question_details Ê†ºÂºè
        question_results = []
        
        # ‰ºòÂÖà‰ΩøÁî® question_details
        if r.get("question_details"):
            for q in r.get("question_details", []):
                scoring_results = q.get("scoring_point_results") or q.get("scoring_results") or []
                question_results.append({
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0),
                    "confidence_reason": q.get("confidence_reason") or q.get("confidenceReason"),
                    "self_critique": q.get("self_critique") or q.get("selfCritique"),
                    "self_critique_confidence": q.get("self_critique_confidence") or q.get("selfCritiqueConfidence"),
                    "rubric_refs": q.get("rubric_refs") or q.get("rubricRefs"),
                    "review_summary": q.get("review_summary") or q.get("reviewSummary"),
                    "review_corrections": q.get("review_corrections") or q.get("reviewCorrections"),
                    "needsReview": (
                        q.get("needs_review")
                        if q.get("needs_review") is not None
                        else q.get("needsReview", False)
                    ),
                    "reviewReasons": (
                        q.get("review_reasons")
                        if q.get("review_reasons") is not None
                        else q.get("reviewReasons") or []
                    ),
                    "auditFlags": (
                        q.get("audit_flags")
                        if q.get("audit_flags") is not None
                        else q.get("auditFlags") or []
                    ),
                    "typo_notes": q.get("typo_notes") or q.get("typoNotes"),
                    "studentAnswer": q.get("student_answer", ""),
                    "question_type": q.get("question_type") or q.get("questionType"),
                    "isCorrect": q.get("is_correct", False),
                    "scoring_point_results": scoring_results,
                    "page_indices": q.get("page_indices", []),
                    "is_cross_page": q.get("is_cross_page", False),
                    "merge_source": q.get("merge_source")
                })
        # ÂÖºÂÆπÊóßÊ†ºÂºè grading_results
        elif r.get("grading_results"):
            for q in r.get("grading_results", []):
                scoring_results = q.get("scoring_point_results") or q.get("scoring_results") or []
                question_results.append({
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0),
                    "confidence_reason": q.get("confidence_reason") or q.get("confidenceReason"),
                    "self_critique": q.get("self_critique") or q.get("selfCritique"),
                    "self_critique_confidence": q.get("self_critique_confidence") or q.get("selfCritiqueConfidence"),
                    "rubric_refs": q.get("rubric_refs") or q.get("rubricRefs"),
                    "review_summary": q.get("review_summary") or q.get("reviewSummary"),
                    "review_corrections": q.get("review_corrections") or q.get("reviewCorrections"),
                    "needsReview": (
                        q.get("needs_review")
                        if q.get("needs_review") is not None
                        else q.get("needsReview", False)
                    ),
                    "reviewReasons": (
                        q.get("review_reasons")
                        if q.get("review_reasons") is not None
                        else q.get("reviewReasons") or []
                    ),
                    "auditFlags": (
                        q.get("audit_flags")
                        if q.get("audit_flags") is not None
                        else q.get("auditFlags") or []
                    ),
                    "typo_notes": q.get("typo_notes") or q.get("typoNotes"),
                    "studentAnswer": q.get("student_answer", ""),
                    "question_type": q.get("question_type") or q.get("questionType"),
                    "scoring_point_results": scoring_results,
                    "page_indices": q.get("page_indices", []),
                    "is_cross_page": q.get("is_cross_page", False),
                    "merge_source": q.get("merge_source")
                })
        # √•‚Ä¶¬º√•¬Æ¬π export_data √ß≈°‚Äû question_results
        elif r.get("question_results"):
            for q in r.get("question_results", []):
                scoring_results = q.get("scoring_point_results") or q.get("scoring_results") or []
                question_results.append({
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0),
                    "confidence_reason": q.get("confidence_reason") or q.get("confidenceReason"),
                    "self_critique": q.get("self_critique") or q.get("selfCritique"),
                    "self_critique_confidence": q.get("self_critique_confidence") or q.get("selfCritiqueConfidence"),
                    "rubric_refs": q.get("rubric_refs") or q.get("rubricRefs"),
                    "review_summary": q.get("review_summary") or q.get("reviewSummary"),
                    "review_corrections": q.get("review_corrections") or q.get("reviewCorrections"),
                    "needsReview": (
                        q.get("needs_review")
                        if q.get("needs_review") is not None
                        else q.get("needsReview", False)
                    ),
                    "reviewReasons": (
                        q.get("review_reasons")
                        if q.get("review_reasons") is not None
                        else q.get("reviewReasons") or []
                    ),
                    "auditFlags": (
                        q.get("audit_flags")
                        if q.get("audit_flags") is not None
                        else q.get("auditFlags") or []
                    ),
                    "typo_notes": q.get("typo_notes") or q.get("typoNotes"),
                    "studentAnswer": q.get("student_answer", ""),
                    "question_type": q.get("question_type") or q.get("questionType"),
                    "isCorrect": q.get("is_correct", False),
                    "scoring_point_results": scoring_results,
                    "page_indices": q.get("page_indices", []),
                    "is_cross_page": q.get("is_cross_page", False),
                    "merge_source": q.get("merge_source"),
                })
        # ‰ªé page_results ÊèêÂèñ
        elif r.get("page_results"):
            for page in r.get("page_results", []):
                if page.get("status") == "completed":
                    # ‰ªéÈ°µÈù¢ÁªìÊûú‰∏≠ÊèêÂèñÈ¢òÁõÆËØ¶ÊÉÖ
                    for q in page.get("question_details", []):
                        scoring_results = q.get("scoring_point_results") or q.get("scoring_results") or []
                        page_indices = q.get("page_indices")
                        if not page_indices and page.get("page_index") is not None:
                            page_indices = [page.get("page_index")]
                        question_results.append({
                            "questionId": str(q.get("question_id", "")),
                            "score": q.get("score", 0),
                            "maxScore": q.get("max_score", 0),
                            "feedback": q.get("feedback", ""),
                            "confidence": q.get("confidence", 0),
                            "confidence_reason": q.get("confidence_reason") or q.get("confidenceReason"),
                            "self_critique": q.get("self_critique") or q.get("selfCritique"),
                            "self_critique_confidence": q.get("self_critique_confidence") or q.get("selfCritiqueConfidence"),
                            "rubric_refs": q.get("rubric_refs") or q.get("rubricRefs"),
                            "review_summary": q.get("review_summary") or q.get("reviewSummary"),
                            "review_corrections": q.get("review_corrections") or q.get("reviewCorrections"),
                            "needsReview": (
                                q.get("needs_review")
                                if q.get("needs_review") is not None
                                else q.get("needsReview", False)
                            ),
                            "reviewReasons": (
                                q.get("review_reasons")
                                if q.get("review_reasons") is not None
                                else q.get("reviewReasons") or []
                            ),
                            "auditFlags": (
                                q.get("audit_flags")
                                if q.get("audit_flags") is not None
                                else q.get("auditFlags") or []
                            ),
                            "typo_notes": q.get("typo_notes") or q.get("typoNotes"),
                            "studentAnswer": q.get("student_answer", ""),
                            "question_type": q.get("question_type") or q.get("questionType"),
                            "isCorrect": q.get("is_correct", False),
                            "scoring_point_results": scoring_results,
                            "page_indices": page_indices or [],
                            "is_cross_page": q.get("is_cross_page", False),
                            "merge_source": q.get("merge_source")
                        })
        
        computed_score = sum(_safe_float(q.get("score", 0)) for q in question_results)
        computed_max = sum(_safe_float(q.get("maxScore", 0)) for q in question_results)
        raw_score = _safe_float(r.get("total_score", r.get("score", 0)))
        raw_max = _safe_float(r.get("max_total_score", r.get("max_score", 0)))
        final_score = raw_score if raw_score > 0 or computed_score <= 0 else computed_score
        final_max = raw_max if raw_max > 0 or computed_max <= 0 else computed_max

        student_summary = r.get("student_summary") or r.get("studentSummary")
        self_audit = r.get("self_audit") or r.get("selfAudit")
        formatted.append({
            "studentName": r.get("student_key") or r.get("student_name") or r.get("student_id", "Unknown"),
            "score": final_score,
            "maxScore": final_max if final_max > 0 else 0,
            "startPage": r.get("start_page"),   # üî• Êñ∞Â¢ûÔºöÂ≠¶ÁîüÈ°µÈù¢ËåÉÂõ¥
            "endPage": r.get("end_page"),       # üî• Êñ∞Â¢ûÔºöÂ≠¶ÁîüÈ°µÈù¢ËåÉÂõ¥
            "questionResults": question_results,
            "confidence": r.get("confidence", 0),
            "needsConfirmation": r.get("needs_confirmation", False),
            "gradingMode": r.get("grading_mode") or r.get("gradingMode"),
            "studentSummary": student_summary,
            "selfAudit": self_audit
        })
    # #region agent log - ÂÅáËÆæD: _format_results_for_frontend ËæìÂá∫
    _write_debug_log({
        "hypothesisId": "D",
        "location": "batch_langgraph.py:_format_results_for_frontend:output",
        "message": "ËæìÂá∫ÁöÑformatted",
        "data": {
            "count": len(formatted),
            "students": [{"name": f.get("studentName"), "score": f.get("score")} for f in formatted],
        },
        "timestamp": int(datetime.now().timestamp() * 1000),
        "sessionId": "debug-session",
    })
    # #endregion
    return formatted


@router.websocket("/ws/{batch_id}")
async def websocket_endpoint(websocket: WebSocket, batch_id: str):
    """
    WebSocket Á´ØÁÇπÔºåÁî®‰∫éÂÆûÊó∂Êé®ÈÄÅÊâπÊîπËøõÂ∫¶
    
    ÂâçÁ´ØÈÄöËøáÊ≠§Á´ØÁÇπÊé•Êî∂ LangGraph ÁöÑÂÆûÊó∂ÊâßË°åËøõÂ∫¶
    """
    await websocket.accept()

    cached_images = batch_image_cache.get(batch_id, {})
    if cached_images:
        try:
            for key, message in cached_images.items():
                if key == "llm_stream_cache":
                    continue
                await websocket.send_json(message)
            stream_cache = cached_images.get("llm_stream_cache")
            if isinstance(stream_cache, dict):
                for stream_message in stream_cache.values():
                    await websocket.send_json({
                        "type": "llm_stream_chunk",
                        **stream_message,
                    })
        except Exception as e:
            logger.warning(f"ÂèëÈÄÅÁºìÂ≠òÂõæÁâáÂ§±Ë¥•: {e}")
    
    # Ê≥®ÂÜåËøûÊé•
    if batch_id not in active_connections:
        active_connections[batch_id] = []
    active_connections[batch_id].append(websocket)
    
    logger.info(f"WebSocket ËøûÊé•Âª∫Á´ã: batch_id={batch_id}")

    # ËøûÊé•Âª∫Á´ãÂêéÂ∞ùËØïÂèëÈÄÅÂΩìÂâçÁä∂ÊÄÅÂø´ÁÖßÔºåÈÅøÂÖçÂâçÁ´ØÈîôËøáÊó©Êúü‰∫ã‰ª∂ÂØºËá¥Âç°‰Ωè
    try:
        orchestrator = await get_orchestrator()
        if orchestrator:
            run_id = f"batch_grading_{batch_id}"
            run_info = await orchestrator.get_run_info(run_id)
            if run_info and run_info.state:
                state = run_info.state or {}
                current_stage = state.get("current_stage", "")
                percentage = state.get("percentage", 0)
                if current_stage or percentage:
                    await websocket.send_json({
                        "type": "grading_progress",
                        "percentage": percentage or 0,
                        "currentStage": current_stage
                    })
                if state.get("student_boundaries"):
                    boundaries = state.get("student_boundaries", [])
                    await websocket.send_json({
                        "type": "students_identified",
                        "studentCount": len(boundaries),
                        "students": [
                            {
                                "studentKey": b.get("student_key", ""),
                                "startPage": b.get("start_page", 0),
                                "endPage": b.get("end_page", 0),
                                "confidence": b.get("confidence", 0),
                                "needsConfirmation": b.get("needs_confirmation", False)
                            }
                            for b in boundaries
                        ]
                    })
                if state.get("parsed_rubric"):
                    parsed = state.get("parsed_rubric", {})
                    await websocket.send_json({
                        "type": "rubric_parsed",
                        "totalQuestions": parsed.get("total_questions", 0),
                        "totalScore": parsed.get("total_score", 0),
                        "generalNotes": parsed.get("general_notes", ""),
                        "rubricFormat": parsed.get("rubric_format", ""),
                        "questions": [
                            {
                                "questionId": q.get("question_id", ""),
                                "maxScore": q.get("max_score", 0),
                                "questionText": q.get("question_text", ""),
                                "standardAnswer": q.get("standard_answer", ""),
                                "gradingNotes": q.get("grading_notes", ""),
                          "scoringPoints": [
                              {
                                  "pointId": sp.get("point_id") or sp.get("pointId") or f"{q.get('question_id')}.{idx + 1}",
                                  "description": sp.get("description", ""),
                                  "expectedValue": sp.get("expected_value") or sp.get("expectedValue", ""),
                                  "keywords": sp.get("keywords") or [],
                                  "score": sp.get("score", 0),
                                  "isRequired": sp.get("is_required", True),
                              }
                              for idx, sp in enumerate(q.get("scoring_points", []))
                          ],
                          "deductionRules": [
                              {
                                  "ruleId": dr.get("rule_id") or dr.get("ruleId") or f"{q.get('question_id')}.d{idx + 1}",
                                  "description": dr.get("description", ""),
                                  "deduction": dr.get("deduction", dr.get("score", 0)),
                                  "conditions": dr.get("conditions") or dr.get("when") or "",
                              }
                              for idx, dr in enumerate(q.get("deduction_rules") or q.get("deductionRules") or [])
                          ],
                                "alternativeSolutions": [
                                    {
                                        "description": alt.get("description", ""),
                                        "scoringCriteria": alt.get("scoring_criteria", ""),
                                        "note": alt.get("note", ""),
                                    }
                                    for alt in q.get("alternative_solutions", [])
                                ]
                            }
                            for q in parsed.get("questions", [])
                        ]
                    })
                if run_info.status and run_info.status.value == "completed":
                    student_results = state.get("student_results", [])
                    formatted_results = _format_results_for_frontend(student_results)
                    class_report = state.get("class_report")
                    if not class_report and state.get("export_data"):
                        class_report = state.get("export_data", {}).get("class_report")
                    await websocket.send_json({
                        "type": "workflow_completed",
                        "message": f"Grading completed, processed {len(formatted_results)} students",
                        "results": formatted_results,
                        "cross_page_questions": state.get("cross_page_questions", []),
                        "classReport": class_report
                    })
    except Exception as e:
        logger.warning(f"ÂèëÈÄÅÁä∂ÊÄÅÂø´ÁÖßÂ§±Ë¥•: {e}")
    
    try:
        # ‰øùÊåÅËøûÊé•ÔºåÁ≠âÂæÖÂÆ¢Êà∑Á´ØÊ∂àÊÅØÊàñÊñ≠ÂºÄ
        while True:
            if not _is_ws_connected(websocket):
                break
            data = await websocket.receive_text()
            logger.debug(f"Êî∂Âà∞ WebSocket Ê∂àÊÅØ: batch_id={batch_id}, data={data}")
            
    except (WebSocketDisconnect, RuntimeError) as exc:
        logger.info(f"WebSocket ËøûÊé•Êñ≠ÂºÄ: batch_id={batch_id}, reason={exc}")
        if batch_id in active_connections and websocket in active_connections[batch_id]:
            active_connections[batch_id].remove(websocket)
            if not active_connections[batch_id]:
                del active_connections[batch_id]
        return
    except Exception as exc:
        logger.warning(f"WebSocket Êé•Êî∂ÂºÇÂ∏∏: batch_id={batch_id}, error={exc}")
        logger.info(f"WebSocket ËøûÊé•Êñ≠ÂºÄ: batch_id={batch_id}")
        if batch_id in active_connections and websocket in active_connections[batch_id]:
            active_connections[batch_id].remove(websocket)
            if not active_connections[batch_id]:
                del active_connections[batch_id]


@router.get("/status/{batch_id}", response_model=BatchStatusResponse)
async def get_batch_status(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    Êü•ËØ¢ÊâπÊ¨°Áä∂ÊÄÅÔºà‰ªé LangGraph OrchestratorÔºâ
    
    Args:
        batch_id: ÊâπÊ¨° ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        BatchStatusResponse: ÊâπÊ¨°Áä∂ÊÄÅ
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")
        
        # ÊûÑÂª∫ run_idÔºà‰∏é start_run ‰∏≠ÁöÑÊ†ºÂºè‰∏ÄËá¥Ôºâ
        run_id = f"batch_grading_{batch_id}"
        
        # ‰ªé LangGraph Orchestrator Êü•ËØ¢Áä∂ÊÄÅ
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")
        
        state = run_info.state or {}
        
        return BatchStatusResponse(
            batch_id=batch_id,
            exam_id=state.get("exam_id", ""),
            status=run_info.status.value,
            total_students=len(state.get("student_boundaries", [])),
            completed_students=len(state.get("student_results", [])),
            unidentified_pages=0,
            results=state.get("student_results")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Êü•ËØ¢ÊâπÊ¨°Áä∂ÊÄÅÂ§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Êü•ËØ¢Â§±Ë¥•: {str(e)}")


@router.get("/rubric/{batch_id}", response_model=RubricReviewContextResponse)
async def get_rubric_review_context(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """Ëé∑Âèñ rubric review È°µÈù¢‰∏ä‰∏ãÊñá"""
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")

        run_id = f"batch_grading_{batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")

        state = run_info.state or {}
        parsed_rubric = state.get("parsed_rubric")

        cached = batch_image_cache.get(batch_id, {})
        cached_images = cached.get("rubric_images_ready", {}).get("images") if cached else None
        rubric_images: List[str] = cached_images or []

        if not rubric_images and state.get("rubric_images"):
            try:
                rubric_images = []
                for img in state.get("rubric_images", []):
                    if isinstance(img, (bytes, bytearray)):
                        rubric_images.append(base64.b64encode(img).decode("utf-8"))
                    elif isinstance(img, str) and img:
                        rubric_images.append(img)
            except Exception as exc:
                logger.warning(f"Failed to convert rubric images: {exc}")
        return RubricReviewContextResponse(
            batch_id=batch_id,
            status=run_info.status.value if run_info.status else None,
            current_stage=state.get("current_stage"),
            parsed_rubric=parsed_rubric,
            rubric_images=rubric_images,
        )
    except HTTPException:
        raise
    except Exception as exc:
        logger.error(f"Ëé∑Âèñ rubric ‰∏ä‰∏ãÊñáÂ§±Ë¥•: {exc}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ëé∑ÂèñÂ§±Ë¥•: {str(exc)}")


@router.get("/results-review/{batch_id}", response_model=ResultsReviewContextResponse)
async def get_results_review_context(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """Ëé∑Âèñ results review È°µÈù¢‰∏ä‰∏ãÊñá"""
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")

        run_id = f"batch_grading_{batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")

        state = run_info.state or {}
        student_results = state.get("student_results", [])
        if not student_results:
            try:
                final_output = await orchestrator.get_final_output(run_id)
                if final_output:
                    student_results = final_output.get("student_results", [])
            except Exception as exc:
                logger.warning(f"Ëé∑ÂèñÊúÄÁªàËæìÂá∫Â§±Ë¥•: {exc}")

        if not student_results:
            export_students = (state.get("export_data") or {}).get("students", [])
            if export_students:
                student_results = export_students

        cached = batch_image_cache.get(batch_id, {})
        cached_images = cached.get("images_ready", {}).get("images") if cached else None
        answer_images: List[str] = cached_images or []

        if not answer_images:
            raw_images = state.get("processed_images") or state.get("answer_images") or []
            try:
                answer_images = []
                for img in raw_images:
                    if isinstance(img, (bytes, bytearray)):
                        answer_images.append(base64.b64encode(img).decode("utf-8"))
                    elif isinstance(img, str) and img:
                        answer_images.append(img)
            except Exception as exc:
                logger.warning(f"Failed to convert answer images: {exc}")
        return ResultsReviewContextResponse(
            batch_id=batch_id,
            status=run_info.status.value if run_info.status else None,
            current_stage=state.get("current_stage"),
            student_results=_format_results_for_frontend(student_results),
            answer_images=answer_images,
        )
    except HTTPException:
        raise
    except Exception as exc:
        logger.error(f"Ëé∑Âèñ results ‰∏ä‰∏ãÊñáÂ§±Ë¥•: {exc}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ëé∑ÂèñÂ§±Ë¥•: {str(exc)}")


@router.get("/results/{batch_id}")
async def get_batch_results(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    Ëé∑ÂèñÊâπÊ¨°ÊâπÊîπÁªìÊûúÔºà‰ªé LangGraph OrchestratorÔºâ
    
    Args:
        batch_id: ÊâπÊ¨° ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        ÊâπÊîπÁªìÊûú
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")
        
        # ÊûÑÂª∫ run_idÔºà‰∏é start_run ‰∏≠ÁöÑÊ†ºÂºè‰∏ÄËá¥Ôºâ
        run_id = f"batch_grading_{batch_id}"
        
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")
        
        state = run_info.state or {}
        
        # ‰ºòÂÖà‰ªé student_results Ëé∑ÂèñÁªìÊûú
        student_results = state.get("student_results", [])
        
        # Â¶ÇÊûúÊ≤°Êúâ student_resultsÔºåÂ∞ùËØï‰ªé orchestrator Ëé∑ÂèñÊúÄÁªàËæìÂá∫
        if not student_results:
            try:
                final_output = await orchestrator.get_final_output(run_id)
                if final_output:
                    student_results = final_output.get("student_results", [])
            except Exception as e:
                logger.warning(f"Ëé∑ÂèñÊúÄÁªàËæìÂá∫Â§±Ë¥•: {e}")
        
        return {
            "batch_id": batch_id,
            "status": run_info.status.value,
            "results": _format_results_for_frontend(student_results),
            "class_report": state.get("class_report")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Ëé∑ÂèñÊâπÊîπÁªìÊûúÂ§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ëé∑ÂèñÂ§±Ë¥•: {str(e)}")


@router.get("/full-results/{batch_id}")
async def get_full_batch_results(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    Ëé∑ÂèñÊâπÊ¨°ÂÆåÊï¥ÊâπÊîπÁªìÊûúÔºàÂåÖÂê´Ë∑®È°µÈ¢òÁõÆ‰ø°ÊÅØÔºâ
    
    Args:
        batch_id: ÊâπÊ¨° ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        ÂÆåÊï¥ÊâπÊîπÁªìÊûúÔºàÂåÖÂê´Ë∑®È°µÈ¢òÁõÆ‰ø°ÊÅØÔºâ
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")
        
        run_id = f"batch_grading_{batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")
        
        state = run_info.state or {}
        student_results = state.get("student_results", [])
        cross_page_questions = state.get("cross_page_questions", [])
        parsed_rubric = state.get("parsed_rubric", {})
        class_report = state.get("class_report") or state.get("export_data", {}).get("class_report")
        
        return {
            "batch_id": batch_id,
            "status": run_info.status.value,
            "results": _format_results_for_frontend(student_results),
            "cross_page_questions": cross_page_questions,
            "parsed_rubric": parsed_rubric,
            "class_report": class_report,
            "total_students": len(student_results),
            "total_score": parsed_rubric.get("total_score", 100) if parsed_rubric else 100
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Ëé∑ÂèñÂÆåÊï¥ÊâπÊîπÁªìÊûúÂ§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ëé∑ÂèñÂ§±Ë¥•: {str(e)}")


@router.get("/cross-page-questions/{batch_id}")
async def get_cross_page_questions(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    Ëé∑ÂèñË∑®È°µÈ¢òÁõÆ‰ø°ÊÅØ
    
    Args:
        batch_id: ÊâπÊ¨° ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        Ë∑®È°µÈ¢òÁõÆ‰ø°ÊÅØÂàóË°®
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")
        
        run_id = f"batch_grading_{batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")
        
        state = run_info.state or {}
        cross_page_questions = state.get("cross_page_questions", [])
        
        return cross_page_questions
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Ëé∑ÂèñË∑®È°µÈ¢òÁõÆ‰ø°ÊÅØÂ§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ëé∑ÂèñÂ§±Ë¥•: {str(e)}")


class ConfirmBoundaryRequest(BaseModel):
    """Á°ÆËÆ§Â≠¶ÁîüËæπÁïåËØ∑Ê±Ç"""
    batch_id: str = Field(..., description="ÊâπÊ¨° ID")
    student_key: str = Field(..., description="Â≠¶ÁîüÊ†áËØÜ")
    confirmed_pages: List[int] = Field(..., description="Á°ÆËÆ§ÁöÑÈ°µÈù¢Á¥¢ÂºïÂàóË°®")


class RubricReviewRequest(BaseModel):
    """Êèê‰∫§ËØÑÂàÜÊ†áÂáÜ‰∫∫Â∑•Á°ÆËÆ§ÁªìÊûú"""
    batch_id: str = Field(..., description="ÊâπÊ¨° ID")
    action: str = Field(..., description="approve/update/reparse")
    parsed_rubric: Optional[Dict[str, Any]] = Field(None, description="‰øÆÊ≠£ÂêéÁöÑËØÑÂàÜÊ†áÂáÜ")
    selected_question_ids: Optional[List[str]] = Field(None, description="‰ªÖÈáç‰øÆÊ≠£ÁöÑÈóÆÈ¢ò ID ÂàóË°®")
    notes: Optional[str] = Field(None, description="Ë°•ÂÖÖËØ¥Êòé")


class ResultsReviewRequest(BaseModel):
    """Êèê‰∫§ÊâπÊîπÁªìÊûú‰∫∫Â∑•Á°ÆËÆ§ÁªìÊûú"""
    batch_id: str = Field(..., description="ÊâπÊ¨° ID")
    action: str = Field(..., description="approve/update/regrade")
    results: Optional[List[Dict[str, Any]]] = Field(None, description="‰øÆÊ≠£ÂêéÁöÑÁªìÊûú")
    regrade_items: Optional[List[Dict[str, Any]]] = Field(
        None,
        description="ÈúÄË¶ÅÈáçÊñ∞ÊâπÊîπÁöÑÈ¢òÁõÆÈ°π",
    )
    notes: Optional[str] = Field(None, description="Ë°•ÂÖÖËØ¥Êòé")


@router.post("/review/rubric")
async def submit_rubric_review(
    request: RubricReviewRequest,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """Êèê‰∫§ËØÑÂàÜÊ†áÂáÜÂ§çÊ†∏ÁªìÊûúÔºåÊÅ¢Â§ç workflow"""
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")

        action = request.action.lower().strip()
        if action not in ("approve", "update", "override", "reparse"):
            raise HTTPException(status_code=400, detail="Êó†ÊïàÁöÑ review action")

        run_id = f"batch_grading_{request.batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")

        payload: Dict[str, Any] = {
            "action": action,
        }
        if request.parsed_rubric is not None:
            payload["parsed_rubric"] = request.parsed_rubric
        if request.selected_question_ids:
            payload["selected_question_ids"] = request.selected_question_ids
        if request.notes:
            payload["notes"] = request.notes

        success = await orchestrator.send_event(run_id, "review_signal", payload)
        if not success:
            raise HTTPException(status_code=409, detail="ÊâπÊ¨°Êú™Â§Ñ‰∫éÂèØÂ§çÊ†∏Áä∂ÊÄÅ")

        cached = batch_image_cache.get(request.batch_id)
        if cached and "review_required" in cached:
            cached.pop("review_required", None)

        return {"success": True, "message": "ËØÑÂàÜÊ†áÂáÜÂ§çÊ†∏Â∑≤Êèê‰∫§"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Êèê‰∫§ËØÑÂàÜÊ†áÂáÜÂ§çÊ†∏Â§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Êèê‰∫§Â§±Ë¥•: {str(e)}")


@router.post("/review/results")
async def submit_results_review(
    request: ResultsReviewRequest,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """Êèê‰∫§ÊâπÊîπÁªìÊûúÂ§çÊ†∏ÔºåÊÅ¢Â§ç workflow"""
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")

        action = request.action.lower().strip()
        if action not in ("approve", "update", "override", "regrade"):
            raise HTTPException(status_code=400, detail="Êó†ÊïàÁöÑ review action")

        run_id = f"batch_grading_{request.batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")

        payload: Dict[str, Any] = {
            "action": action,
        }
        if request.results is not None:
            payload["results"] = request.results
        if request.regrade_items is not None:
            payload["regrade_items"] = request.regrade_items
        if request.notes:
            payload["notes"] = request.notes

        success = await orchestrator.send_event(run_id, "review_signal", payload)
        if not success:
            raise HTTPException(status_code=409, detail="ÊâπÊ¨°Êú™Â§Ñ‰∫éÂèØÂ§çÊ†∏Áä∂ÊÄÅ")

        cached = batch_image_cache.get(request.batch_id)
        if cached and "review_required" in cached:
            cached.pop("review_required", None)

        return {"success": True, "message": "ÊâπÊîπÁªìÊûúÂ§çÊ†∏Â∑≤Êèê‰∫§"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Êèê‰∫§ÊâπÊîπÂ§çÊ†∏Â§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Êèê‰∫§Â§±Ë¥•: {str(e)}")


@router.post("/confirm-boundary")
async def confirm_student_boundary(
    request: ConfirmBoundaryRequest,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    Á°ÆËÆ§Â≠¶ÁîüËæπÁïå
    
    ÂΩì AI ËØÜÂà´ÁöÑÂ≠¶ÁîüËæπÁïå‰∏çÂáÜÁ°ÆÊó∂ÔºåÂÖÅËÆ∏Áî®Êà∑ÊâãÂä®Á°ÆËÆ§
    
    Args:
        request: Á°ÆËÆ§ËæπÁïåËØ∑Ê±Ç
        orchestrator: LangGraph Orchestrator
        
    Returns:
        Á°ÆËÆ§ÁªìÊûú
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ÁºñÊéíÂô®Êú™ÂàùÂßãÂåñ")
        
        run_id = f"batch_grading_{request.batch_id}"
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="ÊâπÊ¨°‰∏çÂ≠òÂú®")
        
        # Êõ¥Êñ∞Áä∂ÊÄÅ‰∏≠ÁöÑÂ≠¶ÁîüËæπÁïå
        state = run_info.state or {}
        student_boundaries = state.get("student_boundaries", [])
        
        # Êü•ÊâæÂπ∂Êõ¥Êñ∞ÂØπÂ∫îÂ≠¶ÁîüÁöÑËæπÁïå
        updated = False
        for boundary in student_boundaries:
            if boundary.get("student_key") == request.student_key:
                boundary["pages"] = request.confirmed_pages
                boundary["confirmed"] = True
                updated = True
                break
        
        if not updated:
            # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ÔºåÊ∑ªÂä†Êñ∞ÁöÑËæπÁïå
            student_boundaries.append({
                "student_key": request.student_key,
                "pages": request.confirmed_pages,
                "confirmed": True
            })
        
        logger.info(f"Â≠¶ÁîüËæπÁïåÂ∑≤Á°ÆËÆ§: batch_id={request.batch_id}, student_key={request.student_key}")
        
        return {
            "success": True,
            "message": f"Â≠¶Áîü {request.student_key} ÁöÑËæπÁïåÂ∑≤Á°ÆËÆ§"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Á°ÆËÆ§Â≠¶ÁîüËæπÁïåÂ§±Ë¥•: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Á°ÆËÆ§Â§±Ë¥•: {str(e)}")
