"""æ‰¹é‡æäº¤ API è·¯ç”± - ä½¿ç”¨ LangGraph Orchestrator

æ­£ç¡®çš„æ¶æ„ï¼š
1. ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨æ‰¹æ”¹æµç¨‹
2. é€šè¿‡ LangGraph çš„æµå¼ API å®æ—¶æ¨é€è¿›åº¦
3. åˆ©ç”¨ PostgreSQL Checkpointer å®ç°æŒä¹…åŒ–å’Œæ–­ç‚¹æ¢å¤
"""

import uuid
import logging
import tempfile
import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, WebSocket, WebSocketDisconnect, Depends
from pydantic import BaseModel, Field
import fitz
from PIL import Image
from io import BytesIO
import os

from src.models.enums import SubmissionStatus
from src.orchestration.base import Orchestrator
from src.api.dependencies import get_orchestrator


logger = logging.getLogger(__name__)
router = APIRouter(prefix="/batch", tags=["æ‰¹é‡æäº¤"])

# å­˜å‚¨æ´»è·ƒçš„ WebSocket è¿æ¥
active_connections: Dict[str, List[WebSocket]] = {}


class BatchSubmissionResponse(BaseModel):
    """æ‰¹é‡æäº¤å“åº”"""
    batch_id: str = Field(..., description="æ‰¹æ¬¡ ID")
    status: SubmissionStatus = Field(..., description="çŠ¶æ€")
    total_pages: int = Field(..., description="æ€»é¡µæ•°")
    estimated_completion_time: int = Field(..., description="é¢„è®¡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰")


class BatchStatusResponse(BaseModel):
    """æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å“åº”"""
    batch_id: str
    exam_id: str
    status: str
    total_students: int = Field(0, description="è¯†åˆ«åˆ°çš„å­¦ç”Ÿæ•°")
    completed_students: int = Field(0, description="å·²å®Œæˆæ‰¹æ”¹çš„å­¦ç”Ÿæ•°")
    unidentified_pages: int = Field(0, description="æœªè¯†åˆ«å­¦ç”Ÿçš„é¡µæ•°")
    results: Optional[dict] = Field(None, description="æ‰¹æ”¹ç»“æœ")


def _pdf_to_images(pdf_path: str, dpi: int = 150) -> List[bytes]:
    """å°† PDF è½¬æ¢ä¸ºå›¾åƒåˆ—è¡¨"""
    pdf_doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(pdf_doc)):
        page = pdf_doc[page_num]
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        img_bytes = BytesIO()
        img.save(img_bytes, format='PNG')
        images.append(img_bytes.getvalue())
    
    pdf_doc.close()
    return images


async def broadcast_progress(batch_id: str, message: dict):
    """å‘æ‰€æœ‰è¿æ¥çš„ WebSocket å®¢æˆ·ç«¯å¹¿æ’­è¿›åº¦"""
    if batch_id in active_connections:
        disconnected = []
        for ws in active_connections[batch_id]:
            try:
                await ws.send_json(message)
            except Exception as e:
                logger.error(f"WebSocket å‘é€å¤±è´¥: {e}")
                disconnected.append(ws)
        
        # ç§»é™¤æ–­å¼€çš„è¿æ¥
        for ws in disconnected:
            active_connections[batch_id].remove(ws)


@router.post("/submit", response_model=BatchSubmissionResponse)
async def submit_batch(
    exam_id: Optional[str] = Form(None, description="è€ƒè¯• ID"),
    rubrics: List[UploadFile] = File(default=[], description="è¯„åˆ†æ ‡å‡† PDFï¼ˆå¯é€‰ï¼‰"),
    files: List[UploadFile] = File(..., description="å­¦ç”Ÿä½œç­” PDF"),
    api_key: Optional[str] = Form(None, description="Gemini API Key"),
    auto_identify: bool = Form(True, description="æ˜¯å¦è‡ªåŠ¨è¯†åˆ«å­¦ç”Ÿèº«ä»½"),
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    æ‰¹é‡æäº¤è¯•å·å¹¶è¿›è¡Œæ‰¹æ”¹ï¼ˆä½¿ç”¨ LangGraph Orchestratorï¼‰
    
    æ­£ç¡®çš„æ¶æ„ï¼š
    1. ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨ batch_grading Graph
    2. Graph è‡ªåŠ¨å¤„ç†ï¼šè¾¹ç•Œæ£€æµ‹ â†’ å¹¶è¡Œæ‰¹æ”¹ â†’ èšåˆ â†’ æŒä¹…åŒ– â†’ é€šçŸ¥
    3. é€šè¿‡ WebSocket å®æ—¶æ¨é€ LangGraph çš„æ‰§è¡Œè¿›åº¦
    
    Args:
        exam_id: è€ƒè¯• ID
        rubrics: è¯„åˆ†æ ‡å‡† PDF æ–‡ä»¶åˆ—è¡¨
        files: å­¦ç”Ÿä½œç­” PDF æ–‡ä»¶åˆ—è¡¨
        api_key: Gemini API Key
        auto_identify: æ˜¯å¦å¯ç”¨è‡ªåŠ¨å­¦ç”Ÿè¯†åˆ«
        orchestrator: LangGraph Orchestratorï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        
    Returns:
        BatchSubmissionResponse: æ‰¹æ¬¡ä¿¡æ¯
    """
    # æ£€æŸ¥ orchestrator æ˜¯å¦å¯ç”¨
    if not orchestrator:
        raise HTTPException(
            status_code=503, 
            detail="æ‰¹æ”¹æœåŠ¡æœªåˆå§‹åŒ–ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥æœåŠ¡é…ç½®"
        )
    
    if not api_key:
        api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        raise HTTPException(
            status_code=400,
            detail="æœªæä¾› API Keyï¼Œè¯·åœ¨è¯·æ±‚ä¸­æä¾›æˆ–é…ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY"
        )

    if not exam_id:
        exam_id = str(uuid.uuid4())

    batch_id = str(uuid.uuid4())
    
    logger.info(
        f"æ”¶åˆ°æ‰¹é‡æäº¤ï¼ˆLangGraphï¼‰: "
        f"batch_id={batch_id}, "
        f"exam_id={exam_id}, "
        f"auto_identify={auto_identify}"
    )
    
    temp_dir = None
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        temp_path = Path(temp_dir)
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        answer_path = temp_path / "answer.pdf"
        answer_content = await files[0].read()
        
        with open(answer_path, "wb") as f:
            f.write(answer_content)
        
        # å¤„ç†è¯„åˆ†æ ‡å‡†ï¼ˆå¯é€‰ï¼‰
        rubric_images = []
        if rubrics and len(rubrics) > 0:
            rubric_path = temp_path / "rubric.pdf"
            rubric_content = await rubrics[0].read()
            with open(rubric_path, "wb") as f:
                f.write(rubric_content)
            
            # è½¬æ¢è¯„åˆ†æ ‡å‡† PDF ä¸ºå›¾åƒ
            logger.info(f"è½¬æ¢è¯„åˆ†æ ‡å‡† PDF ä¸ºå›¾åƒ: batch_id={batch_id}")
            loop = asyncio.get_event_loop()
            rubric_images = await loop.run_in_executor(None, _pdf_to_images, str(rubric_path), 150)
        else:
            logger.info(f"æœªæä¾›è¯„åˆ†æ ‡å‡†ï¼Œå°†ä½¿ç”¨é»˜è®¤è¯„åˆ†: batch_id={batch_id}")
        
        # è½¬æ¢ç­”é¢˜ PDF/æ–‡æœ¬ä¸ºå›¾åƒ
        logger.info(f"å¤„ç†ç­”é¢˜æ–‡ä»¶: batch_id={batch_id}")
        loop = asyncio.get_event_loop()
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_name = files[0].filename or "submission"
        if file_name.lower().endswith('.txt'):
            # æ–‡æœ¬æ–‡ä»¶ï¼šç›´æ¥ä½¿ç”¨æ–‡æœ¬å†…å®¹
            text_content = answer_content.decode('utf-8')
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å›¾åƒè¡¨ç¤ºæ–‡æœ¬ï¼ˆæˆ–ç›´æ¥ä¼ é€’æ–‡æœ¬ï¼‰
            answer_images = [answer_content]  # ä¼ é€’åŸå§‹æ–‡æœ¬å†…å®¹
            logger.info(f"æ–‡æœ¬æ–‡ä»¶å¤„ç†å®Œæˆ: batch_id={batch_id}, å†…å®¹é•¿åº¦={len(text_content)}")
        else:
            # PDF æ–‡ä»¶ï¼šè½¬æ¢ä¸ºå›¾åƒ
            answer_images = await loop.run_in_executor(None, _pdf_to_images, str(answer_path), 150)
        
        total_pages = len(answer_images)
        
        logger.info(
            f"PDF è½¬æ¢å®Œæˆ: "
            f"batch_id={batch_id}, "
            f"rubric_pages={len(rubric_images)}, "
            f"answer_pages={total_pages}"
        )
        
        # ğŸš€ ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨æ‰¹æ”¹æµç¨‹
        payload = {
            "batch_id": batch_id,
            "exam_id": exam_id,
            "pdf_path": str(answer_path),
            "rubric_images": rubric_images,
            "answer_images": answer_images,
            "api_key": api_key,
            "inputs": {
                "pdf_path": str(answer_path),
                "rubric": "rubric_content",  # TODO: è§£æ rubric
                "auto_identify": auto_identify
            }
        }
        
        # å¯åŠ¨ LangGraph batch_grading Graph
        run_id = await orchestrator.start_run(
            graph_name="batch_grading",
            payload=payload,
            idempotency_key=batch_id
        )
        
        logger.info(
            f"LangGraph æ‰¹æ”¹æµç¨‹å·²å¯åŠ¨: "
            f"batch_id={batch_id}, "
            f"run_id={run_id}"
        )
        
        # å¯åŠ¨åå°ä»»åŠ¡ç›‘å¬ LangGraph è¿›åº¦å¹¶æ¨é€åˆ° WebSocket
        asyncio.create_task(
            stream_langgraph_progress(
                batch_id=batch_id,
                run_id=run_id,
                orchestrator=orchestrator
            )
        )
        
        return BatchSubmissionResponse(
            batch_id=batch_id,
            status=SubmissionStatus.UPLOADED,
            total_pages=total_pages,
            estimated_completion_time=total_pages * 3  # ä¼°ç®—ï¼šæ¯é¡µ 3 ç§’
        )
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æäº¤å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æäº¤å¤±è´¥: {str(e)}")


async def stream_langgraph_progress(
    batch_id: str,
    run_id: str,
    orchestrator: Orchestrator
):
    """
    æµå¼ç›‘å¬ LangGraph æ‰§è¡Œè¿›åº¦å¹¶æ¨é€åˆ° WebSocket
    
    è¿™æ˜¯å®ç°å®æ—¶è¿›åº¦æ¨é€çš„å…³é”®å‡½æ•°ï¼
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        run_id: LangGraph è¿è¡Œ ID
        orchestrator: LangGraph Orchestrator
    """
    logger.info(f"å¼€å§‹æµå¼ç›‘å¬ LangGraph è¿›åº¦: batch_id={batch_id}, run_id={run_id}")
    
    try:
        # ğŸ”¥ ä½¿ç”¨ LangGraph çš„æµå¼ API
        async for event in orchestrator.stream_run(run_id):
            event_type = event.get("type")
            node_name = event.get("node")
            data = event.get("data", {})
            
            logger.debug(
                f"LangGraph äº‹ä»¶: "
                f"batch_id={batch_id}, "
                f"type={event_type}, "
                f"node={node_name}"
            )
            
            # å°† LangGraph äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯ WebSocket æ¶ˆæ¯
            if event_type == "node_start":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "running",
                    "message": f"æ­£åœ¨æ‰§è¡Œ {_get_node_display_name(node_name)}..."
                })
            
            elif event_type == "node_end":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "completed",
                    "message": f"{_get_node_display_name(node_name)} å®Œæˆ"
                })
                
                # å¤„ç†èŠ‚ç‚¹è¾“å‡º
                output = data.get("output", {})
                if isinstance(output, dict):
                    # è¯„åˆ†æ ‡å‡†è§£æå®Œæˆ
                    if node_name == "rubric_parse" and output.get("parsed_rubric"):
                        parsed = output["parsed_rubric"]
                        await broadcast_progress(batch_id, {
                            "type": "rubric_parsed",
                            "totalQuestions": parsed.get("total_questions", 0),
                            "totalScore": parsed.get("total_score", 0)
                        })
                    
                    # æ‰¹æ”¹æ‰¹æ¬¡å®Œæˆ
                    if node_name == "grade_batch" and output.get("grading_results"):
                        results = output["grading_results"]
                        completed = sum(1 for r in results if r.get("status") == "completed")
                        await broadcast_progress(batch_id, {
                            "type": "batch_completed",
                            "batchSize": len(results),
                            "successCount": completed,
                            "totalScore": sum(r.get("score", 0) for r in results if r.get("status") == "completed"),
                            "pages": [r.get("page_index") for r in results]
                        })
                    
                    # ç´¢å¼•å®Œæˆï¼ˆå­¦ç”Ÿè¯†åˆ«ï¼‰
                    if node_name == "index" and output.get("student_boundaries"):
                        boundaries = output["student_boundaries"]
                        await broadcast_progress(batch_id, {
                            "type": "students_identified",
                            "studentCount": len(boundaries),
                            "students": [
                                {
                                    "studentKey": b.get("student_key", ""),
                                    "startPage": b.get("start_page", 0),
                                    "endPage": b.get("end_page", 0),
                                    "confidence": b.get("confidence", 0),
                                    "needsConfirmation": b.get("needs_confirmation", False)
                                }
                                for b in boundaries
                            ]
                        })
                    
                    # å®¡æ ¸å®Œæˆ
                    if node_name == "review" and output.get("review_summary"):
                        await broadcast_progress(batch_id, {
                            "type": "review_completed",
                            "summary": output["review_summary"]
                        })
                    
                    # è·¨é¡µé¢˜ç›®åˆå¹¶å®Œæˆ
                    if node_name == "cross_page_merge":
                        cross_page_questions = output.get("cross_page_questions", [])
                        merged_questions = output.get("merged_questions", [])
                        if cross_page_questions:
                            await broadcast_progress(batch_id, {
                                "type": "cross_page_detected",
                                "questions": cross_page_questions,
                                "mergedCount": len(merged_questions),
                                "crossPageCount": len(cross_page_questions)
                            })
            
            elif event_type == "state_update":
                # æ¨é€çŠ¶æ€æ›´æ–°
                state = data.get("state", {})
                
                # æ‰¹æ¬¡è¿›åº¦æ›´æ–°
                if state.get("progress"):
                    progress = state["progress"]
                    await broadcast_progress(batch_id, {
                        "type": "batch_progress",
                        "batchIndex": progress.get("current_batch", 0),
                        "totalBatches": progress.get("total_batches", 1),
                        "successCount": progress.get("success_count", 0),
                        "failureCount": progress.get("failure_count", 0)
                    })
                
                # ç™¾åˆ†æ¯”è¿›åº¦
                if state.get("percentage"):
                    await broadcast_progress(batch_id, {
                        "type": "grading_progress",
                        "percentage": state["percentage"],
                        "currentStage": state.get("current_stage", "")
                    })
            
            elif event_type == "error":
                await broadcast_progress(batch_id, {
                    "type": "workflow_error",
                    "message": data.get("error", "Unknown error")
                })
            
            elif event_type == "completed":
                # å·¥ä½œæµå®Œæˆ - è·å–å®Œæ•´çš„æœ€ç»ˆçŠ¶æ€
                final_state = data.get("state", {})
                
                # ä» student_results è·å–ç»“æœ
                student_results = final_state.get("student_results", [])
                
                # å¦‚æœæ²¡æœ‰ student_resultsï¼Œå°è¯•ä» orchestrator è·å–æœ€ç»ˆè¾“å‡º
                if not student_results:
                    try:
                        final_output = await orchestrator.get_final_output(run_id)
                        if final_output:
                            student_results = final_output.get("student_results", [])
                            logger.info(f"ä» orchestrator è·å–åˆ° {len(student_results)} ä¸ªå­¦ç”Ÿç»“æœ")
                    except Exception as e:
                        logger.warning(f"è·å–æœ€ç»ˆè¾“å‡ºå¤±è´¥: {e}")
                
                formatted_results = _format_results_for_frontend(student_results)
                
                await broadcast_progress(batch_id, {
                    "type": "workflow_completed",
                    "message": f"æ‰¹æ”¹å®Œæˆï¼Œå…±å¤„ç† {len(formatted_results)} åå­¦ç”Ÿ",
                    "results": formatted_results
                })
        
        logger.info(f"LangGraph è¿›åº¦æµå¼ä¼ è¾“å®Œæˆ: batch_id={batch_id}")
        
    except Exception as e:
        logger.error(
            f"æµå¼ä¼ è¾“å¤±è´¥: batch_id={batch_id}, error={str(e)}",
            exc_info=True
        )
        await broadcast_progress(batch_id, {
            "type": "workflow_error",
            "message": f"æµå¼ä¼ è¾“å¤±è´¥: {str(e)}"
        })


def _map_node_to_frontend(node_name: str) -> str:
    """å°† LangGraph èŠ‚ç‚¹åç§°æ˜ å°„åˆ°å‰ç«¯èŠ‚ç‚¹ ID
    
    å‰ç«¯å·¥ä½œæµèŠ‚ç‚¹ï¼ˆconsoleStore.ts initialNodesï¼‰ï¼š
    - intake: æ¥æ”¶æ–‡ä»¶
    - preprocess: å›¾åƒé¢„å¤„ç†
    - rubric_parse: è§£æè¯„åˆ†æ ‡å‡†
    - grade_batch: åˆ†æ‰¹å¹¶è¡Œæ‰¹æ”¹ï¼ˆisParallelContainerï¼‰
    - cross_page_merge: è·¨é¡µé¢˜ç›®åˆå¹¶
    - index: æ‰¹æ”¹å‰ç´¢å¼•
    - index_merge: ç´¢å¼•èšåˆ
    - review: ç»“æœå®¡æ ¸
    - export: å¯¼å‡ºç»“æœ
    """
    mapping = {
        # ä¸»è¦èŠ‚ç‚¹ï¼ˆä¸åç«¯ batch_grading.py å®Œå…¨å¯¹åº”ï¼‰
        "intake": "intake",
        "preprocess": "preprocess",
        "rubric_parse": "rubric_parse",
        "grade_batch": "grade_batch",
        "cross_page_merge": "cross_page_merge",
        "index": "index",
        "index_merge": "index_merge",
        "segment": "index_merge",
        "review": "review",
        "export": "export",
        # å…¼å®¹æ—§åç§°
        "detect_boundaries": "index",
        "grade_student": "grade_batch",
        "grading": "grade_batch",
        "aggregate": "review",
        "batch_persist": "export",
        "batch_notify": "export"
    }
    return mapping.get(node_name, node_name)


def _get_node_display_name(node_name: str) -> str:
    """è·å–èŠ‚ç‚¹çš„æ˜¾ç¤ºåç§°ï¼ˆä¸­æ–‡ï¼‰"""
    display_names = {
        "intake": "æ¥æ”¶æ–‡ä»¶",
        "preprocess": "å›¾åƒé¢„å¤„ç†",
        "rubric_parse": "è§£æè¯„åˆ†æ ‡å‡†",
        "grade_batch": "åˆ†æ‰¹å¹¶è¡Œæ‰¹æ”¹",
        "cross_page_merge": "è·¨é¡µé¢˜ç›®åˆå¹¶",
        "index": "ç´¢å¼•å±‚",
        "index_merge": "ç´¢å¼•èšåˆ",
        "segment": "ç´¢å¼•èšåˆ",
        "review": "ç»“æœå®¡æ ¸",
        "export": "å¯¼å‡ºç»“æœ"
    }
    return display_names.get(node_name, node_name)


def _format_results_for_frontend(results: List[Dict]) -> List[Dict]:
    """æ ¼å¼åŒ–æ‰¹æ”¹ç»“æœä¸ºå‰ç«¯æ ¼å¼"""
    formatted = []
    for r in results:
        # å¤„ç† question_details æ ¼å¼
        question_results = []
        
        # ä¼˜å…ˆä½¿ç”¨ question_details
        if r.get("question_details"):
            for q in r.get("question_details", []):
                question_results.append({
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0),
                    "studentAnswer": q.get("student_answer", ""),
                    "isCorrect": q.get("is_correct", False)
                })
        # å…¼å®¹æ—§æ ¼å¼ grading_results
        elif r.get("grading_results"):
            for q in r.get("grading_results", []):
                question_results.append({
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0)
                })
        # ä» page_results æå–
        elif r.get("page_results"):
            for page in r.get("page_results", []):
                if page.get("status") == "completed":
                    # ä»é¡µé¢ç»“æœä¸­æå–é¢˜ç›®è¯¦æƒ…
                    for q in page.get("question_details", []):
                        question_results.append({
                            "questionId": str(q.get("question_id", "")),
                            "score": q.get("score", 0),
                            "maxScore": q.get("max_score", 0),
                            "feedback": q.get("feedback", ""),
                            "confidence": q.get("confidence", 0),
                            "studentAnswer": q.get("student_answer", ""),
                            "isCorrect": q.get("is_correct", False)
                        })
        
        formatted.append({
            "studentName": r.get("student_key") or r.get("student_id", "Unknown"),
            "score": r.get("total_score", 0),
            "maxScore": r.get("max_total_score", 100),
            "questionResults": question_results,
            "confidence": r.get("confidence", 0),
            "needsConfirmation": r.get("needs_confirmation", False)
        })
    return formatted


@router.websocket("/ws/{batch_id}")
async def websocket_endpoint(websocket: WebSocket, batch_id: str):
    """
    WebSocket ç«¯ç‚¹ï¼Œç”¨äºå®æ—¶æ¨é€æ‰¹æ”¹è¿›åº¦
    
    å‰ç«¯é€šè¿‡æ­¤ç«¯ç‚¹æ¥æ”¶ LangGraph çš„å®æ—¶æ‰§è¡Œè¿›åº¦
    """
    await websocket.accept()
    
    # æ³¨å†Œè¿æ¥
    if batch_id not in active_connections:
        active_connections[batch_id] = []
    active_connections[batch_id].append(websocket)
    
    logger.info(f"WebSocket è¿æ¥å»ºç«‹: batch_id={batch_id}")
    
    try:
        # ä¿æŒè¿æ¥ï¼Œç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯æˆ–æ–­å¼€
        while True:
            data = await websocket.receive_text()
            logger.debug(f"æ”¶åˆ° WebSocket æ¶ˆæ¯: batch_id={batch_id}, data={data}")
            
    except WebSocketDisconnect:
        logger.info(f"WebSocket è¿æ¥æ–­å¼€: batch_id={batch_id}")
        active_connections[batch_id].remove(websocket)
        if not active_connections[batch_id]:
            del active_connections[batch_id]


@router.get("/status/{batch_id}", response_model=BatchStatusResponse)
async def get_batch_status(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    æŸ¥è¯¢æ‰¹æ¬¡çŠ¶æ€ï¼ˆä» LangGraph Orchestratorï¼‰
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        BatchStatusResponse: æ‰¹æ¬¡çŠ¶æ€
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ç¼–æ’å™¨æœªåˆå§‹åŒ–")
        
        # æ„å»º run_idï¼ˆä¸ start_run ä¸­çš„æ ¼å¼ä¸€è‡´ï¼‰
        run_id = f"batch_grading_{batch_id}"
        
        # ä» LangGraph Orchestrator æŸ¥è¯¢çŠ¶æ€
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨")
        
        state = run_info.state or {}
        
        return BatchStatusResponse(
            batch_id=batch_id,
            exam_id=state.get("exam_id", ""),
            status=run_info.status.value,
            total_students=len(state.get("student_boundaries", [])),
            completed_students=len(state.get("student_results", [])),
            unidentified_pages=0,
            results=state.get("student_results")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/results/{batch_id}")
async def get_batch_results(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    è·å–æ‰¹æ¬¡æ‰¹æ”¹ç»“æœï¼ˆä» LangGraph Orchestratorï¼‰
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        æ‰¹æ”¹ç»“æœ
    """
    try:
        if not orchestrator:
            raise HTTPException(status_code=503, detail="ç¼–æ’å™¨æœªåˆå§‹åŒ–")
        
        # æ„å»º run_idï¼ˆä¸ start_run ä¸­çš„æ ¼å¼ä¸€è‡´ï¼‰
        run_id = f"batch_grading_{batch_id}"
        
        run_info = await orchestrator.get_run_info(run_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨")
        
        state = run_info.state or {}
        
        # ä¼˜å…ˆä» student_results è·å–ç»“æœ
        student_results = state.get("student_results", [])
        
        # å¦‚æœæ²¡æœ‰ student_resultsï¼Œå°è¯•ä» orchestrator è·å–æœ€ç»ˆè¾“å‡º
        if not student_results:
            try:
                final_output = await orchestrator.get_final_output(run_id)
                if final_output:
                    student_results = final_output.get("student_results", [])
            except Exception as e:
                logger.warning(f"è·å–æœ€ç»ˆè¾“å‡ºå¤±è´¥: {e}")
        
        return {
            "batch_id": batch_id,
            "status": run_info.status.value,
            "results": _format_results_for_frontend(student_results)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ‰¹æ”¹ç»“æœå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")
