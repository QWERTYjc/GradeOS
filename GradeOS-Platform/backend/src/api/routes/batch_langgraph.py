"""æ‰¹é‡æäº¤ API è·¯ç”± - ä½¿ç”¨ LangGraph Orchestrator

æ­£ç¡®çš„æ¶æ„ï¼š
1. ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨æ‰¹æ”¹æµç¨‹
2. é€šè¿‡ LangGraph çš„æµå¼ API å®æ—¶æ¨é€è¿›åº¦
3. åˆ©ç”¨ PostgreSQL Checkpointer å®ç°æŒä¹…åŒ–å’Œæ–­ç‚¹æ¢å¤
"""

import uuid
import logging
import tempfile
import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, WebSocket, WebSocketDisconnect, Depends
from pydantic import BaseModel, Field
import fitz
from PIL import Image
from io import BytesIO
import os

from src.models.enums import SubmissionStatus
from src.orchestration.base import Orchestrator
from src.api.dependencies import get_orchestrator


logger = logging.getLogger(__name__)
router = APIRouter(prefix="/batch", tags=["æ‰¹é‡æäº¤"])

# å­˜å‚¨æ´»è·ƒçš„ WebSocket è¿æ¥
active_connections: Dict[str, List[WebSocket]] = {}


class BatchSubmissionResponse(BaseModel):
    """æ‰¹é‡æäº¤å“åº”"""
    batch_id: str = Field(..., description="æ‰¹æ¬¡ ID")
    status: SubmissionStatus = Field(..., description="çŠ¶æ€")
    total_pages: int = Field(..., description="æ€»é¡µæ•°")
    estimated_completion_time: int = Field(..., description="é¢„è®¡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰")


class BatchStatusResponse(BaseModel):
    """æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å“åº”"""
    batch_id: str
    exam_id: str
    status: str
    total_students: int = Field(0, description="è¯†åˆ«åˆ°çš„å­¦ç”Ÿæ•°")
    completed_students: int = Field(0, description="å·²å®Œæˆæ‰¹æ”¹çš„å­¦ç”Ÿæ•°")
    unidentified_pages: int = Field(0, description="æœªè¯†åˆ«å­¦ç”Ÿçš„é¡µæ•°")
    results: Optional[dict] = Field(None, description="æ‰¹æ”¹ç»“æœ")


def _pdf_to_images(pdf_path: str, dpi: int = 150) -> List[bytes]:
    """å°† PDF è½¬æ¢ä¸ºå›¾åƒåˆ—è¡¨"""
    pdf_doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(pdf_doc)):
        page = pdf_doc[page_num]
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        img_bytes = BytesIO()
        img.save(img_bytes, format='PNG')
        images.append(img_bytes.getvalue())
    
    pdf_doc.close()
    return images


async def broadcast_progress(batch_id: str, message: dict):
    """å‘æ‰€æœ‰è¿æ¥çš„ WebSocket å®¢æˆ·ç«¯å¹¿æ’­è¿›åº¦"""
    if batch_id in active_connections:
        disconnected = []
        for ws in active_connections[batch_id]:
            try:
                await ws.send_json(message)
            except Exception as e:
                logger.error(f"WebSocket å‘é€å¤±è´¥: {e}")
                disconnected.append(ws)
        
        # ç§»é™¤æ–­å¼€çš„è¿æ¥
        for ws in disconnected:
            active_connections[batch_id].remove(ws)


@router.post("/submit", response_model=BatchSubmissionResponse)
async def submit_batch(
    exam_id: Optional[str] = Form(None, description="è€ƒè¯• ID"),
    rubrics: List[UploadFile] = File(..., description="è¯„åˆ†æ ‡å‡† PDF"),
    files: List[UploadFile] = File(..., description="å­¦ç”Ÿä½œç­” PDF"),
    api_key: Optional[str] = Form(None, description="Gemini API Key"),
    auto_identify: bool = Form(True, description="æ˜¯å¦è‡ªåŠ¨è¯†åˆ«å­¦ç”Ÿèº«ä»½"),
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    æ‰¹é‡æäº¤è¯•å·å¹¶è¿›è¡Œæ‰¹æ”¹ï¼ˆä½¿ç”¨ LangGraph Orchestratorï¼‰
    
    æ­£ç¡®çš„æ¶æ„ï¼š
    1. ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨ batch_grading Graph
    2. Graph è‡ªåŠ¨å¤„ç†ï¼šè¾¹ç•Œæ£€æµ‹ â†’ å¹¶è¡Œæ‰¹æ”¹ â†’ èšåˆ â†’ æŒä¹…åŒ– â†’ é€šçŸ¥
    3. é€šè¿‡ WebSocket å®æ—¶æ¨é€ LangGraph çš„æ‰§è¡Œè¿›åº¦
    
    Args:
        exam_id: è€ƒè¯• ID
        rubrics: è¯„åˆ†æ ‡å‡† PDF æ–‡ä»¶åˆ—è¡¨
        files: å­¦ç”Ÿä½œç­” PDF æ–‡ä»¶åˆ—è¡¨
        api_key: Gemini API Key
        auto_identify: æ˜¯å¦å¯ç”¨è‡ªåŠ¨å­¦ç”Ÿè¯†åˆ«
        orchestrator: LangGraph Orchestratorï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        
    Returns:
        BatchSubmissionResponse: æ‰¹æ¬¡ä¿¡æ¯
    """
    if not api_key:
        api_key = os.getenv("GEMINI_API_KEY")

    if not exam_id:
        exam_id = str(uuid.uuid4())

    batch_id = str(uuid.uuid4())
    
    logger.info(
        f"æ”¶åˆ°æ‰¹é‡æäº¤ï¼ˆLangGraphï¼‰: "
        f"batch_id={batch_id}, "
        f"exam_id={exam_id}, "
        f"auto_identify={auto_identify}"
    )
    
    temp_dir = None
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        temp_path = Path(temp_dir)
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        rubric_path = temp_path / "rubric.pdf"
        answer_path = temp_path / "answer.pdf"
        
        rubric_content = await rubrics[0].read()
        answer_content = await files[0].read()
        
        with open(rubric_path, "wb") as f:
            f.write(rubric_content)
        with open(answer_path, "wb") as f:
            f.write(answer_content)
        
        # è½¬æ¢ PDF ä¸ºå›¾åƒ
        logger.info(f"è½¬æ¢ PDF ä¸ºå›¾åƒ: batch_id={batch_id}")
        loop = asyncio.get_event_loop()
        rubric_images = await loop.run_in_executor(None, _pdf_to_images, str(rubric_path), 150)
        answer_images = await loop.run_in_executor(None, _pdf_to_images, str(answer_path), 150)
        
        total_pages = len(answer_images)
        
        logger.info(
            f"PDF è½¬æ¢å®Œæˆ: "
            f"batch_id={batch_id}, "
            f"rubric_pages={len(rubric_images)}, "
            f"answer_pages={total_pages}"
        )
        
        # ğŸš€ ä½¿ç”¨ LangGraph Orchestrator å¯åŠ¨æ‰¹æ”¹æµç¨‹
        payload = {
            "batch_id": batch_id,
            "exam_id": exam_id,
            "pdf_path": str(answer_path),
            "rubric_images": rubric_images,
            "answer_images": answer_images,
            "api_key": api_key,
            "inputs": {
                "pdf_path": str(answer_path),
                "rubric": "rubric_content",  # TODO: è§£æ rubric
                "auto_identify": auto_identify
            }
        }
        
        # å¯åŠ¨ LangGraph batch_grading Graph
        run_id = await orchestrator.start_run(
            graph_name="batch_grading",
            payload=payload,
            idempotency_key=batch_id
        )
        
        logger.info(
            f"LangGraph æ‰¹æ”¹æµç¨‹å·²å¯åŠ¨: "
            f"batch_id={batch_id}, "
            f"run_id={run_id}"
        )
        
        # å¯åŠ¨åå°ä»»åŠ¡ç›‘å¬ LangGraph è¿›åº¦å¹¶æ¨é€åˆ° WebSocket
        asyncio.create_task(
            stream_langgraph_progress(
                batch_id=batch_id,
                run_id=run_id,
                orchestrator=orchestrator
            )
        )
        
        return BatchSubmissionResponse(
            batch_id=batch_id,
            status=SubmissionStatus.UPLOADED,
            total_pages=total_pages,
            estimated_completion_time=total_pages * 3  # ä¼°ç®—ï¼šæ¯é¡µ 3 ç§’
        )
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æäº¤å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æäº¤å¤±è´¥: {str(e)}")


async def stream_langgraph_progress(
    batch_id: str,
    run_id: str,
    orchestrator: Orchestrator
):
    """
    æµå¼ç›‘å¬ LangGraph æ‰§è¡Œè¿›åº¦å¹¶æ¨é€åˆ° WebSocket
    
    è¿™æ˜¯å®ç°å®æ—¶è¿›åº¦æ¨é€çš„å…³é”®å‡½æ•°ï¼
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        run_id: LangGraph è¿è¡Œ ID
        orchestrator: LangGraph Orchestrator
    """
    logger.info(f"å¼€å§‹æµå¼ç›‘å¬ LangGraph è¿›åº¦: batch_id={batch_id}, run_id={run_id}")
    
    try:
        # ğŸ”¥ ä½¿ç”¨ LangGraph çš„æµå¼ API
        async for event in orchestrator.stream_run(run_id):
            event_type = event.get("type")
            node_name = event.get("node")
            data = event.get("data", {})
            
            logger.debug(
                f"LangGraph äº‹ä»¶: "
                f"batch_id={batch_id}, "
                f"type={event_type}, "
                f"node={node_name}"
            )
            
            # å°† LangGraph äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯ WebSocket æ¶ˆæ¯
            if event_type == "node_start":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "running",
                    "message": f"æ­£åœ¨æ‰§è¡Œ {node_name}..."
                })
            
            elif event_type == "node_end":
                await broadcast_progress(batch_id, {
                    "type": "workflow_update",
                    "nodeId": _map_node_to_frontend(node_name),
                    "status": "completed",
                    "message": f"{node_name} å®Œæˆ"
                })
            
            elif event_type == "state_update":
                # æ¨é€çŠ¶æ€æ›´æ–°
                state = data.get("state", {})
                
                # è¯„åˆ†æ ‡å‡†è§£æå®Œæˆ
                if state.get("rubric_parsed"):
                    await broadcast_progress(batch_id, {
                        "type": "rubric_parsed",
                        "totalQuestions": state.get("total_questions", 0),
                        "totalScore": state.get("total_score", 0)
                    })
                
                # å­¦ç”Ÿè¾¹ç•Œè¯†åˆ«å®Œæˆ
                if state.get("student_boundaries"):
                    await broadcast_progress(batch_id, {
                        "type": "student_identified",
                        "boundaries": state["student_boundaries"]
                    })
                
                # æ‰¹æ¬¡è¿›åº¦æ›´æ–°
                if state.get("progress"):
                    progress = state["progress"]
                    await broadcast_progress(batch_id, {
                        "type": "batch_progress",
                        "batchIndex": progress.get("current_batch", 0),
                        "totalBatches": progress.get("total_batches", 1),
                        "successCount": progress.get("success_count", 0),
                        "failureCount": progress.get("failure_count", 0)
                    })
            
            elif event_type == "error":
                await broadcast_progress(batch_id, {
                    "type": "workflow_error",
                    "message": data.get("error", "Unknown error")
                })
            
            elif event_type == "completed":
                # å·¥ä½œæµå®Œæˆ
                final_state = data.get("state", {})
                results = final_state.get("batch_results", [])
                
                await broadcast_progress(batch_id, {
                    "type": "workflow_completed",
                    "message": f"æ‰¹æ”¹å®Œæˆï¼Œå…±å¤„ç† {len(results)} åå­¦ç”Ÿ",
                    "results": _format_results_for_frontend(results)
                })
        
        logger.info(f"LangGraph è¿›åº¦æµå¼ä¼ è¾“å®Œæˆ: batch_id={batch_id}")
        
    except Exception as e:
        logger.error(
            f"æµå¼ä¼ è¾“å¤±è´¥: batch_id={batch_id}, error={str(e)}",
            exc_info=True
        )
        await broadcast_progress(batch_id, {
            "type": "workflow_error",
            "message": f"æµå¼ä¼ è¾“å¤±è´¥: {str(e)}"
        })


def _map_node_to_frontend(node_name: str) -> str:
    """å°† LangGraph èŠ‚ç‚¹åç§°æ˜ å°„åˆ°å‰ç«¯èŠ‚ç‚¹ ID"""
    mapping = {
        "detect_boundaries": "segment",
        "grade_student": "grading",
        "aggregate": "review",
        "batch_persist": "persist",
        "batch_notify": "export"
    }
    return mapping.get(node_name, node_name)


def _format_results_for_frontend(results: List[Dict]) -> List[Dict]:
    """æ ¼å¼åŒ–æ‰¹æ”¹ç»“æœä¸ºå‰ç«¯æ ¼å¼"""
    formatted = []
    for r in results:
        formatted.append({
            "studentName": r.get("student_id", "Unknown"),
            "score": r.get("total_score", 0),
            "maxScore": r.get("max_total_score", 100),
            "questionResults": [
                {
                    "questionId": str(q.get("question_id", "")),
                    "score": q.get("score", 0),
                    "maxScore": q.get("max_score", 0),
                    "feedback": q.get("feedback", ""),
                    "confidence": q.get("confidence", 0)
                }
                for q in r.get("grading_results", [])
            ]
        })
    return formatted


@router.websocket("/ws/{batch_id}")
async def websocket_endpoint(websocket: WebSocket, batch_id: str):
    """
    WebSocket ç«¯ç‚¹ï¼Œç”¨äºå®æ—¶æ¨é€æ‰¹æ”¹è¿›åº¦
    
    å‰ç«¯é€šè¿‡æ­¤ç«¯ç‚¹æ¥æ”¶ LangGraph çš„å®æ—¶æ‰§è¡Œè¿›åº¦
    """
    await websocket.accept()
    
    # æ³¨å†Œè¿æ¥
    if batch_id not in active_connections:
        active_connections[batch_id] = []
    active_connections[batch_id].append(websocket)
    
    logger.info(f"WebSocket è¿æ¥å»ºç«‹: batch_id={batch_id}")
    
    try:
        # ä¿æŒè¿æ¥ï¼Œç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯æˆ–æ–­å¼€
        while True:
            data = await websocket.receive_text()
            logger.debug(f"æ”¶åˆ° WebSocket æ¶ˆæ¯: batch_id={batch_id}, data={data}")
            
    except WebSocketDisconnect:
        logger.info(f"WebSocket è¿æ¥æ–­å¼€: batch_id={batch_id}")
        active_connections[batch_id].remove(websocket)
        if not active_connections[batch_id]:
            del active_connections[batch_id]


@router.get("/status/{batch_id}", response_model=BatchStatusResponse)
async def get_batch_status(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    æŸ¥è¯¢æ‰¹æ¬¡çŠ¶æ€ï¼ˆä» LangGraph Orchestratorï¼‰
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        BatchStatusResponse: æ‰¹æ¬¡çŠ¶æ€
    """
    try:
        # ä» LangGraph Orchestrator æŸ¥è¯¢çŠ¶æ€
        run_info = await orchestrator.get_run_info(batch_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨")
        
        state = run_info.state or {}
        
        return BatchStatusResponse(
            batch_id=batch_id,
            exam_id=state.get("exam_id", ""),
            status=run_info.status.value,
            total_students=len(state.get("student_boundaries", [])),
            completed_students=len(state.get("completed_submissions", [])),
            unidentified_pages=0,
            results=state.get("batch_results")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/results/{batch_id}")
async def get_batch_results(
    batch_id: str,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    """
    è·å–æ‰¹æ¬¡æ‰¹æ”¹ç»“æœï¼ˆä» LangGraph Orchestratorï¼‰
    
    Args:
        batch_id: æ‰¹æ¬¡ ID
        orchestrator: LangGraph Orchestrator
        
    Returns:
        æ‰¹æ”¹ç»“æœ
    """
    try:
        run_info = await orchestrator.get_run_info(batch_id)
        
        if not run_info:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨")
        
        state = run_info.state or {}
        results = state.get("batch_results", [])
        
        return {
            "batch_id": batch_id,
            "status": run_info.status.value,
            "results": _format_results_for_frontend(results)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ‰¹æ”¹ç»“æœå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")
