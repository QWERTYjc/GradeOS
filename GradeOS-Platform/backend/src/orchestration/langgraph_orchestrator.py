"""LangGraph Orchestrator å®ç°

å®ç° Orchestrator æŠ½è±¡æ¥å£ï¼Œä½¿ç”¨ LangGraph ä½œä¸ºç¼–æ’å¼•æ“ã€‚
æ”¯æŒåå°æ‰§è¡Œã€çŠ¶æ€æŸ¥è¯¢ã€å–æ¶ˆã€é‡è¯•ã€äººå·¥ä»‹å…¥ç­‰èƒ½åŠ›ã€‚

éªŒè¯ï¼šéœ€æ±‚ 1.1, 1.2, 1.3, 1.4, 1.5, 1.6
"""

import logging
import uuid
import asyncio
import os
from typing import Any, Dict, List, Optional
from datetime import datetime
import json

from langgraph.graph import StateGraph
from langgraph.types import Command, interrupt
from langgraph.checkpoint.memory import InMemorySaver

from src.orchestration.base import Orchestrator, RunStatus, RunInfo


logger = logging.getLogger(__name__)


class LangGraphOrchestrator(Orchestrator):
    """LangGraph ç¼–æ’å™¨å®ç°

    ä½¿ç”¨ LangGraph ä½œä¸ºç¼–æ’å¼•æ“ï¼Œå®ç° Orchestrator æ¥å£ã€‚
    å°† LangGraph çš„ Graph æ¦‚å¿µæ˜ å°„åˆ° Orchestrator çš„ Run æ¦‚å¿µã€‚

    ç‰¹æ€§ï¼š
    - æŒä¹…åŒ–æ‰§è¡Œï¼ˆPostgresSaverï¼‰
    - åå°è¿è¡Œï¼ˆasyncio.create_taskï¼‰
    - çŠ¶æ€æŸ¥è¯¢ï¼ˆcheckpointer.getï¼‰
    - å–æ¶ˆ/é‡è¯•ï¼ˆrun è¡¨ç®¡ç†ï¼‰
    - äººå·¥ä»‹å…¥ï¼ˆinterrupt + resumeï¼‰

    éªŒè¯ï¼šéœ€æ±‚ 1.1, 1.2, 1.3, 1.4, 1.5, 1.6
    """

    def __init__(
        self,
        db_pool: Optional[Any] = None,  # æ”¹ä¸º Any ä»¥æ”¯æŒç¦»çº¿æ¨¡å¼
        checkpointer: Optional[Any] = None,
        offline_mode: bool = False,
    ):
        """åˆå§‹åŒ– LangGraph Orchestrator

        Args:
            db_pool: PostgreSQL è¿æ¥æ± ï¼ˆç”¨äº run/attempt è¡¨ï¼Œå¯é€‰ï¼‰
            checkpointer: LangGraph Checkpointerï¼ˆç”¨äºçŠ¶æ€æŒä¹…åŒ–ï¼Œå¯é€‰ï¼‰
            offline_mode: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆè·³è¿‡æ‰€æœ‰æ•°æ®åº“æ“ä½œï¼‰
        """
        self.db_pool = db_pool if not offline_mode else None
        self.checkpointer = checkpointer or self._create_default_checkpointer()
        self._offline_mode = offline_mode

        # Graph åç§°åˆ°ç¼–è¯‘å Graph çš„æ˜ å°„
        self._graph_registry: Dict[str, Any] = {}

        # åå°ä»»åŠ¡ç®¡ç†
        self._background_tasks: Dict[str, asyncio.Task] = {}

        # å†…å­˜ä¸­çš„ run è®°å½•ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
        self._runs: Dict[str, Dict[str, Any]] = {}

        # äº‹ä»¶é˜Ÿåˆ—ï¼ˆç”¨äºå®æ—¶æµå¼æ¨é€ï¼‰
        self._event_queues: Dict[str, asyncio.Queue] = {}
        self._event_stream_complete: Dict[str, bool] = {}
        max_active_runs = int(os.getenv("RUN_MAX_CONCURRENCY", "100"))
        if max_active_runs > 0:
            self._run_semaphore = asyncio.Semaphore(max_active_runs)
        else:
            self._run_semaphore = None
        self._graph_max_concurrency = int(os.getenv("LANGGRAPH_MAX_CONCURRENCY", "8"))
        self._graph_recursion_limit = int(os.getenv("LANGGRAPH_RECURSION_LIMIT", "50"))
        self._auto_resume_enabled = os.getenv("LANGGRAPH_AUTO_RESUME", "true").strip().lower() in (
            "1",
            "true",
            "yes",
        )
        self._auto_resume_limit = int(os.getenv("LANGGRAPH_AUTO_RESUME_LIMIT", "25"))

        if offline_mode:
            logger.info("LangGraphOrchestrator å·²åˆå§‹åŒ–ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
        else:
            logger.info("LangGraphOrchestrator å·²åˆå§‹åŒ–")

    def _create_default_checkpointer(self) -> InMemorySaver:
        """åˆ›å»ºé»˜è®¤ Checkpointer"""
        return InMemorySaver()

    @staticmethod
    def _json_serializer(obj):
        """è‡ªå®šä¹‰ JSON åºåˆ—åŒ–å™¨ï¼Œå¤„ç† bytes å’Œå…¶ä»–ç‰¹æ®Šç±»å‹"""
        if isinstance(obj, bytes):
            # å°† bytes è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²
            import base64
            return base64.b64encode(obj).decode('utf-8')
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        else:
            return str(obj)

    def _build_graph_config(self, run_id: str, graph_name: str) -> Dict[str, Any]:
        config: Dict[str, Any] = {"configurable": {"thread_id": run_id}}
        max_concurrency = self._graph_max_concurrency
        if graph_name == "batch_grading":
            override = os.getenv("GRADING_MAX_WORKERS")
            if override is not None:
                try:
                    max_concurrency = int(override)
                except ValueError:
                    pass
        if max_concurrency > 0:
            config["max_concurrency"] = max_concurrency
        if self._graph_recursion_limit > 0:
            config["recursion_limit"] = self._graph_recursion_limit
        return config

    def register_graph(self, graph_name: str, compiled_graph: Any):
        """æ³¨å†Œç¼–è¯‘åçš„ Graph

        Args:
            graph_name: Graph åç§°ï¼ˆå¦‚ "exam_paper"ï¼‰
            compiled_graph: ç¼–è¯‘åçš„ LangGraph Graph
        """
        self._graph_registry[graph_name] = compiled_graph
        logger.info(f"å·²æ³¨å†Œ Graph: {graph_name}")

    async def start_run(
        self, graph_name: str, payload: Dict[str, Any], idempotency_key: Optional[str] = None
    ) -> str:
        """å¯åŠ¨ LangGraph Graph æ‰§è¡Œ

        Args:
            graph_name: Graph åç§°
            payload: Graph è¾“å…¥æ•°æ®
            idempotency_key: å¹‚ç­‰é”®ï¼ˆå¯é€‰ï¼‰

        Returns:
            run_id: æ‰§è¡Œ IDï¼ˆå³ thread_idï¼‰

        Raises:
            ValueError: å½“ graph_name æœªæ³¨å†Œæ—¶
            Exception: å¯åŠ¨å¤±è´¥æ—¶

        éªŒè¯ï¼šéœ€æ±‚ 1.1
        """
        # æ£€æŸ¥ Graph æ˜¯å¦å·²æ³¨å†Œ
        if graph_name not in self._graph_registry:
            raise ValueError(f"æœªæ³¨å†Œçš„ Graph: {graph_name}")

        compiled_graph = self._graph_registry[graph_name]

        # ç”Ÿæˆ run_idï¼ˆä½¿ç”¨å¹‚ç­‰é”®æˆ–ç”Ÿæˆæ–°çš„ UUIDï¼‰
        if idempotency_key:
            run_id = f"{graph_name}_{idempotency_key}"
        else:
            run_id = str(uuid.uuid4())

        logger.info(
            f"å¯åŠ¨ LangGraph Graph: "
            f"graph_name={graph_name}, "
            f"run_id={run_id}, "
            f"idempotency_key={idempotency_key}"
        )

        try:
            # æ£€æŸ¥å¹‚ç­‰æ€§ï¼šå¦‚æœ run å·²å­˜åœ¨ä¸”æœªå®Œæˆï¼Œè¿”å›ç°æœ‰ run_id
            existing_run = await self._get_run_from_db(run_id)
            if existing_run and existing_run["status"] in ["pending", "running", "paused"]:
                logger.info(
                    f"Run å·²å­˜åœ¨ï¼ˆå¹‚ç­‰æ€§ï¼‰: "
                    f"run_id={run_id}, "
                    f"status={existing_run['status']}"
                )
                return run_id

            # åˆ›å»º run è®°å½•
            await self._create_run_in_db(run_id=run_id, graph_name=graph_name, input_data=payload)

            # å¯åŠ¨åå°ä»»åŠ¡æ‰§è¡Œ Graph
            task = asyncio.create_task(
                self._run_graph_background(
                    run_id=run_id,
                    graph_name=graph_name,
                    compiled_graph=compiled_graph,
                    payload=payload,
                )
            )

            self._background_tasks[run_id] = task

            logger.info(f"Graph å·²å¯åŠ¨: run_id={run_id}")
            return run_id

        except Exception as e:
            logger.error(f"å¯åŠ¨ Graph å¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True)
            raise

    async def _run_graph_background(
        self, run_id: str, graph_name: str, compiled_graph: Any, payload: Dict[str, Any]
    ):
        """åå°æ‰§è¡Œ Graphï¼ˆæ”¯æŒå®æ—¶äº‹ä»¶æ¨é€ï¼‰

        Args:
            run_id: æ‰§è¡Œ ID
            graph_name: Graph åç§°
            compiled_graph: ç¼–è¯‘åçš„ Graph
            payload: è¾“å…¥æ•°æ®
        """
        paused = False  # åˆå§‹åŒ–ï¼Œé¿å… finally ä¸­ UnboundLocalError
        acquired = False
        try:
            if self._run_semaphore:
                await self._run_semaphore.acquire()
                acquired = True
            # æ›´æ–°çŠ¶æ€ä¸º running
            await self._update_run_status(run_id, "running")

            # é…ç½® thread_id + LangGraph å†…å»ºå¹¶å‘æ§åˆ¶
            config = self._build_graph_config(run_id, graph_name)

            # æ‰§è¡Œ Graphï¼ˆä½¿ç”¨ astream_events è·å–è¯¦ç»†äº‹ä»¶ï¼‰
            logger.info(f"å¼€å§‹æ‰§è¡Œ Graph: run_id={run_id}")

            result = None
            accumulated_state = dict(payload)  # ä»åˆå§‹ payload å¼€å§‹ç´¯ç§¯çŠ¶æ€

            # ä½¿ç”¨ astream_events è·å–è¯¦ç»†çš„æ‰§è¡Œäº‹ä»¶
            async for event in compiled_graph.astream_events(payload, config=config, version="v2"):
                event_kind = event.get("event")
                event_name = event.get("name", "")
                event_data = event.get("data", {})

                # å°†äº‹ä»¶å­˜å‚¨åˆ°å†…å­˜é˜Ÿåˆ—ï¼ˆä¾› stream_run ä½¿ç”¨ï¼‰
                await self._push_event(
                    run_id, {"kind": event_kind, "name": event_name, "data": event_data}
                )

                # æ£€æŸ¥æ˜¯å¦æœ‰ interrupt
                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict) and "__interrupt__" in output:
                        logger.info(f"Graph ä¸­æ–­: run_id={run_id}")
                        paused = True
                        await self._update_run_status(run_id, "paused")
                        return  # ç­‰å¾…å¤–éƒ¨ resume

                # å¤„ç† LLM æµå¼è¾“å‡º (Requirement: å…¨æµç¨‹æµå¼)
                if event_kind == "on_chat_model_stream":
                    chunk = event_data.get("chunk")
                    if chunk:
                        # å°è¯•ä» chunk ä¸­æå–å†…å®¹
                        content = ""
                        if hasattr(chunk, "content"):
                            content = chunk.content
                        elif isinstance(chunk, dict) and "content" in chunk:
                            content = chunk["content"]
                        elif isinstance(chunk, str):
                            content = chunk

                        if content:
                            await self._push_event(
                                run_id,
                                {
                                    "kind": "llm_stream",
                                    "name": event_name,
                                    "data": {
                                        "chunk": content,
                                        "node": event.get("metadata", {}).get("langgraph_node", ""),
                                    },
                                },
                            )

                # ç´¯ç§¯èŠ‚ç‚¹è¾“å‡ºåˆ°çŠ¶æ€
                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict):
                        # åˆå¹¶è¾“å‡ºåˆ°ç´¯ç§¯çŠ¶æ€
                        for key, value in output.items():
                            # å¯¹ä½¿ç”¨ operator.add reducer çš„å­—æ®µä½¿ç”¨è¿½åŠ é€»è¾‘
                            # grading_results å’Œ student_results éƒ½ä½¿ç”¨äº† operator.add reducer
                            if (
                                key in ("grading_results", "student_results")
                                and key in accumulated_state
                                and isinstance(accumulated_state[key], list)
                                and isinstance(value, list)
                            ):
                                # è¿½åŠ åˆ—è¡¨ç»“æœ
                                accumulated_state[key].extend(value)
                            else:
                                # å…¶ä»–ç±»å‹ï¼šè¦†ç›–
                                accumulated_state[key] = value

                # ä¿å­˜æœ€åçš„ç»“æœ
                if event_kind == "on_chain_end" and event_name == graph_name:
                    result = event_data.get("output", {})

            # å¾ªç¯ç»“æŸåå†æ¬¡æ£€æŸ¥ Graph çŠ¶æ€
            # astream_events å¯èƒ½åœ¨ interrupt æ—¶æ­£å¸¸ç»“æŸå¾ªç¯ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ get_state ç¡®è®¤æ˜¯å¦çœŸçš„å®Œæˆäº†
            snapshot = await compiled_graph.aget_state(config)
            if snapshot.next:
                logger.info(
                    f"Graph ä¸­æ–­ (detected via state): run_id={run_id}, next={snapshot.next}"
                )
                paused = True
                await self._update_run_status(run_id, "paused")

                # å°è¯•è·å– interrupt payload
                interrupt_value = None
                if (
                    snapshot.tasks
                    and hasattr(snapshot.tasks[0], "interrupts")
                    and snapshot.tasks[0].interrupts
                ):
                    # interrupts is usually a tuple or list
                    interrupt_value = (
                        snapshot.tasks[0].interrupts[0] if snapshot.tasks[0].interrupts else None
                    )

                await self._push_event(
                    run_id,
                    {
                        "kind": "paused",
                        "name": None,
                        "data": {"state": snapshot.values, "interrupt_value": interrupt_value},
                    },
                )
                return

            # æ‰§è¡Œå®Œæˆ - ä½¿ç”¨ç´¯ç§¯çš„å®Œæ•´çŠ¶æ€
            logger.info(f"Graph æ‰§è¡Œå®Œæˆ: run_id={run_id}")

            await self._update_run_status(run_id, "completed", output_data=accumulated_state)

            # æ ‡è®°äº‹ä»¶æµç»“æŸ - ä¼ é€’å®Œæ•´çŠ¶æ€
            await self._push_event(
                run_id, {"kind": "completed", "name": None, "data": {"state": accumulated_state}}
            )

        except Exception as e:
            logger.error(f"Graph æ‰§è¡Œå¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True)
            await self._update_run_status(run_id, "failed", error=str(e))

            # æ¨é€é”™è¯¯äº‹ä»¶
            await self._push_event(
                run_id, {"kind": "error", "name": None, "data": {"error": str(e)}}
            )

        finally:
            if acquired and self._run_semaphore:
                self._run_semaphore.release()
            # æ¸…ç†åå°ä»»åŠ¡
            self._background_tasks.pop(run_id, None)

            # æ ‡è®°äº‹ä»¶æµç»“æŸï¼ˆå¦‚æœè¿˜æ²¡æ ‡è®°ï¼‰
            if not paused:
                await self._mark_event_stream_complete(run_id)

    async def _resume_from_checkpoint_background(
        self,
        run_id: str,
        graph_name: str,
        compiled_graph: Any,
        config: Dict[str, Any],
    ) -> None:
        """ä» Checkpointer æ¢å¤ Graph æ‰§è¡Œï¼ˆè‡ªåŠ¨æ–­ç‚¹ç»­è·‘ï¼‰"""
        paused = False
        acquired = False
        try:
            if self._run_semaphore:
                await self._run_semaphore.acquire()
                acquired = True
            await self._update_run_status(run_id, "running")

            logger.info(f"æ¢å¤æ‰§è¡Œ Graph: run_id={run_id}")

            accumulated_state = await self.get_state(run_id) or {}
            if not accumulated_state:
                run = await self._get_run_from_db(run_id)
                if run and run.get("input_data"):
                    accumulated_state = run.get("input_data", {})
                    if isinstance(accumulated_state, str):
                        try:
                            accumulated_state = json.loads(accumulated_state)
                        except json.JSONDecodeError:
                            accumulated_state = {}

            result = None
            async for event in compiled_graph.astream_events(None, config=config, version="v2"):
                event_kind = event.get("event")
                event_name = event.get("name", "")
                event_data = event.get("data", {})

                await self._push_event(
                    run_id,
                    {
                        "kind": event_kind,
                        "name": event_name,
                        "data": event_data,
                    },
                )

                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict) and "__interrupt__" in output:
                        logger.info(f"Graph ä¸­æ–­: run_id={run_id}")
                        paused = True
                        await self._update_run_status(run_id, "paused")
                        return

                if event_kind == "on_chat_model_stream":
                    chunk = event_data.get("chunk")
                    if chunk:
                        content = ""
                        if hasattr(chunk, "content"):
                            content = chunk.content
                        elif isinstance(chunk, dict) and "content" in chunk:
                            content = chunk["content"]
                        elif isinstance(chunk, str):
                            content = chunk
                        if content:
                            await self._push_event(
                                run_id,
                                {
                                    "kind": "llm_stream",
                                    "name": event_name,
                                    "data": {
                                        "chunk": content,
                                        "node": event.get("metadata", {}).get("langgraph_node", ""),
                                    },
                                },
                            )

                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict):
                        for key, value in output.items():
                            if (
                                key == "grading_results"
                                and key in accumulated_state
                                and isinstance(accumulated_state[key], list)
                                and isinstance(value, list)
                            ):
                                accumulated_state[key].extend(value)
                            else:
                                accumulated_state[key] = value

                if event_kind == "on_chain_end" and event_name == graph_name:
                    result = event_data.get("output", {})

            snapshot = await compiled_graph.aget_state(config)
            if snapshot.next:
                logger.info(
                    f"Graph ä¸­æ–­ (detected via state): run_id={run_id}, next={snapshot.next}"
                )
                paused = True
                await self._update_run_status(run_id, "paused")
                interrupt_value = None
                if (
                    snapshot.tasks
                    and hasattr(snapshot.tasks[0], "interrupts")
                    and snapshot.tasks[0].interrupts
                ):
                    interrupt_value = (
                        snapshot.tasks[0].interrupts[0] if snapshot.tasks[0].interrupts else None
                    )
                await self._push_event(
                    run_id,
                    {
                        "kind": "paused",
                        "name": None,
                        "data": {
                            "state": snapshot.values,
                            "interrupt_value": interrupt_value,
                        },
                    },
                )
                return

            logger.info(f"Graph æ‰§è¡Œå®Œæˆ: run_id={run_id}")
            await self._update_run_status(run_id, "completed", output_data=accumulated_state)
            await self._push_event(
                run_id, {"kind": "completed", "name": None, "data": {"state": accumulated_state}}
            )

        except Exception as exc:
            logger.error(
                f"Graph æ¢å¤å¤±è´¥: run_id={run_id}, error={str(exc)}",
                exc_info=True,
            )
            await self._update_run_status(run_id, "failed", error=str(exc))
            await self._push_event(
                run_id, {"kind": "error", "name": None, "data": {"error": str(exc)}}
            )
        finally:
            if acquired and self._run_semaphore:
                self._run_semaphore.release()
            self._background_tasks.pop(run_id, None)
            if not paused:
                await self._mark_event_stream_complete(run_id)

    async def get_status(self, run_id: str) -> RunInfo:
        """æŸ¥è¯¢ Graph æ‰§è¡ŒçŠ¶æ€

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            RunInfo: æ‰§è¡Œä¿¡æ¯

        Raises:
            Exception: æŸ¥è¯¢å¤±è´¥æˆ– run_id ä¸å­˜åœ¨æ—¶

        éªŒè¯ï¼šéœ€æ±‚ 1.2
        """
        try:
            # ä»æ•°æ®åº“æŸ¥è¯¢ run è®°å½•
            run = await self._get_run_from_db(run_id)
            if not run:
                raise ValueError(f"Run ä¸å­˜åœ¨: {run_id}")

            # ä» Checkpointer æŸ¥è¯¢è¿›åº¦ä¿¡æ¯
            progress = {}
            try:
                config = {"configurable": {"thread_id": run_id}}
                checkpoint = await self.checkpointer.aget(config)
                if checkpoint:
                    channel_values = checkpoint.get("channel_values", {})
                    progress = channel_values.get("progress", {})
            except Exception as e:
                logger.debug(f"æŸ¥è¯¢ Checkpoint å¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}")

            # æ˜ å°„çŠ¶æ€
            status_map = {
                "pending": RunStatus.PENDING,
                "running": RunStatus.RUNNING,
                "paused": RunStatus.PAUSED,
                "completed": RunStatus.COMPLETED,
                "failed": RunStatus.FAILED,
                "cancelled": RunStatus.CANCELLED,
            }
            status = status_map.get(run["status"], RunStatus.PENDING)

            # æ„å»º RunInfo
            run_info = RunInfo(
                run_id=run_id,
                graph_name=run["graph_name"],
                status=status,
                progress=progress,
                created_at=run["created_at"],
                updated_at=run["updated_at"],
                error=run.get("error"),
            )

            return run_info

        except Exception as e:
            logger.error(
                f"æŸ¥è¯¢ Graph çŠ¶æ€å¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True
            )
            raise

    async def get_final_output(self, run_id: str) -> Optional[Dict[str, Any]]:
        """è·å– Graph æ‰§è¡Œçš„æœ€ç»ˆè¾“å‡º

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            æœ€ç»ˆè¾“å‡ºæ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        try:
            # é¦–å…ˆä»å†…å­˜ä¸­è·å–
            if run_id in self._runs:
                run_data = self._runs[run_id]
                output_data = run_data.get("output_data")
                if output_data:
                    logger.info(
                        f"ä»å†…å­˜è·å–æœ€ç»ˆè¾“å‡º: run_id={run_id}, keys={list(output_data.keys())}"
                    )
                    return output_data

            # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ•°æ®åº“è·å–
            run = await self._get_run_from_db(run_id)
            if run and run.get("output_data"):
                logger.info(f"ä»æ•°æ®åº“è·å–æœ€ç»ˆè¾“å‡º: run_id={run_id}")
                return run["output_data"]

            logger.warning(f"æœªæ‰¾åˆ°æœ€ç»ˆè¾“å‡º: run_id={run_id}")
            return None

        except Exception as e:
            logger.error(f"è·å–æœ€ç»ˆè¾“å‡ºå¤±è´¥: run_id={run_id}, error={e}")
            return None

    async def cancel(self, run_id: str) -> bool:
        """å–æ¶ˆ Graph æ‰§è¡Œ

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸå–æ¶ˆ

        éªŒè¯ï¼šéœ€æ±‚ 1.3
        """
        try:
            # å–æ¶ˆåå°ä»»åŠ¡
            task = self._background_tasks.get(run_id)
            if task and not task.done():
                task.cancel()
                logger.info(f"åå°ä»»åŠ¡å·²å–æ¶ˆ: run_id={run_id}")

            # æ›´æ–°çŠ¶æ€
            await self._update_run_status(run_id, "cancelled")

            logger.info(f"Graph å·²å–æ¶ˆ: run_id={run_id}")
            return True

        except Exception as e:
            logger.error(f"å–æ¶ˆ Graph å¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True)
            return False

    async def retry(self, run_id: str) -> str:
        """é‡è¯•å¤±è´¥çš„ Graph

        Args:
            run_id: åŸæ‰§è¡Œ ID

        Returns:
            str: æ–°çš„æ‰§è¡Œ ID

        Raises:
            Exception: é‡è¯•å¤±è´¥æ—¶

        éªŒè¯ï¼šéœ€æ±‚ 1.4
        """
        try:
            # è·å–åŸ run è®°å½•
            run = await self._get_run_from_db(run_id)
            if not run:
                raise ValueError(f"Run ä¸å­˜åœ¨: {run_id}")

            # æå– graph_name å’Œ input_data
            graph_name = run["graph_name"]
            input_data = run.get("input_data", {})

            # ç”Ÿæˆæ–°çš„ run_id
            new_run_id = str(uuid.uuid4())

            logger.info(f"é‡è¯• Graph: " f"original_run_id={run_id}, " f"new_run_id={new_run_id}")

            # å¯åŠ¨æ–°çš„ run
            return await self.start_run(graph_name=graph_name, payload=input_data)

        except Exception as e:
            logger.error(f"é‡è¯• Graph å¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True)
            raise

    async def list_runs(
        self,
        graph_name: Optional[str] = None,
        status: Optional[RunStatus] = None,
        limit: int = 100,
        offset: int = 0,
    ) -> List[RunInfo]:
        """åˆ—å‡º Graph æ‰§è¡Œ

        Args:
            graph_name: æŒ‰ Graph åç§°ç­›é€‰
            status: æŒ‰çŠ¶æ€ç­›é€‰
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: åç§»é‡

        Returns:
            List[RunInfo]: æ‰§è¡Œä¿¡æ¯åˆ—è¡¨

        éªŒè¯ï¼šéœ€æ±‚ 1.5
        """
        try:
            # å¦‚æœæ²¡æœ‰æ•°æ®åº“è¿æ¥ï¼Œä»å†…å­˜è¿”å›
            if not self.db_pool:
                run_infos = []
                for run_id, run in self._runs.items():
                    if graph_name and run["graph_name"] != graph_name:
                        continue
                    if status and run["status"] != status.value:
                        continue

                    status_map = {
                        "pending": RunStatus.PENDING,
                        "running": RunStatus.RUNNING,
                        "paused": RunStatus.PAUSED,
                        "completed": RunStatus.COMPLETED,
                        "failed": RunStatus.FAILED,
                        "cancelled": RunStatus.CANCELLED,
                    }

                    run_info = RunInfo(
                        run_id=run["run_id"],
                        graph_name=run["graph_name"],
                        status=status_map.get(run["status"], RunStatus.PENDING),
                        progress={},
                        created_at=run["created_at"],
                        updated_at=run["updated_at"],
                        error=run.get("error"),
                    )
                    run_infos.append(run_info)

                return run_infos[offset : offset + limit]

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼ˆå…¼å®¹ psycopg3ï¼‰
            conditions = []
            params = []

            if graph_name:
                conditions.append("graph_name = %s")
                params.append(graph_name)

            if status:
                conditions.append("status = %s")
                params.append(status.value)

            where_clause = " AND ".join(conditions) if conditions else "TRUE"

            # æŸ¥è¯¢æ•°æ®åº“
            query = f"""
                SELECT run_id, graph_name, status, created_at, updated_at, error FROM runs
                WHERE {where_clause}
                ORDER BY created_at DESC
                LIMIT %s OFFSET %s
            """
            params.extend([limit, offset])

            async with self.db_pool.connection() as conn:
                async with conn.cursor() as cur:
                    await cur.execute(query, params)
                    rows = await cur.fetchall()

            # æ„å»º RunInfo åˆ—è¡¨
            run_infos = []
            columns = ["run_id", "graph_name", "status", "created_at", "updated_at", "error"]
            for row in rows:
                row_dict = dict(zip(columns, row))
                status_map = {
                    "pending": RunStatus.PENDING,
                    "running": RunStatus.RUNNING,
                    "paused": RunStatus.PAUSED,
                    "completed": RunStatus.COMPLETED,
                    "failed": RunStatus.FAILED,
                    "cancelled": RunStatus.CANCELLED,
                }

                run_info = RunInfo(
                    run_id=row_dict["run_id"],
                    graph_name=row_dict["graph_name"],
                    status=status_map.get(row_dict["status"], RunStatus.PENDING),
                    progress={},  # ç®€åŒ–å¤„ç†ï¼Œä¸æŸ¥è¯¢ Checkpoint
                    created_at=row_dict["created_at"],
                    updated_at=row_dict["updated_at"],
                    error=row_dict.get("error"),
                )
                run_infos.append(run_info)

            logger.info(f"æŸ¥è¯¢åˆ° {len(run_infos)} ä¸ª Runs")
            return run_infos

        except Exception as e:
            logger.error(f"åˆ—å‡º Runs å¤±è´¥: " f"error={str(e)}", exc_info=True)
            raise

    async def recover_incomplete_runs(
        self,
        graph_name: Optional[str] = None,
    ) -> int:
        """è‡ªåŠ¨æ¢å¤ä¸­æ–­çš„è¿è¡Œï¼ˆä¾èµ– Checkpointerï¼‰"""
        if not self._auto_resume_enabled:
            logger.info("Auto resume disabled; skipping recovery.")
            return 0
        if self._offline_mode or not self.db_pool or not self.checkpointer:
            logger.info("Auto resume unavailable (no DB/checkpointer).")
            return 0

        runs = await self._fetch_incomplete_runs(
            graph_name=graph_name,
            limit=self._auto_resume_limit,
        )
        resumed = 0
        for run in runs:
            run_id = run.get("run_id")
            graph = run.get("graph_name")
            status_value = run.get("status")
            if not run_id or not graph:
                continue
            if run_id in self._background_tasks:
                continue

            compiled_graph = self._graph_registry.get(graph)
            if not compiled_graph:
                continue

            config = self._build_graph_config(run_id, graph)
            checkpoint = None
            try:
                checkpoint = await self.checkpointer.aget(config)
            except Exception as exc:
                logger.warning("Failed to fetch checkpoint for %s: %s", run_id, exc)

            if checkpoint:
                task = asyncio.create_task(
                    self._resume_from_checkpoint_background(
                        run_id=run_id,
                        graph_name=graph,
                        compiled_graph=compiled_graph,
                        config=config,
                    )
                )
                self._background_tasks[run_id] = task
                resumed += 1
                continue

            if status_value == "pending":
                payload = run.get("input_data") or {}
                if isinstance(payload, str):
                    try:
                        payload = json.loads(payload)
                    except json.JSONDecodeError:
                        payload = {}
                task = asyncio.create_task(
                    self._run_graph_background(
                        run_id=run_id,
                        graph_name=graph,
                        compiled_graph=compiled_graph,
                        payload=payload,
                    )
                )
                self._background_tasks[run_id] = task
                resumed += 1

        if resumed:
            logger.info("Auto resumed %s runs.", resumed)
        return resumed

    async def _fetch_incomplete_runs(
        self,
        graph_name: Optional[str],
        limit: int,
    ) -> List[Dict[str, Any]]:
        if not self.db_pool:
            return []

        conditions = ["status IN ('running', 'pending')"]
        params: List[Any] = []
        if graph_name:
            conditions.append("graph_name = %s")
            params.append(graph_name)
        where_clause = " AND ".join(conditions)
        query = f"""
            SELECT run_id, graph_name, status, input_data
            FROM runs
            WHERE {where_clause}
            ORDER BY updated_at DESC
            LIMIT %s
        """
        params.append(limit)

        try:
            async with self.db_pool.connection() as conn:
                async with conn.cursor() as cur:
                    await cur.execute(query, params)
                    rows = await cur.fetchall()
        except Exception as exc:
            logger.warning("Failed to fetch incomplete runs: %s", exc)
            return []

        columns = ["run_id", "graph_name", "status", "input_data"]
        return [dict(zip(columns, row)) for row in rows]

    async def send_event(self, run_id: str, event_type: str, event_data: Dict[str, Any]) -> bool:
        """å‘é€äº‹ä»¶åˆ° Graphï¼ˆç”¨äº resumeï¼‰

        Args:
            run_id: æ‰§è¡Œ ID
            event_type: äº‹ä»¶ç±»å‹ï¼ˆå¦‚ "review_signal"ï¼‰
            event_data: äº‹ä»¶æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸå‘é€

        éªŒè¯ï¼šéœ€æ±‚ 1.6
        """
        try:
            # æ£€æŸ¥ run æ˜¯å¦å­˜åœ¨ä¸”å¤„äº paused çŠ¶æ€
            run = await self._get_run_from_db(run_id)
            if not run:
                raise ValueError(f"Run ä¸å­˜åœ¨: {run_id}")

            if run["status"] != "paused":
                logger.warning(
                    f"Run ä¸å¤„äº paused çŠ¶æ€: " f"run_id={run_id}, " f"status={run['status']}"
                )
                return False

            logger.info(f"å‘é€äº‹ä»¶åˆ° Graph: " f"run_id={run_id}, " f"event_type={event_type}")

            # è·å– Graph
            graph_name = run["graph_name"]
            compiled_graph = self._graph_registry.get(graph_name)
            if not compiled_graph:
                raise ValueError(f"Graph æœªæ³¨å†Œ: {graph_name}")

            # é…ç½® thread_id + LangGraph å†…å»ºå¹¶å‘æ§åˆ¶
            config = self._build_graph_config(run_id, graph_name)

            # ä½¿ç”¨ Command.resume æ¢å¤æ‰§è¡Œ
            resume_command = Command(resume=event_data)

            # é‡æ–°å¯åŠ¨åå°ä»»åŠ¡
            task = asyncio.create_task(
                self._resume_graph_background(
                    run_id=run_id,
                    graph_name=graph_name,
                    compiled_graph=compiled_graph,
                    resume_command=resume_command,
                    config=config,
                )
            )

            self._background_tasks[run_id] = task

            logger.info(
                f"äº‹ä»¶å·²å‘é€ï¼ŒGraph å·²æ¢å¤: " f"run_id={run_id}, " f"event_type={event_type}"
            )
            return True

        except Exception as e:
            logger.error(
                f"å‘é€äº‹ä»¶å¤±è´¥: "
                f"run_id={run_id}, "
                f"event_type={event_type}, "
                f"error={str(e)}",
                exc_info=True,
            )
            return False

    async def _resume_graph_background(
        self,
        run_id: str,
        graph_name: str,
        compiled_graph: Any,
        resume_command: Command,
        config: Dict[str, Any],
    ):
        """åå°æ¢å¤ Graph æ‰§è¡Œ

        Args:
            run_id: æ‰§è¡Œ ID
            graph_name: Graph åç§°
            compiled_graph: ç¼–è¯‘åçš„ Graph
            resume_command: Resume å‘½ä»¤
            config: é…ç½®
        """
        paused = False
        acquired = False
        accumulated_state: Dict[str, Any] = {}
        try:
            if self._run_semaphore:
                await self._run_semaphore.acquire()
                acquired = True
            # æ›´æ–°çŠ¶æ€ä¸º running
            await self._update_run_status(run_id, "running")

            # æ‰§è¡Œ Graphï¼ˆä» interrupt ç‚¹æ¢å¤ï¼‰
            logger.info(f"æ¢å¤æ‰§è¡Œ Graph: run_id={run_id}")

            accumulated_state = await self._get_final_state(run_id) or {}
            if not accumulated_state:
                run = await self._get_run_from_db(run_id)
                if run and run.get("input_data"):
                    accumulated_state = dict(run["input_data"])

            result = None
            async for event in compiled_graph.astream_events(
                resume_command, config=config, version="v2"
            ):
                event_kind = event.get("event")
                event_name = event.get("name", "")
                event_data = event.get("data", {})
                logger.debug(f"Graph äº‹ä»¶: run_id={run_id}, event={event}")

                await self._push_event(
                    run_id, {"kind": event_kind, "name": event_name, "data": event_data}
                )

                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict) and "__interrupt__" in output:
                        logger.info(f"Graph å†æ¬¡ä¸­æ–­: run_id={run_id}")
                        paused = True
                        await self._update_run_status(run_id, "paused")
                        return

                if event_kind == "on_chat_model_stream":
                    chunk = event_data.get("chunk")
                    if chunk:
                        content = ""
                        if hasattr(chunk, "content"):
                            content = chunk.content
                        elif isinstance(chunk, dict) and "content" in chunk:
                            content = chunk["content"]
                        elif isinstance(chunk, str):
                            content = chunk
                        if content:
                            await self._push_event(
                                run_id,
                                {
                                    "kind": "llm_stream",
                                    "name": event_name,
                                    "data": {
                                        "chunk": content,
                                        "node": event.get("metadata", {}).get("langgraph_node", ""),
                                    },
                                },
                            )

                if event_kind == "on_chain_end":
                    output = event_data.get("output", {})
                    if isinstance(output, dict):
                        for key, value in output.items():
                            # å¯¹ä½¿ç”¨ operator.add reducer çš„å­—æ®µä½¿ç”¨è¿½åŠ é€»è¾‘
                            if (
                                key in ("grading_results", "student_results")
                                and key in accumulated_state
                                and isinstance(accumulated_state[key], list)
                                and isinstance(value, list)
                            ):
                                accumulated_state[key].extend(value)
                            else:
                                accumulated_state[key] = value

                if event_kind == "on_chain_end" and event_name == graph_name:
                    result = event_data.get("output", {})

            # æ‰§è¡Œå®Œæˆ
            logger.info(f"Graph æ¢å¤æ‰§è¡Œå®Œæˆ: run_id={run_id}")
            output_state = accumulated_state if accumulated_state else (result or {})
            await self._update_run_status(run_id, "completed", output_data=output_state)
            await self._push_event(
                run_id,
                {"kind": "completed", "name": None, "data": {"state": output_state}},
            )

        except Exception as e:
            logger.error(
                f"Graph æ¢å¤æ‰§è¡Œå¤±è´¥: " f"run_id={run_id}, " f"error={str(e)}", exc_info=True
            )
            await self._update_run_status(run_id, "failed", error=str(e))
        finally:
            if acquired and self._run_semaphore:
                self._run_semaphore.release()
            self._background_tasks.pop(run_id, None)
            if not paused:
                await self._mark_event_stream_complete(run_id)

    # ==================== æµå¼ API ====================

    async def stream_run(self, run_id: str):
        """æµå¼è¿”å› Graph æ‰§è¡Œäº‹ä»¶ï¼ˆä»å†…å­˜é˜Ÿåˆ—ï¼‰

        è¿™æ˜¯å®ç°å®æ—¶è¿›åº¦æ¨é€çš„å…³é”®æ–¹æ³•ï¼
        ä»å†…å­˜äº‹ä»¶é˜Ÿåˆ—è¯»å– Graph æ‰§è¡ŒæœŸé—´äº§ç”Ÿçš„äº‹ä»¶ã€‚

        Args:
            run_id: æ‰§è¡Œ IDï¼ˆthread_idï¼‰

        Yields:
            äº‹ä»¶å­—å…¸ï¼ŒåŒ…å« type, node, data ç­‰ä¿¡æ¯

        Example:
            async for event in orchestrator.stream_run(run_id):
                if event["type"] == "node_start":
                    print(f"èŠ‚ç‚¹å¼€å§‹: {event['node']}")
                elif event["type"] == "state_update":
                    print(f"çŠ¶æ€æ›´æ–°: {event['data']}")
        """
        try:
            # ç¡®ä¿äº‹ä»¶é˜Ÿåˆ—å­˜åœ¨
            if run_id not in self._event_queues:
                self._event_queues[run_id] = asyncio.Queue()

            queue = self._event_queues[run_id]

            logger.info(f"å¼€å§‹æµå¼ç›‘å¬ Graphï¼ˆä»é˜Ÿåˆ—ï¼‰: run_id={run_id}")

            # ä»é˜Ÿåˆ—è¯»å–äº‹ä»¶
            while True:
                try:
                    # ç­‰å¾…äº‹ä»¶ï¼ˆå¸¦è¶…æ—¶ï¼‰
                    event = await asyncio.wait_for(queue.get(), timeout=1.0)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸæ ‡è®°
                    if event.get("kind") == "__end__":
                        logger.info(f"äº‹ä»¶æµç»“æŸ: run_id={run_id}")
                        break

                    # è½¬æ¢äº‹ä»¶æ ¼å¼
                    event_kind = event.get("kind")
                    event_name = event.get("name", "")
                    event_data = event.get("data", {})

                    # è½¬æ¢ä¸ºç»Ÿä¸€çš„äº‹ä»¶æ ¼å¼
                    if event_kind == "on_chain_start":
                        yield {"type": "node_start", "node": event_name, "data": event_data}
                    elif event_kind == "llm_stream":
                        yield {
                            "type": "llm_stream",
                            "node": event_data.get("node", ""),
                            "data": event_data,
                        }

                    elif event_kind == "on_chain_end":
                        yield {
                            "type": "node_end",
                            "node": event_name,
                            "data": {"output": event_data.get("output", {})},
                        }

                    elif event_kind == "on_chain_stream":
                        # æµå¼è¾“å‡ºï¼ˆå¦‚ LLM ç”Ÿæˆï¼‰
                        yield {"type": "stream", "node": event_name, "data": event_data}

                    elif event_kind == "on_chat_model_stream":
                        # LLM æµå¼è¾“å‡º
                        chunk = event_data.get("chunk", {})
                        content = chunk.content if hasattr(chunk, "content") else str(chunk)
                        yield {
                            "type": "llm_stream",
                            "node": event_name,
                            "data": {"content": content},
                        }

                    elif event_kind == "completed":
                        # æ‰§è¡Œå®Œæˆ
                        yield {"type": "completed", "node": None, "data": event_data}
                        break

                    elif event_kind == "error":
                        # é”™è¯¯
                        yield {"type": "error", "node": None, "data": event_data}
                        break

                    # æ£€æŸ¥çŠ¶æ€æ›´æ–°
                    if "output" in event_data:
                        output = event_data["output"]
                        if isinstance(output, dict):
                            yield {
                                "type": "state_update",
                                "node": event_name,
                                "data": {"state": output},
                            }

                except asyncio.TimeoutError:
                    # è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                    is_complete = self._is_event_stream_complete(run_id)
                    if is_complete:
                        # ğŸ”¥ ä¿®å¤ç«æ€æ¡ä»¶ï¼šå…ˆ drain é˜Ÿåˆ—ä¸­çš„å‰©ä½™äº‹ä»¶
                        # Drain é˜Ÿåˆ—ä¸­çš„å‰©ä½™äº‹ä»¶
                        drained_count = 0
                        while not queue.empty():
                            try:
                                remaining_event = queue.get_nowait()
                                drained_count += 1
                                if remaining_event.get("kind") == "__end__":
                                    break
                                
                                # å¤„ç†å‰©ä½™äº‹ä»¶
                                evt_kind = remaining_event.get("kind")
                                evt_name = remaining_event.get("name", "")
                                evt_data = remaining_event.get("data", {})
                                
                                if evt_kind == "on_chain_start":
                                    yield {"type": "node_start", "node": evt_name, "data": evt_data}
                                elif evt_kind == "on_chain_end":
                                    yield {"type": "node_end", "node": evt_name, "data": {"output": evt_data.get("output", {})}}
                                elif evt_kind == "on_chain_stream":
                                    yield {"type": "stream", "node": evt_name, "data": evt_data}
                                elif evt_kind == "completed":
                                    yield {"type": "completed", "node": None, "data": evt_data}
                                elif evt_kind == "error":
                                    yield {"type": "error", "node": None, "data": evt_data}
                                
                                # çŠ¶æ€æ›´æ–°
                                if "output" in evt_data:
                                    output = evt_data["output"]
                                    if isinstance(output, dict):
                                        yield {"type": "state_update", "node": evt_name, "data": {"state": output}}
                            except asyncio.QueueEmpty:
                                break
                        
                        logger.info(f"äº‹ä»¶æµå·²å®Œæˆï¼ˆè¶…æ—¶æ£€æµ‹ï¼Œdrain {drained_count} ä¸ªäº‹ä»¶ï¼‰: run_id={run_id}")
                        break
                    # å¦åˆ™ç»§ç»­ç­‰å¾…
                    continue

            logger.info(f"æµå¼ç›‘å¬å®Œæˆ: run_id={run_id}")

            # æ¸…ç†é˜Ÿåˆ—
            await self._cleanup_event_queue(run_id)

        except Exception as e:
            logger.error(f"æµå¼ç›‘å¬å¤±è´¥: run_id={run_id}, error={str(e)}", exc_info=True)
            yield {"type": "error", "node": None, "data": {"error": str(e)}}

    async def stream_run_simple(self, run_id: str):
        """ç®€åŒ–ç‰ˆæµå¼ç›‘å¬ï¼ˆä½¿ç”¨ astreamï¼‰

        é€‚ç”¨äºä¸éœ€è¦è¯¦ç»†äº‹ä»¶çš„åœºæ™¯ï¼Œåªå…³å¿ƒèŠ‚ç‚¹è¾“å‡ºã€‚

        Args:
            run_id: æ‰§è¡Œ ID

        Yields:
            èŠ‚ç‚¹è¾“å‡ºå­—å…¸
        """
        try:
            run = await self._get_run_from_db(run_id)
            if not run:
                raise ValueError(f"Run ä¸å­˜åœ¨: {run_id}")

            graph_name = run["graph_name"]
            compiled_graph = self._graph_registry.get(graph_name)
            if not compiled_graph:
                raise ValueError(f"Graph æœªæ³¨å†Œ: {graph_name}")

            config = self._build_graph_config(run_id, graph_name)

            # ä½¿ç”¨ç®€å•çš„ astream
            async for chunk in compiled_graph.astream(None, config=config):
                for node_name, node_output in chunk.items():
                    yield {"type": "node_output", "node": node_name, "data": node_output}

        except Exception as e:
            logger.error(f"ç®€åŒ–æµå¼ç›‘å¬å¤±è´¥: {str(e)}", exc_info=True)
            yield {"type": "error", "node": None, "data": {"error": str(e)}}

    async def get_run_info(self, run_id: str) -> Optional[RunInfo]:
        """è·å– Run è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«çŠ¶æ€ï¼‰

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            RunInfo æˆ– Noneï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        """
        try:
            run = await self._get_run_from_db(run_id)
            if not run:
                return None

            # è·å–æœ€æ–°çŠ¶æ€
            state = await self._get_final_state(run_id)

            status_map = {
                "pending": RunStatus.PENDING,
                "running": RunStatus.RUNNING,
                "paused": RunStatus.PAUSED,
                "completed": RunStatus.COMPLETED,
                "failed": RunStatus.FAILED,
                "cancelled": RunStatus.CANCELLED,
            }

            return RunInfo(
                run_id=run_id,
                graph_name=run["graph_name"],
                status=status_map.get(run["status"], RunStatus.PENDING),
                progress=state.get("progress", {}),
                created_at=run["created_at"],
                updated_at=run["updated_at"],
                error=run.get("error"),
                state=state,  # åŒ…å«å®Œæ•´çŠ¶æ€
            )

        except Exception as e:
            logger.error(f"è·å– Run ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
            return None

    async def get_state(self, run_id: str) -> Dict[str, Any]:
        """ä» Checkpointer è·å–å½“å‰/æœ€ç»ˆçŠ¶æ€

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            çŠ¶æ€å­—å…¸
        """
        try:
            logger.info(f"DEBUG: get_state called for run_id={run_id}")
            config = {"configurable": {"thread_id": run_id}}
            checkpoint = await self.checkpointer.aget(config)
            logger.info(f"DEBUG: checkpointer.aget result for {run_id}: {bool(checkpoint)}")

            if checkpoint:
                return checkpoint.get("channel_values", {})

            # å¦‚æœ Checkpointer ä¸­æ²¡æœ‰ï¼Œå°è¯•ä» DB æˆ–å†…å­˜ä¸­è·å–ï¼ˆé’ˆå¯¹å·²å®Œæˆçš„ï¼‰
            run = await self._get_run_from_db(run_id)
            logger.info(f"DEBUG: _get_run_from_db result for {run_id}: {bool(run)}")

            if run:
                if run.get("output_data"):
                    return run["output_data"]
                if run.get("input_data"):
                    # å¦‚æœåªæœ‰è¾“å…¥æ•°æ®ï¼ˆåˆšå¼€å§‹ï¼‰ï¼Œè‡³å°‘è¿”å›è¾“å…¥
                    return run["input_data"]

            return {}
        except Exception as e:
            logger.debug(f"è·å– Checkpoint å¤±è´¥: {str(e)}")
            return {}

    async def _get_final_state(self, run_id: str) -> Dict[str, Any]:
        """å·²å¼ƒç”¨ï¼šè¯·ä½¿ç”¨ get_state"""
        return await self.get_state(run_id)

    # ==================== äº‹ä»¶é˜Ÿåˆ—ç®¡ç† ====================

    async def _push_event(self, run_id: str, event: Dict[str, Any]):
        """æ¨é€äº‹ä»¶åˆ°é˜Ÿåˆ—

        Args:
            run_id: æ‰§è¡Œ ID
            event: äº‹ä»¶æ•°æ®
        """
        if run_id not in self._event_queues:
            self._event_queues[run_id] = asyncio.Queue()

        await self._event_queues[run_id].put(event)

    async def _mark_event_stream_complete(self, run_id: str):
        """æ ‡è®°äº‹ä»¶æµå®Œæˆ

        Args:
            run_id: æ‰§è¡Œ ID
        """
        self._event_stream_complete[run_id] = True

        # æ¨é€ä¸€ä¸ªç‰¹æ®Šçš„ç»“æŸæ ‡è®°
        if run_id in self._event_queues:
            await self._event_queues[run_id].put({"kind": "__end__", "name": None, "data": {}})

    def _is_event_stream_complete(self, run_id: str) -> bool:
        """æ£€æŸ¥äº‹ä»¶æµæ˜¯å¦å®Œæˆ

        Args:
            run_id: æ‰§è¡Œ ID

        Returns:
            æ˜¯å¦å®Œæˆ
        """
        return self._event_stream_complete.get(run_id, False)

    async def _cleanup_event_queue(self, run_id: str):
        """æ¸…ç†äº‹ä»¶é˜Ÿåˆ—

        Args:
            run_id: æ‰§è¡Œ ID
        """
        self._event_queues.pop(run_id, None)
        self._event_stream_complete.pop(run_id, None)

    # ==================== æ•°æ®åº“æ“ä½œè¾…åŠ©æ–¹æ³• ====================

    async def _create_run_in_db(self, run_id: str, graph_name: str, input_data: Dict[str, Any]):
        """åœ¨æ•°æ®åº“ä¸­åˆ›å»º run è®°å½•ï¼ˆæ”¯æŒç¦»çº¿æ¨¡å¼ï¼‰"""
        if self.db_pool:
            try:
                async with self.db_pool.connection() as conn:
                    async with conn.cursor() as cur:
                        await cur.execute(
                            """
                            INSERT INTO runs (run_id, graph_name, status, input_data, created_at, updated_at)
                            VALUES (%s, %s, %s, %s, %s, %s)
                            """,
                            (
                                run_id,
                                graph_name,
                                "pending",
                                json.dumps(input_data, default=self._json_serializer),
                                datetime.now(),
                                datetime.now(),
                            ),
                        )
                    await conn.commit()
            except Exception as e:
                logger.warning(f"æ•°æ®åº“å†™å…¥å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨: {e}")
                self._create_run_in_memory(run_id, graph_name, input_data)
        else:
            self._create_run_in_memory(run_id, graph_name, input_data)

    def _create_run_in_memory(self, run_id: str, graph_name: str, input_data: Dict[str, Any]):
        """åœ¨å†…å­˜ä¸­åˆ›å»º run è®°å½•ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰"""
        self._runs[run_id] = {
            "run_id": run_id,
            "graph_name": graph_name,
            "status": "pending",
            "input_data": input_data,
            "output_data": None,
            "error": None,
            "created_at": datetime.now(),
            "updated_at": datetime.now(),
        }

    async def _get_run_from_db(self, run_id: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“æŸ¥è¯¢ run è®°å½•ï¼ˆæ”¯æŒç¦»çº¿æ¨¡å¼ï¼‰"""
        # å…ˆæ£€æŸ¥å†…å­˜
        if run_id in self._runs:
            return self._runs[run_id]

        # å†æ£€æŸ¥æ•°æ®åº“ï¼ˆå…¼å®¹ psycopg3 AsyncConnectionPoolï¼‰
        if self.db_pool:
            try:
                async with self.db_pool.connection() as conn:
                    async with conn.cursor() as cur:
                        await cur.execute(
                            "SELECT run_id, graph_name, status, input_data, output_data, error, created_at, updated_at FROM runs WHERE run_id = %s",
                            (run_id,),
                        )
                        row = await cur.fetchone()
                        if row:
                            columns = [
                                "run_id",
                                "graph_name",
                                "status",
                                "input_data",
                                "output_data",
                                "error",
                                "created_at",
                                "updated_at",
                            ]
                            return dict(zip(columns, row))
                        return None
            except Exception as e:
                logger.warning(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                return None

        return None

    async def _update_run_status(
        self,
        run_id: str,
        status: str,
        output_data: Optional[Dict[str, Any]] = None,
        error: Optional[str] = None,
    ):
        """æ›´æ–° run çŠ¶æ€ï¼ˆæ”¯æŒç¦»çº¿æ¨¡å¼ï¼‰"""
        # æ›´æ–°å†…å­˜
        if run_id in self._runs:
            self._runs[run_id]["status"] = status
            self._runs[run_id]["updated_at"] = datetime.now()
            if output_data is not None:
                self._runs[run_id]["output_data"] = output_data
            if error is not None:
                self._runs[run_id]["error"] = error

        # æ›´æ–°æ•°æ®åº“ï¼ˆå…¼å®¹ psycopg3 AsyncConnectionPoolï¼‰
        if self.db_pool:
            try:
                async with self.db_pool.connection() as conn:
                    async with conn.cursor() as cur:
                        # æ„å»ºåŠ¨æ€æ›´æ–°è¯­å¥
                        set_parts = ["status = %s", "updated_at = %s"]
                        params = [status, datetime.now()]

                        if output_data is not None:
                            set_parts.append("output_data = %s")
                            # ä½¿ç”¨è‡ªå®šä¹‰åºåˆ—åŒ–å‡½æ•°å¤„ç† bytes ç±»å‹
                            params.append(json.dumps(output_data, default=self._json_serializer))

                        if error is not None:
                            set_parts.append("error = %s")
                            params.append(error)

                        if status == "completed":
                            set_parts.append("completed_at = %s")
                            params.append(datetime.now())

                        params.append(run_id)
                        query = f"UPDATE runs SET {', '.join(set_parts)} WHERE run_id = %s"
                        await cur.execute(query, params)
                    await conn.commit()
            except Exception as e:
                logger.warning(f"æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
