"""ç«¯åˆ°ç«¯æ‰¹æ”¹åŠŸèƒ½æµ‹ï¿½?""
import os
import asyncio
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from src.services.layout_analysis import LayoutAnalysisService
from src.services.llm_reasoning import LLMReasoningClient
from src.agents.grading_agent import GradingAgent
from src.models.state import GradingState

def create_test_image(text: str, width: int = 800, height: int = 600) -> bytes:
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    # åˆ›å»ºç™½è‰²èƒŒæ™¯å›¾åƒ
    img = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶æ–‡æœ¬
    try:
        # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("arial.ttf", 40)
    except:
        # å¦‚æœæ‰¾ä¸åˆ°å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
        font = ImageFont.load_default()
    
    # ç»˜åˆ¶é¢˜ç›®æ ‡é¢˜
    draw.text((50, 50), "é¢˜ç›® 1: è®¡ç®—ï¿½?, fill='black', font=font)
    
    # ç»˜åˆ¶å­¦ç”Ÿç­”æ¡ˆ
    draw.text((50, 150), text, fill='blue', font=font)
    
    # ç»˜åˆ¶ä¸€äº›æ•°å­¦å…¬å¼æ ·å¼çš„å†…å®¹
    draw.text((50, 250), "ï¿½? 1 + 1 = 2", fill='black', font=font)
    draw.text((50, 350), "ï¿½? 2", fill='black', font=font)
    
    # è½¬æ¢ä¸ºå­—ï¿½?
    buffer = BytesIO()
    img.save(buffer, format='JPEG')
    return buffer.getvalue()

async def test_layout_analysis():
    """æµ‹è¯•å¸ƒå±€åˆ†æåŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: å¸ƒå±€åˆ†æ (Gemini 3.0 Flash)")
    print("="*60)
    
    api_key = os.getenv("LLM_API_KEY")
    service = LayoutAnalysisService(api_key=api_key)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("\nğŸ“ åˆ›å»ºæµ‹è¯•è¯•å·å›¾åƒ...")
    image_data = create_test_image("å­¦ç”Ÿç­”æ¡ˆ: 1 + 1 = 2")
    print(f"ï¿½?å›¾åƒåˆ›å»ºæˆåŠŸ ({len(image_data)} å­—èŠ‚)")
    
    try:
        print("\nğŸ” è°ƒç”¨ Gemini 3.0 Flash è¿›è¡Œé¡µé¢åˆ†å‰²...")
        result = await service.segment_document(
            image_data=image_data,
            submission_id="test_submission_001",
            page_index=0
        )
        
        print(f"\nï¿½?å¸ƒå±€åˆ†ææˆåŠŸï¿½?)
        print(f"   - æäº¤ ID: {result.submission_id}")
        print(f"   - æ€»é¡µï¿½? {result.total_pages}")
        print(f"   - è¯†åˆ«é¢˜ç›®ï¿½? {len(result.regions)}")
        
        for region in result.regions:
            print(f"\n   é¢˜ç›® {region.question_id}:")
            print(f"     - é¡µé¢ç´¢å¼•: {region.page_index}")
            print(f"     - è¾¹ç•Œï¿½? ymin={region.bounding_box.ymin}, xmin={region.bounding_box.xmin}")
            print(f"               ymax={region.bounding_box.ymax}, xmax={region.bounding_box.xmax}")
        
        return result
        
    except Exception as e:
        print(f"\nï¿½?å¸ƒå±€åˆ†æå¤±è´¥: {str(e)}")
        return None

async def test_vision_extraction():
    """æµ‹è¯•è§†è§‰æå–åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: è§†è§‰æå– (Gemini 3.0 Flash)")
    print("="*60)
    
    api_key = os.getenv("LLM_API_KEY")
    client = LLMReasoningClient(api_key=api_key)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("\nğŸ“ åˆ›å»ºå­¦ç”Ÿç­”é¢˜å›¾åƒ...")
    image_data = create_test_image("å­¦ç”Ÿç­”æ¡ˆ: 1 + 1 = 2")
    image_b64 = base64.b64encode(image_data).decode('utf-8')
    print(f"ï¿½?å›¾åƒåˆ›å»ºæˆåŠŸ")
    
    rubric = """
è¯„åˆ†ç»†åˆ™ï¿½?
1. æ­£ç¡®å†™å‡ºç®—å¼ (2ï¿½?
2. è®¡ç®—ç»“æœæ­£ç¡® (3ï¿½?
æ€»åˆ†: 5ï¿½?
"""
    
    try:
        print("\nğŸ” è°ƒç”¨ Gemini 3.0 Flash è¿›è¡Œè§†è§‰æå–...")
        vision_analysis = await client.vision_extraction(
            question_image_b64=image_b64,
            rubric=rubric,
            standard_answer="1 + 1 = 2"
        )
        
        print(f"\nï¿½?è§†è§‰æå–æˆåŠŸï¿½?)
        print(f"\nè§†è§‰åˆ†æç»“æœ:")
        print("-" * 60)
        print(vision_analysis[:500] + "..." if len(vision_analysis) > 500 else vision_analysis)
        print("-" * 60)
        
        return vision_analysis
        
    except Exception as e:
        print(f"\nï¿½?è§†è§‰æå–å¤±è´¥: {str(e)}")
        return None

async def test_rubric_mapping(vision_analysis: str):
    """æµ‹è¯•è¯„åˆ†æ˜ å°„åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: è¯„åˆ†æ˜ å°„ (Gemini 3.0 Flash)")
    print("="*60)
    
    api_key = os.getenv("LLM_API_KEY")
    client = LLMReasoningClient(api_key=api_key)
    
    rubric = """
è¯„åˆ†ç»†åˆ™ï¿½?
1. æ­£ç¡®å†™å‡ºç®—å¼ (2ï¿½?
2. è®¡ç®—ç»“æœæ­£ç¡® (3ï¿½?
æ€»åˆ†: 5ï¿½?
"""
    
    try:
        print("\nğŸ” è°ƒç”¨ Gemini 3.0 Flash è¿›è¡Œè¯„åˆ†æ˜ å°„...")
        result = await client.rubric_mapping(
            vision_analysis=vision_analysis,
            rubric=rubric,
            max_score=5.0,
            standard_answer="1 + 1 = 2"
        )
        
        print(f"\nï¿½?è¯„åˆ†æ˜ å°„æˆåŠŸï¿½?)
        print(f"\nè¯„åˆ†ç»“æœ:")
        print("-" * 60)
        print(f"åˆå§‹å¾—åˆ†: {result.get('initial_score')}/5.0")
        print(f"\nè¯„åˆ†ç‚¹æ˜ ï¿½?")
        for item in result.get('rubric_mapping', []):
            print(f"  - {item.get('rubric_point')}")
            print(f"    è¯æ®: {item.get('evidence')}")
            print(f"    å¾—åˆ†: {item.get('score_awarded')}/{item.get('max_score')}")
        print(f"\nè¯„åˆ†ç†ç”±: {result.get('reasoning', 'N/A')[:200]}...")
        print("-" * 60)
        
        return result
        
    except Exception as e:
        print(f"\nï¿½?è¯„åˆ†æ˜ å°„å¤±è´¥: {str(e)}")
        return None

async def test_critique(vision_analysis: str, rubric_mapping: dict):
    """æµ‹è¯•è‡ªæˆ‘åæ€åŠŸï¿½?""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: è‡ªæˆ‘åï¿½?(Gemini 3.0 Flash)")
    print("="*60)
    
    api_key = os.getenv("LLM_API_KEY")
    client = LLMReasoningClient(api_key=api_key)
    
    rubric = """
è¯„åˆ†ç»†åˆ™ï¿½?
1. æ­£ç¡®å†™å‡ºç®—å¼ (2ï¿½?
2. è®¡ç®—ç»“æœæ­£ç¡® (3ï¿½?
æ€»åˆ†: 5ï¿½?
"""
    
    try:
        print("\nğŸ” è°ƒç”¨ Gemini 3.0 Flash è¿›è¡Œè‡ªæˆ‘åï¿½?..")
        result = await client.critique(
            vision_analysis=vision_analysis,
            rubric=rubric,
            rubric_mapping=rubric_mapping.get('rubric_mapping', []),
            initial_score=rubric_mapping.get('initial_score', 0),
            max_score=5.0,
            standard_answer="1 + 1 = 2"
        )
        
        print(f"\nï¿½?è‡ªæˆ‘åæ€æˆåŠŸï¼")
        print(f"\nåæ€ç»“ï¿½?")
        print("-" * 60)
        print(f"éœ€è¦ä¿®ï¿½? {result.get('needs_revision')}")
        print(f"ç½®ä¿¡ï¿½? {result.get('confidence')}")
        if result.get('critique_feedback'):
            print(f"åé¦ˆ: {result.get('critique_feedback')[:200]}...")
        else:
            print(f"åé¦ˆ: æ— éœ€ä¿®æ­£")
        print("-" * 60)
        
        return result
        
    except Exception as e:
        print(f"\nï¿½?è‡ªæˆ‘åæ€å¤±ï¿½? {str(e)}")
        return None

async def test_full_grading_agent():
    """æµ‹è¯•å®Œæ•´çš„æ‰¹æ”¹æ™ºèƒ½ä½“"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: å®Œæ•´æ‰¹æ”¹æ™ºèƒ½ï¿½?(LangGraph + Gemini)")
    print("="*60)
    
    api_key = os.getenv("LLM_API_KEY")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("\nğŸ“ åˆ›å»ºå­¦ç”Ÿç­”é¢˜å›¾åƒ...")
    image_data = create_test_image("å­¦ç”Ÿç­”æ¡ˆ: 1 + 1 = 2")
    image_b64 = base64.b64encode(image_data).decode('utf-8')
    print(f"ï¿½?å›¾åƒåˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºæ‰¹æ”¹æ™ºèƒ½ï¿½?
    print("\nğŸ¤– åˆå§‹åŒ–æ‰¹æ”¹æ™ºèƒ½ä½“...")
    reasoning_client = LLMReasoningClient(api_key=api_key)
    agent = GradingAgent(reasoning_client=reasoning_client)
    print(f"ï¿½?æ™ºèƒ½ä½“åˆå§‹åŒ–æˆåŠŸ")
    
    # å‡†å¤‡è¾“å…¥å‚æ•°
    rubric = """
è¯„åˆ†ç»†åˆ™ï¿½?
1. æ­£ç¡®å†™å‡ºç®—å¼ (2ï¿½?
2. è®¡ç®—ç»“æœæ­£ç¡® (3ï¿½?
æ€»åˆ†: 5ï¿½?
"""
    standard_answer = "1 + 1 = 2"
    max_score = 5.0
    
    try:
        print("\nğŸš€ å¼€å§‹æ‰¹æ”¹æµï¿½?..")
        print("   æ­¥éª¤: è§†è§‰æå– ï¿½?è¯„åˆ†æ˜ å°„ ï¿½?è‡ªæˆ‘åï¿½?ï¿½?æœ€ç»ˆåŒ–")
        
        # è¿è¡Œæ™ºèƒ½ï¿½?
        final_state = await agent.run(
            question_image=image_b64,
            rubric=rubric,
            max_score=max_score,
            standard_answer=standard_answer
        )
        
        print(f"\nï¿½?æ‰¹æ”¹å®Œæˆï¿½?)
        print(f"\næ‰¹æ”¹ç»“æœ:")
        print("=" * 60)
        print(f"æœ€ç»ˆå¾—ï¿½? {final_state['final_score']}/{final_state['max_score']}")
        print(f"ç½®ä¿¡ï¿½? {final_state['confidence']:.2f}")
        print(f"ä¿®æ­£æ¬¡æ•°: {final_state['revision_count']}")
        print(f"\nå­¦ç”Ÿåé¦ˆ:")
        print("-" * 60)
        print(final_state['student_feedback'][:500] + "..." if len(final_state['student_feedback']) > 500 else final_state['student_feedback'])
        print("-" * 60)
        
        print(f"\næ¨ç†è½¨è¿¹ ({len(final_state['reasoning_trace'])} ï¿½?:")
        for i, trace in enumerate(final_state['reasoning_trace'], 1):
            print(f"  {i}. {trace[:100]}...")
        
        return final_state
        
    except Exception as e:
        print(f"\nï¿½?æ‰¹æ”¹å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

async def main():
    """ä¸»æµ‹è¯•å‡½ï¿½?""
    print("\n" + "ğŸ¯" * 30)
    print("AI æ‰¹æ”¹ç³»ç»Ÿ - ç«¯åˆ°ç«¯åŠŸèƒ½æµ‹ï¿½?)
    print("ğŸ¯" * 30)
    
    # æ£€ï¿½?API Key
    api_key = os.getenv("LLM_API_KEY")
    if not api_key:
        print("\nï¿½?é”™è¯¯: æœªæ‰¾ï¿½?LLM_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·ç¡®ï¿½?.env æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«æœ‰æ•ˆçš„ API Key")
        return
    
    print(f"\nï¿½?API Key å·²åŠ ï¿½? {api_key[:20]}...")
    
    # æµ‹è¯• 1: å¸ƒå±€åˆ†æ
    layout_result = await test_layout_analysis()
    
    # æµ‹è¯• 2: è§†è§‰æå–
    vision_analysis = await test_vision_extraction()
    
    # åˆå§‹åŒ–å˜ï¿½?
    rubric_mapping = None
    critique_result = None
    
    if vision_analysis:
        # æµ‹è¯• 3: è¯„åˆ†æ˜ å°„
        rubric_mapping = await test_rubric_mapping(vision_analysis)
        
        if rubric_mapping:
            # æµ‹è¯• 4: è‡ªæˆ‘åï¿½?
            critique_result = await test_critique(vision_analysis, rubric_mapping)
    
    # æµ‹è¯• 5: å®Œæ•´æ‰¹æ”¹æ™ºèƒ½ï¿½?
    final_result = await test_full_grading_agent()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"ï¿½?å¸ƒå±€åˆ†æ: {'é€šè¿‡' if layout_result else 'å¤±è´¥'}")
    print(f"ï¿½?è§†è§‰æå–: {'é€šè¿‡' if vision_analysis else 'å¤±è´¥'}")
    print(f"ï¿½?è¯„åˆ†æ˜ å°„: {'é€šè¿‡' if rubric_mapping else 'å¤±è´¥'}")
    print(f"ï¿½?è‡ªæˆ‘åï¿½? {'é€šè¿‡' if critique_result else 'å¤±è´¥'}")
    print(f"ï¿½?å®Œæ•´æ‰¹æ”¹: {'é€šè¿‡' if final_result else 'å¤±è´¥'}")
    
    if final_result:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‰¹æ”¹ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
        print(f"\næœ€ç»ˆæ‰¹æ”¹ç»“ï¿½?")
        print(f"  - å¾—åˆ†: {final_result['final_score']}/{final_result['max_score']}")
        print(f"  - ç½®ä¿¡ï¿½? {final_result['confidence']:.2%}")
        print(f"  - ä¿®æ­£æ¬¡æ•°: {final_result['revision_count']}")
    else:
        print(f"\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡ï¿½?)

if __name__ == "__main__":
    asyncio.run(main())
