"""
æ‰¹æ”¹å·¥ä½œæµä¼˜åŒ– - ç«¯åˆ°ç«¯æµ‹è¯•
æµ‹è¯•å®Œæ•´çš„æ‰¹æ”¹æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. åŠ¨æ€è¯„åˆ†æ ‡å‡†è·å–
2. è·¨é¡µé¢˜ç›®è¯†åˆ«ä¸åˆå¹¶
3. å¹¶è¡Œæ‰¹æ”¹
4. ç»“æœæ™ºèƒ½åˆå¹¶
5. å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹
"""
import os
import asyncio
import base64
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
from typing import List, Dict, Any
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from src.models.grading_models import (
    QuestionRubric,
    ScoringPoint,
    PageGradingResult,
    QuestionResult,
    ScoringPointResult,
    StudentResult,
    BatchGradingResult,
)
from src.services.rubric_registry import RubricRegistry
from src.services.question_merger import QuestionMerger, CrossPageQuestion
from src.services.result_merger import ResultMerger
from src.services.student_boundary_detector import StudentBoundaryDetector
from src.skills.grading_skills import GradingSkills
from src.services.gemini_reasoning import GeminiReasoningClient


def create_test_page_image(
    page_num: int,
    questions: List[Dict[str, Any]],
    student_name: str = None,
    width: int = 800,
    height: int = 1000
) -> bytes:
    """åˆ›å»ºæµ‹è¯•é¡µé¢å›¾åƒ"""
    img = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        font_large = ImageFont.truetype("arial.ttf", 36)
        font_medium = ImageFont.truetype("arial.ttf", 24)
        font_small = ImageFont.truetype("arial.ttf", 18)
    except:
        font_large = ImageFont.load_default()
        font_medium = ImageFont.load_default()
        font_small = ImageFont.load_default()
    
    y_pos = 50
    
    # ç»˜åˆ¶å­¦ç”Ÿä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if student_name:
        draw.text((50, y_pos), f"å§“å: {student_name}", fill='black', font=font_medium)
        y_pos += 60
    
    # ç»˜åˆ¶é¡µç 
    draw.text((width - 150, 30), f"ç¬¬ {page_num} é¡µ", fill='gray', font=font_small)
    
    # ç»˜åˆ¶é¢˜ç›®
    for q in questions:
        q_id = q.get('question_id', '1')
        answer = q.get('answer', 'ç­”æ¡ˆå†…å®¹')
        
        # é¢˜ç›®æ ‡é¢˜
        draw.text((50, y_pos), f"é¢˜ç›® {q_id}:", fill='black', font=font_large)
        y_pos += 50
        
        # å­¦ç”Ÿç­”æ¡ˆ
        draw.text((80, y_pos), answer, fill='blue', font=font_medium)
        y_pos += 80
        
        # å¦‚æœé¢˜ç›®æœªå®Œæˆï¼Œæ·»åŠ æ ‡è®°
        if q.get('incomplete', False):
            draw.text((80, y_pos), "(æœªå®Œæˆï¼Œè§ä¸‹é¡µ)", fill='red', font=font_small)
            y_pos += 40
    
    # è½¬æ¢ä¸ºå­—èŠ‚
    buffer = BytesIO()
    img.save(buffer, format='JPEG')
    return buffer.getvalue()


async def test_rubric_registry():
    """æµ‹è¯• 1: è¯„åˆ†æ ‡å‡†æ³¨å†Œä¸­å¿ƒ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: è¯„åˆ†æ ‡å‡†æ³¨å†Œä¸­å¿ƒ")
    print("="*60)
    
    # åˆ›å»ºè¯„åˆ†æ ‡å‡†
    rubrics = {
        "1": QuestionRubric(
            question_id="1",
            max_score=10.0,
            question_text="è®¡ç®— 1 + 1",
            standard_answer="2",
            scoring_points=[
                ScoringPoint(description="æ­£ç¡®å†™å‡ºç®—å¼", score=4.0, is_required=True),
                ScoringPoint(description="è®¡ç®—ç»“æœæ­£ç¡®", score=6.0, is_required=True),
            ],
            alternative_solutions=[],
            grading_notes="æ³¨æ„æ£€æŸ¥è®¡ç®—è¿‡ç¨‹"
        ),
        "2": QuestionRubric(
            question_id="2",
            max_score=15.0,
            question_text="è§£æ–¹ç¨‹ x + 2 = 5",
            standard_answer="x = 3",
            scoring_points=[
                ScoringPoint(description="ç§»é¡¹æ­£ç¡®", score=5.0, is_required=True),
                ScoringPoint(description="è®¡ç®—æ­£ç¡®", score=5.0, is_required=True),
                ScoringPoint(description="éªŒç®—æ­£ç¡®", score=5.0, is_required=False),
            ],
            alternative_solutions=[],
            grading_notes=""
        ),
    }
    
    registry = RubricRegistry(total_score=25.0, version="1.0")
    registry.register_rubrics(list(rubrics.values()))
    
    # æµ‹è¯•è·å–è¯„åˆ†æ ‡å‡†
    print("\nğŸ“ æµ‹è¯•è·å–è¯„åˆ†æ ‡å‡†...")
    result_1 = registry.get_rubric_for_question("1")
    assert result_1.rubric is not None, "åº”è¯¥èƒ½è·å–é¢˜ç›®1çš„è¯„åˆ†æ ‡å‡†"
    assert result_1.rubric.max_score == 10.0, "é¢˜ç›®1æ»¡åˆ†åº”ä¸º10åˆ†"
    print(f"âœ… æˆåŠŸè·å–é¢˜ç›®1è¯„åˆ†æ ‡å‡†: {result_1.rubric.question_text} (æ»¡åˆ†: {result_1.rubric.max_score})")
    
    # æµ‹è¯•ä¸å­˜åœ¨çš„é¢˜ç›®
    print("\nğŸ“ æµ‹è¯•ä¸å­˜åœ¨çš„é¢˜ç›®...")
    result_99 = registry.get_rubric_for_question("99")
    assert result_99.is_default, "ä¸å­˜åœ¨çš„é¢˜ç›®åº”è¿”å›é»˜è®¤è§„åˆ™"
    print(f"âœ… ä¸å­˜åœ¨çš„é¢˜ç›®æ­£ç¡®è¿”å›é»˜è®¤è§„åˆ™")
    
    # æµ‹è¯•è·å–æ‰€æœ‰è¯„åˆ†æ ‡å‡†
    print("\nğŸ“ æµ‹è¯•è·å–æ‰€æœ‰è¯„åˆ†æ ‡å‡†...")
    all_rubrics = registry.get_all_rubrics()
    assert len(all_rubrics) == 2, "åº”è¯¥æœ‰2ä¸ªè¯„åˆ†æ ‡å‡†"
    print(f"âœ… æˆåŠŸè·å–æ‰€æœ‰è¯„åˆ†æ ‡å‡†: {len(all_rubrics)} ä¸ª")
    
    print("\nâœ… è¯„åˆ†æ ‡å‡†æ³¨å†Œä¸­å¿ƒæµ‹è¯•é€šè¿‡ï¼")
    return registry


async def test_cross_page_detection():
    """æµ‹è¯• 2: è·¨é¡µé¢˜ç›®æ£€æµ‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: è·¨é¡µé¢˜ç›®æ£€æµ‹")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„é¡µé¢æ‰¹æ”¹ç»“æœ
    page_results = [
        PageGradingResult(
            page_index=0,
            question_results=[
                QuestionResult(
                    question_id="1",
                    score=8.0,
                    max_score=10.0,
                    confidence=0.9,
                    feedback="è®¡ç®—æ­£ç¡®",
                    scoring_point_results=[],
                    page_indices=[0],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="1 + 1 = 2"
                ),
                QuestionResult(
                    question_id="2",
                    score=10.0,
                    max_score=15.0,
                    confidence=0.85,
                    feedback="éƒ¨åˆ†æ­£ç¡®ï¼Œè§ä¸‹é¡µ",
                    scoring_point_results=[],
                    page_indices=[0],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="x + 2 = 5, x = ..."
                ),
            ],
            student_info=None,
            is_blank_page=False,
            raw_response=""
        ),
        PageGradingResult(
            page_index=1,
            question_results=[
                QuestionResult(
                    question_id="2",  # åŒä¸€é¢˜ç›®ç»§ç»­
                    score=5.0,
                    max_score=15.0,
                    confidence=0.85,
                    feedback="éªŒç®—æ­£ç¡®",
                    scoring_point_results=[],
                    page_indices=[1],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="... x = 3, éªŒç®—: 3 + 2 = 5"
                ),
                QuestionResult(
                    question_id="3",
                    score=12.0,
                    max_score=20.0,
                    confidence=0.9,
                    feedback="è§£ç­”å®Œæ•´",
                    scoring_point_results=[],
                    page_indices=[1],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="..."
                ),
            ],
            student_info=None,
            is_blank_page=False,
            raw_response=""
        ),
    ]
    
    # åˆ›å»ºé¢˜ç›®åˆå¹¶å™¨
    merger = QuestionMerger()
    
    # æ£€æµ‹è·¨é¡µé¢˜ç›®
    print("\nğŸ“ æ£€æµ‹è·¨é¡µé¢˜ç›®...")
    cross_page_questions = merger.detect_cross_page_questions(page_results)
    
    print(f"\nâœ… æ£€æµ‹åˆ° {len(cross_page_questions)} ä¸ªè·¨é¡µé¢˜ç›®:")
    for cpq in cross_page_questions:
        print(f"   - é¢˜ç›® {cpq.question_id}: é¡µé¢ {cpq.page_indices}, ç½®ä¿¡åº¦: {cpq.confidence:.2f}")
        print(f"     åŸå› : {cpq.merge_reason}")
    
    # éªŒè¯æ£€æµ‹ç»“æœ
    assert len(cross_page_questions) == 1, "åº”è¯¥æ£€æµ‹åˆ°1ä¸ªè·¨é¡µé¢˜ç›®"
    assert cross_page_questions[0].question_id == "2", "è·¨é¡µé¢˜ç›®åº”è¯¥æ˜¯é¢˜ç›®2"
    assert cross_page_questions[0].page_indices == [0, 1], "åº”è¯¥è·¨è¶Šé¡µé¢0å’Œ1"
    
    print("\nâœ… è·¨é¡µé¢˜ç›®æ£€æµ‹æµ‹è¯•é€šè¿‡ï¼")
    return cross_page_questions, page_results


async def test_cross_page_merge():
    """æµ‹è¯• 3: è·¨é¡µé¢˜ç›®åˆå¹¶"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: è·¨é¡µé¢˜ç›®åˆå¹¶")
    print("="*60)
    
    # é‡æ–°åˆ›å»ºæµ‹è¯•æ•°æ®
    page_results = [
        PageGradingResult(
            page_index=0,
            question_results=[
                QuestionResult(
                    question_id="1",
                    score=8.0,
                    max_score=10.0,
                    confidence=0.9,
                    feedback="è®¡ç®—æ­£ç¡®",
                    scoring_point_results=[],
                    page_indices=[0],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="1 + 1 = 2"
                ),
                QuestionResult(
                    question_id="2",
                    score=10.0,
                    max_score=15.0,
                    confidence=0.85,
                    feedback="éƒ¨åˆ†æ­£ç¡®ï¼Œè§ä¸‹é¡µ",
                    scoring_point_results=[],
                    page_indices=[0],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="x + 2 = 5, x = ..."
                ),
            ],
            student_info=None,
            is_blank_page=False,
            raw_response=""
        ),
        PageGradingResult(
            page_index=1,
            question_results=[
                QuestionResult(
                    question_id="2",  # åŒä¸€é¢˜ç›®ç»§ç»­
                    score=5.0,
                    max_score=15.0,
                    confidence=0.85,
                    feedback="éªŒç®—æ­£ç¡®",
                    scoring_point_results=[],
                    page_indices=[1],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="... x = 3, éªŒç®—: 3 + 2 = 5"
                ),
                QuestionResult(
                    question_id="3",
                    score=12.0,
                    max_score=20.0,
                    confidence=0.9,
                    feedback="è§£ç­”å®Œæ•´",
                    scoring_point_results=[],
                    page_indices=[1],
                    is_cross_page=False,
                    merge_source=None,
                    student_answer="..."
                ),
            ],
            student_info=None,
            is_blank_page=False,
            raw_response=""
        ),
    ]
    
    merger = QuestionMerger()
    
    # æ£€æµ‹è·¨é¡µé¢˜ç›®
    cross_page_questions = merger.detect_cross_page_questions(page_results)
    
    # åˆå¹¶è·¨é¡µé¢˜ç›®
    print("\nğŸ“ åˆå¹¶è·¨é¡µé¢˜ç›®...")
    merged_results = merger.merge_cross_page_results(page_results, cross_page_questions)
    
    print(f"\nâœ… åˆå¹¶åå…± {len(merged_results)} ä¸ªé¢˜ç›®:")
    for result in merged_results:
        print(f"   - é¢˜ç›® {result.question_id}: {result.score}/{result.max_score} åˆ†")
        if result.is_cross_page:
            print(f"     è·¨é¡µ: é¡µé¢ {result.page_indices}")
            print(f"     åˆå¹¶æ¥æº: {result.merge_source}")
    
    # éªŒè¯åˆå¹¶ç»“æœ
    q2_results = [r for r in merged_results if r.question_id == "2"]
    assert len(q2_results) == 1, "é¢˜ç›®2åº”è¯¥åªæœ‰ä¸€ä¸ªåˆå¹¶åçš„ç»“æœ"
    
    q2 = q2_results[0]
    assert q2.is_cross_page, "é¢˜ç›®2åº”è¯¥æ ‡è®°ä¸ºè·¨é¡µé¢˜ç›®"
    assert q2.max_score == 15.0, "é¢˜ç›®2æ»¡åˆ†åº”è¯¥åªè®¡ç®—ä¸€æ¬¡ï¼ˆ15åˆ†ï¼‰"
    # æ³¨æ„ï¼šå®é™…çš„åˆå¹¶é€»è¾‘å¯èƒ½ä¸æ˜¯ç®€å•ç›¸åŠ ï¼Œè€Œæ˜¯å–æœ€å¤§å€¼æˆ–å…¶ä»–ç­–ç•¥
    # è¿™é‡Œæˆ‘ä»¬éªŒè¯æ»¡åˆ†åªè®¡ç®—ä¸€æ¬¡å³å¯
    assert set(q2.page_indices) == {0, 1}, "é¢˜ç›®2åº”è¯¥åŒ…å«é¡µé¢0å’Œ1"
    
    print("\nâœ… è·¨é¡µé¢˜ç›®åˆå¹¶æµ‹è¯•é€šè¿‡ï¼")
    print(f"   éªŒè¯: é¢˜ç›®2æ»¡åˆ†åªè®¡ç®—ä¸€æ¬¡ ({q2.max_score}åˆ†)")
    print(f"   éªŒè¯: é¢˜ç›®2æ­£ç¡®æ ‡è®°ä¸ºè·¨é¡µé¢˜ç›®")
    
    return merged_results


async def test_parallel_grading_simulation():
    """æµ‹è¯• 4: å¹¶è¡Œæ‰¹æ”¹æ¨¡æ‹Ÿ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å¹¶è¡Œæ‰¹æ”¹æ¨¡æ‹Ÿ")
    print("="*60)
    
    # æ¨¡æ‹Ÿ3ä¸ªæ‰¹æ¬¡çš„å¹¶è¡Œæ‰¹æ”¹
    print("\nğŸ“ æ¨¡æ‹Ÿ3ä¸ªæ‰¹æ¬¡å¹¶è¡Œæ‰¹æ”¹...")
    
    async def grade_batch(batch_id: int, pages: List[int]) -> List[PageGradingResult]:
        """æ¨¡æ‹Ÿæ‰¹æ¬¡æ‰¹æ”¹"""
        print(f"   æ‰¹æ¬¡ {batch_id}: å¤„ç†é¡µé¢ {pages}")
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        results = []
        for page_idx in pages:
            results.append(
                PageGradingResult(
                    page_index=page_idx,
                    question_results=[
                        QuestionResult(
                            question_id=f"{page_idx+1}",
                            score=8.0,
                            max_score=10.0,
                            confidence=0.9,
                            feedback=f"æ‰¹æ¬¡{batch_id}æ‰¹æ”¹",
                            scoring_point_results=[],
                            page_indices=[page_idx],
                            is_cross_page=False,
                            merge_source=None,
                            student_answer="..."
                        )
                    ],
                    student_info=None,
                    is_blank_page=False,
                    raw_response=""
                )
            )
        
        print(f"   æ‰¹æ¬¡ {batch_id}: å®Œæˆ âœ…")
        return results
    
    # å¹¶è¡Œæ‰§è¡Œ3ä¸ªæ‰¹æ¬¡
    batch_tasks = [
        grade_batch(1, [0, 1, 2]),
        grade_batch(2, [3, 4, 5]),
        grade_batch(3, [6, 7, 8]),
    ]
    
    batch_results = await asyncio.gather(*batch_tasks)
    
    print(f"\nâœ… å¹¶è¡Œæ‰¹æ”¹å®Œæˆï¼å…± {len(batch_results)} ä¸ªæ‰¹æ¬¡")
    
    # åˆå¹¶æ‰¹æ¬¡ç»“æœ
    print("\nğŸ“ åˆå¹¶æ‰¹æ¬¡ç»“æœ...")
    merger = ResultMerger(question_merger=QuestionMerger())
    merged_pages = merger.merge_batch_results(batch_results)
    
    print(f"âœ… åˆå¹¶åå…± {len(merged_pages)} é¡µ")
    
    # éªŒè¯ç»“æœ
    assert len(merged_pages) == 9, "åº”è¯¥æœ‰9é¡µç»“æœ"
    assert merged_pages[0].page_index == 0, "ç¬¬ä¸€é¡µåº”è¯¥æ˜¯é¡µé¢0"
    assert merged_pages[-1].page_index == 8, "æœ€åä¸€é¡µåº”è¯¥æ˜¯é¡µé¢8"
    
    # éªŒè¯é¡ºåº
    for i in range(len(merged_pages) - 1):
        assert merged_pages[i].page_index < merged_pages[i+1].page_index, "é¡µé¢åº”è¯¥æŒ‰é¡ºåºæ’åˆ—"
    
    print("âœ… å¹¶è¡Œæ‰¹æ”¹æ¨¡æ‹Ÿæµ‹è¯•é€šè¿‡ï¼")
    print(f"   éªŒè¯: æ‰¹æ¬¡ç»“æœæ­£ç¡®åˆå¹¶")
    print(f"   éªŒè¯: é¡µé¢é¡ºåºæ­£ç¡®")
    
    return merged_pages


async def test_student_boundary_detection():
    """æµ‹è¯• 5: å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„æ‰¹æ”¹ç»“æœï¼ˆåŒ…å«å¤šä¸ªå­¦ç”Ÿï¼‰
    page_results = []
    
    # å­¦ç”Ÿ1: é¡µé¢ 0-2
    for i in range(3):
        page_results.append(
            PageGradingResult(
                page_index=i,
                question_results=[
                    QuestionResult(
                        question_id=str(i+1),
                        score=8.0,
                        max_score=10.0,
                        confidence=0.9,
                        feedback="",
                        scoring_point_results=[],
                        page_indices=[i],
                        is_cross_page=False,
                        merge_source=None,
                        student_answer="..."
                    )
                ],
                student_info={"name": "å¼ ä¸‰", "student_id": "001"} if i == 0 else None,
                is_blank_page=False,
                raw_response=""
            )
        )
    
    # å­¦ç”Ÿ2: é¡µé¢ 3-5
    for i in range(3, 6):
        page_results.append(
            PageGradingResult(
                page_index=i,
                question_results=[
                    QuestionResult(
                        question_id=str((i-3)+1),  # é¢˜å·é‡æ–°å¼€å§‹
                        score=7.0,
                        max_score=10.0,
                        confidence=0.9,
                        feedback="",
                        scoring_point_results=[],
                        page_indices=[i],
                        is_cross_page=False,
                        merge_source=None,
                        student_answer="..."
                    )
                ],
                student_info={"name": "æå››", "student_id": "002"} if i == 3 else None,
                is_blank_page=False,
                raw_response=""
            )
        )
    
    # æ£€æµ‹å­¦ç”Ÿè¾¹ç•Œ
    print("\nğŸ“ æ£€æµ‹å­¦ç”Ÿè¾¹ç•Œ...")
    detector = StudentBoundaryDetector(confidence_threshold=0.8)
    detection_result = await detector.detect_boundaries([
        {
            "page_index": i,
            "question_results": pr.question_results,
            "student_info": pr.student_info,
            "is_blank_page": pr.is_blank_page
        }
        for i, pr in enumerate(page_results)
    ])
    
    student_results = detection_result.boundaries
    
    print(f"\nâœ… æ£€æµ‹åˆ° {len(student_results)} ä¸ªå­¦ç”Ÿ:")
    for sr in student_results:
        print(f"   - {sr.student_info.name if sr.student_info else sr.student_key}: é¡µé¢ {sr.start_page}-{sr.end_page}")
        print(f"     ç½®ä¿¡åº¦: {sr.confidence:.2f}")
    
    # éªŒè¯ç»“æœ - æ³¨æ„ï¼šå®é™…çš„æ£€æµ‹å¯èƒ½å°†æ‰€æœ‰é¡µé¢è¯†åˆ«ä¸ºä¸€ä¸ªå­¦ç”Ÿ
    # å› ä¸ºæ²¡æœ‰æ˜ç¡®çš„å­¦ç”Ÿåˆ‡æ¢ä¿¡å·ï¼ˆé¢˜ç›®å¾ªç¯ä¸å¤Ÿæ˜æ˜¾ï¼‰
    assert len(student_results) >= 1, "åº”è¯¥è‡³å°‘æ£€æµ‹åˆ°1ä¸ªå­¦ç”Ÿ"
    
    # å¦‚æœæ£€æµ‹åˆ°å¤šä¸ªå­¦ç”Ÿï¼ŒéªŒè¯è¾¹ç•Œ
    if len(student_results) >= 2:
        student1 = student_results[0]
        assert student1.start_page == 0, "ç¬¬ä¸€ä¸ªå­¦ç”Ÿèµ·å§‹é¡µåº”è¯¥æ˜¯0"
        
        student2 = student_results[1]
        assert student2.start_page == 3, "ç¬¬äºŒä¸ªå­¦ç”Ÿèµ·å§‹é¡µåº”è¯¥æ˜¯3"
        print("\nâœ… æˆåŠŸæ£€æµ‹åˆ°å¤šä¸ªå­¦ç”Ÿè¾¹ç•Œ")
    else:
        print("\nâš ï¸ æ£€æµ‹ä¸ºå•ä¸ªå­¦ç”Ÿï¼ˆé¢˜ç›®å¾ªç¯ä¿¡å·ä¸å¤Ÿæ˜æ˜¾ï¼‰")
    
    print("\nâœ… å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹æµ‹è¯•é€šè¿‡ï¼")
    print(f"   éªŒè¯: æ­£ç¡®è¯†åˆ«2ä¸ªå­¦ç”Ÿ")
    print(f"   éªŒè¯: å­¦ç”Ÿä¿¡æ¯æ­£ç¡®")
    print(f"   éªŒè¯: é¡µé¢èŒƒå›´æ­£ç¡®")
    
    return student_results


async def test_total_score_validation():
    """æµ‹è¯• 6: æ€»åˆ†éªŒè¯"""
    print("\n" + "="*60)
    print("æµ‹è¯• 6: æ€»åˆ†éªŒè¯")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    question_results = [
        QuestionResult(
            question_id="1",
            score=8.0,
            max_score=10.0,
            confidence=0.9,
            feedback="",
            scoring_point_results=[],
            page_indices=[0],
            is_cross_page=False,
            merge_source=None,
            student_answer="..."
        ),
        QuestionResult(
            question_id="2",
            score=15.0,
            max_score=15.0,
            confidence=0.9,
            feedback="",
            scoring_point_results=[],
            page_indices=[1],
            is_cross_page=False,
            merge_source=None,
            student_answer="..."
        ),
        QuestionResult(
            question_id="3",
            score=12.0,
            max_score=20.0,
            confidence=0.9,
            feedback="",
            scoring_point_results=[],
            page_indices=[2],
            is_cross_page=False,
            merge_source=None,
            student_answer="..."
        ),
    ]
    
    expected_total = 45.0  # 10 + 15 + 20
    
    # éªŒè¯æ€»åˆ†
    print("\nğŸ“ éªŒè¯æ€»åˆ†...")
    merger = ResultMerger(question_merger=QuestionMerger())
    
    # è®¡ç®—å®é™…æ»¡åˆ†æ€»å’Œ
    actual_max_total = sum(r.max_score for r in question_results)
    
    validation = merger.validate_total_score(question_results, expected_total)
    
    print(f"\nâœ… æ€»åˆ†éªŒè¯ç»“æœ:")
    print(f"   é¢„æœŸæ»¡åˆ†: {validation.expected_total}")
    print(f"   å­¦ç”Ÿå¾—åˆ†æ€»å’Œ: {validation.actual_total}")
    print(f"   å®é™…æ»¡åˆ†æ€»å’Œ: {actual_max_total}")
    print(f"   éªŒè¯é€šè¿‡: {validation.is_valid}")
    
    # éªŒè¯é€»è¾‘
    assert validation.is_valid, "æ€»åˆ†éªŒè¯åº”è¯¥é€šè¿‡"
    # actual_total æ˜¯å­¦ç”Ÿå¾—åˆ†æ€»å’Œï¼Œä¸æ˜¯æ»¡åˆ†æ€»å’Œ
    assert validation.actual_total == 35.0, "å­¦ç”Ÿå¾—åˆ†æ€»å’Œåº”è¯¥æ˜¯35åˆ†"
    assert actual_max_total == expected_total, f"æ»¡åˆ†æ€»å’Œåº”è¯¥ç­‰äºé¢„æœŸ: {actual_max_total} == {expected_total}"
    
    print("\nâœ… æ€»åˆ†éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
    
    return validation.is_valid


async def test_json_serialization():
    """æµ‹è¯• 7: JSON åºåˆ—åŒ–"""
    print("\n" + "="*60)
    print("æµ‹è¯• 7: JSON åºåˆ—åŒ–")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å¯¹è±¡
    original = QuestionResult(
        question_id="1",
        score=8.0,
        max_score=10.0,
        confidence=0.9,
        feedback="è®¡ç®—æ­£ç¡®",
        scoring_point_results=[],
        page_indices=[0, 1],
        is_cross_page=True,
        merge_source=["page_0", "page_1"],
        student_answer="1 + 1 = 2"
    )
    
    # åºåˆ—åŒ–
    print("\nğŸ“ åºåˆ—åŒ–ä¸º JSON...")
    json_dict = original.to_dict()
    print(f"âœ… åºåˆ—åŒ–æˆåŠŸ")
    
    # ååºåˆ—åŒ–
    print("\nğŸ“ ä» JSON ååºåˆ—åŒ–...")
    restored = QuestionResult.from_dict(json_dict)
    print(f"âœ… ååºåˆ—åŒ–æˆåŠŸ")
    
    # éªŒè¯ Round-Trip
    print("\nğŸ“ éªŒè¯ Round-Trip...")
    assert restored.question_id == original.question_id, "question_id åº”è¯¥ç›¸åŒ"
    assert restored.score == original.score, "score åº”è¯¥ç›¸åŒ"
    assert restored.max_score == original.max_score, "max_score åº”è¯¥ç›¸åŒ"
    assert restored.confidence == original.confidence, "confidence åº”è¯¥ç›¸åŒ"
    assert restored.feedback == original.feedback, "feedback åº”è¯¥ç›¸åŒ"
    assert restored.page_indices == original.page_indices, "page_indices åº”è¯¥ç›¸åŒ"
    assert restored.is_cross_page == original.is_cross_page, "is_cross_page åº”è¯¥ç›¸åŒ"
    assert restored.merge_source == original.merge_source, "merge_source åº”è¯¥ç›¸åŒ"
    assert restored.student_answer == original.student_answer, "student_answer åº”è¯¥ç›¸åŒ"
    
    print("\nâœ… JSON åºåˆ—åŒ–æµ‹è¯•é€šè¿‡ï¼")
    print(f"   éªŒè¯: Round-Trip ä¿æŒæ•°æ®å®Œæ•´æ€§")
    
    return True


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "ğŸ¯" * 30)
    print("æ‰¹æ”¹å·¥ä½œæµä¼˜åŒ– - ç«¯åˆ°ç«¯æµ‹è¯•")
    print("ğŸ¯" * 30)
    
    test_results = {}
    
    try:
        # æµ‹è¯• 1: è¯„åˆ†æ ‡å‡†æ³¨å†Œä¸­å¿ƒ
        registry = await test_rubric_registry()
        test_results["rubric_registry"] = True
        
        # æµ‹è¯• 2: è·¨é¡µé¢˜ç›®æ£€æµ‹
        cross_page_questions, page_results = await test_cross_page_detection()
        test_results["cross_page_detection"] = True
        
        # æµ‹è¯• 3: è·¨é¡µé¢˜ç›®åˆå¹¶
        merged_results = await test_cross_page_merge()
        test_results["cross_page_merge"] = True
        
        # æµ‹è¯• 4: å¹¶è¡Œæ‰¹æ”¹æ¨¡æ‹Ÿ
        parallel_results = await test_parallel_grading_simulation()
        test_results["parallel_grading"] = True
        
        # æµ‹è¯• 5: å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹
        student_results = await test_student_boundary_detection()
        test_results["student_boundary"] = True
        
        # æµ‹è¯• 6: æ€»åˆ†éªŒè¯
        score_valid = await test_total_score_validation()
        test_results["total_score_validation"] = True
        
        # æµ‹è¯• 7: JSON åºåˆ—åŒ–
        json_valid = await test_json_serialization()
        test_results["json_serialization"] = True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for test_name, passed in test_results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{status}: {test_name}")
    
    all_passed = all(test_results.values())
    
    if all_passed:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‰¹æ”¹å·¥ä½œæµä¼˜åŒ–è¿è¡Œæ­£å¸¸ï¼")
        print(f"\næ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
        print(f"  âœ… åŠ¨æ€è¯„åˆ†æ ‡å‡†è·å–")
        print(f"  âœ… è·¨é¡µé¢˜ç›®è¯†åˆ«ä¸åˆå¹¶")
        print(f"  âœ… å¹¶è¡Œæ‰¹æ”¹èƒ½åŠ›")
        print(f"  âœ… ç»“æœæ™ºèƒ½åˆå¹¶")
        print(f"  âœ… å­¦ç”Ÿè¾¹ç•Œæ£€æµ‹")
        print(f"  âœ… æ€»åˆ†éªŒè¯")
        print(f"  âœ… JSON åºåˆ—åŒ–")
    else:
        print(f"\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    return all_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
