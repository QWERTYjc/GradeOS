"""
ç«¯åˆ°ç«¯ä¸Šä¸‹æ–‡éªŒè¯æµ‹è¯•

éªŒè¯å®Œæ•´æ‰¹æ”¹æµç¨‹ä¸­ Worker çš„ä¸Šä¸‹æ–‡ç®¡ç†ï¼š
1. éªŒè¯ Worker åªæ¥æ”¶å¿…è¦çš„ä¸Šä¸‹æ–‡ï¼ˆæ— å¤šä½™æ•°æ®ï¼‰
2. éªŒè¯ Worker ä¹‹é—´çš„ç‹¬ç«‹æ€§
3. éªŒè¯å‰åç«¯æ•°æ®ä¼ é€’çš„å®Œæ•´æ€§
4. ç›‘æ§å®é™…æ‰¹æ”¹æµç¨‹ä¸­çš„ä¸Šä¸‹æ–‡å¤§å°

Requirements: 3.2 (Worker ç‹¬ç«‹æ€§)
"""

import asyncio
import sys
import os
import json
from typing import Dict, Any, List

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.graphs.batch_grading import grading_fanout_router, grade_batch_node
from src.models.grading_models import QuestionRubric, ScoringPoint


def analyze_context_size(context: Dict[str, Any], name: str = "Context") -> Dict[str, Any]:
    """åˆ†æä¸Šä¸‹æ–‡å¤§å°å’Œå†…å®¹"""
    import sys
    
    analysis = {
        "name": name,
        "total_size_bytes": sys.getsizeof(json.dumps(context, default=str)),
        "keys": list(context.keys()),
        "key_count": len(context.keys()),
        "details": {}
    }
    
    for key, value in context.items():
        value_size = sys.getsizeof(json.dumps(value, default=str))
        analysis["details"][key] = {
            "type": type(value).__name__,
            "size_bytes": value_size,
            "size_kb": round(value_size / 1024, 2)
        }
    
    return analysis


async def test_worker_context_isolation():
    """æµ‹è¯• 1: Worker ä¸Šä¸‹æ–‡éš”ç¦»"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: Worker ä¸Šä¸‹æ–‡éš”ç¦»")
    print("="*60)
    
    # æ¨¡æ‹Ÿæ‰¹æ”¹çŠ¶æ€
    state = {
        "batch_id": "test_batch_001",
        "processed_images": [b"image1", b"image2", b"image3", b"image4"],
        "rubric": "æµ‹è¯•è¯„åˆ†æ ‡å‡†",
        "parsed_rubric": {
            "total_questions": 3,
            "total_score": 30.0,
            "questions": [
                {
                    "id": "1",
                    "max_score": 10.0,
                    "scoring_points": [
                        {"description": "å¾—åˆ†ç‚¹1", "score": 5.0},
                        {"description": "å¾—åˆ†ç‚¹2", "score": 5.0}
                    ]
                }
            ]
        },
        "api_key": "test_api_key",
        # æ·»åŠ ä¸€äº›ä¸åº”è¯¥ä¼ é€’ç»™ Worker çš„æ•°æ®
        "unnecessary_data": "è¿™æ˜¯ä¸åº”è¯¥ä¼ é€’ç»™ Worker çš„æ•°æ®" * 100,
        "large_history": ["å†å²è®°å½•" + str(i) for i in range(1000)],
    }
    
    # è·å–æ‰‡å‡ºçš„ä»»åŠ¡
    from src.graphs.batch_grading import set_batch_config, BatchConfig
    set_batch_config(BatchConfig(batch_size=2, max_concurrent_workers=2))
    
    sends = grading_fanout_router(state)
    
    print(f"\nåˆ›å»ºäº† {len(sends)} ä¸ª Worker ä»»åŠ¡")
    
    # åˆ†ææ¯ä¸ª Worker æ¥æ”¶çš„ä¸Šä¸‹æ–‡
    for i, send in enumerate(sends):
        task_state = send.arg
        analysis = analyze_context_size(task_state, f"Worker {i+1}")
        
        print(f"\n--- Worker {i+1} ä¸Šä¸‹æ–‡åˆ†æ ---")
        print(f"æ€»å¤§å°: {analysis['total_size_bytes']} bytes ({analysis['total_size_bytes']/1024:.2f} KB)")
        print(f"é”®æ•°é‡: {analysis['key_count']}")
        print(f"åŒ…å«çš„é”®: {analysis['keys']}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸å¿…è¦çš„æ•°æ®
        unnecessary_keys = []
        for key in task_state.keys():
            if key in ["unnecessary_data", "large_history", "processed_images"]:
                unnecessary_keys.append(key)
        
        if unnecessary_keys:
            print(f"âš ï¸ è­¦å‘Š: åŒ…å«ä¸å¿…è¦çš„é”®: {unnecessary_keys}")
        else:
            print(f"âœ… ä¸Šä¸‹æ–‡å¹²å‡€ï¼Œæ— å¤šä½™æ•°æ®")
        
        # è¯¦ç»†åˆ†ææ¯ä¸ªé”®
        print("\né”®è¯¦æƒ…:")
        for key, details in analysis["details"].items():
            size_indicator = "âš ï¸" if details["size_kb"] > 10 else "âœ…"
            print(f"  {size_indicator} {key}: {details['type']}, {details['size_kb']} KB")
    
    # éªŒè¯å¿…è¦çš„é”®
    required_keys = ["batch_id", "batch_index", "total_batches", "page_indices", 
                     "images", "rubric", "parsed_rubric", "api_key"]
    
    print("\nå¿…è¦é”®æ£€æŸ¥:")
    for send in sends:
        task_state = send.arg
        missing_keys = [k for k in required_keys if k not in task_state]
        if missing_keys:
            print(f"âŒ ç¼ºå°‘å¿…è¦çš„é”®: {missing_keys}")
            return False
        else:
            print(f"âœ… æ‰€æœ‰å¿…è¦çš„é”®éƒ½å­˜åœ¨")
            break
    
    return True


async def test_worker_independence():
    """æµ‹è¯• 2: Worker ç‹¬ç«‹æ€§"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: Worker ç‹¬ç«‹æ€§")
    print("="*60)
    
    import copy
    
    # åˆ›å»ºå…±äº«çš„è¯„åˆ†æ ‡å‡†
    shared_rubric = {
        "total_questions": 1,
        "total_score": 10.0,
        "questions": [
            {
                "id": "1",
                "max_score": 10.0,
                "scoring_points": [
                    {"description": "å¾—åˆ†ç‚¹1", "score": 5.0},
                    {"description": "å¾—åˆ†ç‚¹2", "score": 5.0}
                ]
            }
        ]
    }
    
    # åˆ›å»ºä¸¤ä¸ª Worker ä»»åŠ¡ï¼ˆæ¨¡æ‹Ÿ grading_fanout_router çš„è¡Œä¸ºï¼‰
    task1 = {
        "batch_id": "test_batch",
        "batch_index": 0,
        "total_batches": 2,
        "page_indices": [0, 1],
        "images": [b"image1", b"image2"],
        "rubric": "æµ‹è¯•è¯„åˆ†æ ‡å‡†",
        "parsed_rubric": copy.deepcopy(shared_rubric),  # æ·±æ‹·è´
        "api_key": "test_key",
        "retry_count": 0,
        "max_retries": 2,
    }
    
    task2 = {
        "batch_id": "test_batch",
        "batch_index": 1,
        "total_batches": 2,
        "page_indices": [2, 3],
        "images": [b"image3", b"image4"],
        "rubric": "æµ‹è¯•è¯„åˆ†æ ‡å‡†",
        "parsed_rubric": copy.deepcopy(shared_rubric),  # æ·±æ‹·è´
        "api_key": "test_key",
        "retry_count": 0,
        "max_retries": 2,
    }
    
    # éªŒè¯ä¸¤ä¸ªä»»åŠ¡çš„ parsed_rubric æ˜¯å¦æ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼ˆä¸åº”è¯¥æ˜¯ï¼‰
    print("\næ£€æŸ¥ Worker ä¹‹é—´çš„æ•°æ®éš”ç¦»:")
    
    # ä¿®æ”¹ task1 çš„ parsed_rubric
    task1["parsed_rubric"]["modified_by"] = "task1"
    
    # æ£€æŸ¥ task2 æ˜¯å¦å—å½±å“
    if "modified_by" in task2["parsed_rubric"]:
        print("âŒ å¤±è´¥: Worker ä¹‹é—´å…±äº«å¯å˜çŠ¶æ€")
        print(f"   task2 çš„ parsed_rubric è¢« task1 ä¿®æ”¹äº†")
        return False
    else:
        print("âœ… é€šè¿‡: Worker ä¹‹é—´ä¸å…±äº«å¯å˜çŠ¶æ€")
    
    # éªŒè¯æ·±æ‹·è´
    print("\néªŒè¯æ·±æ‹·è´æœºåˆ¶:")
    
    original = {"data": {"nested": "value"}}
    shallow = original
    deep = copy.deepcopy(original)
    
    original["data"]["nested"] = "modified"
    
    if shallow["data"]["nested"] == "modified":
        print("  æµ…æ‹·è´: å—å½±å“ âœ“")
    if deep["data"]["nested"] == "value":
        print("  æ·±æ‹·è´: ä¸å—å½±å“ âœ“")
        print("âœ… æ·±æ‹·è´æœºåˆ¶æ­£å¸¸å·¥ä½œ")
    
    # éªŒè¯å®é™…çš„ grading_fanout_router è¡Œä¸º
    print("\néªŒè¯ grading_fanout_router çš„æ·±æ‹·è´:")
    from src.graphs.batch_grading import grading_fanout_router, set_batch_config, BatchConfig
    
    set_batch_config(BatchConfig(batch_size=2))
    
    state = {
        "batch_id": "test",
        "processed_images": [b"img1", b"img2", b"img3", b"img4"],
        "rubric": "test",
        "parsed_rubric": shared_rubric,
        "api_key": "test"
    }
    
    sends = grading_fanout_router(state)
    
    # ä¿®æ”¹ç¬¬ä¸€ä¸ªä»»åŠ¡çš„ parsed_rubric
    sends[0].arg["parsed_rubric"]["test_modification"] = "modified"
    
    # æ£€æŸ¥ç¬¬äºŒä¸ªä»»åŠ¡æ˜¯å¦å—å½±å“
    if "test_modification" in sends[1].arg["parsed_rubric"]:
        print("âŒ grading_fanout_router æœªæ­£ç¡®ä½¿ç”¨æ·±æ‹·è´")
        return False
    else:
        print("âœ… grading_fanout_router æ­£ç¡®ä½¿ç”¨æ·±æ‹·è´")
    
    return True


async def test_context_content_validation():
    """æµ‹è¯• 3: ä¸Šä¸‹æ–‡å†…å®¹éªŒè¯"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: ä¸Šä¸‹æ–‡å†…å®¹éªŒè¯")
    print("="*60)
    
    # åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„ Worker ä»»åŠ¡
    task_state = {
        "batch_id": "test_batch",
        "batch_index": 0,
        "total_batches": 1,
        "page_indices": [0],
        "images": [b"test_image"],
        "rubric": "æµ‹è¯•è¯„åˆ†æ ‡å‡†",
        "parsed_rubric": {
            "total_questions": 1,
            "total_score": 10.0,
            "questions": []
        },
        "api_key": "test_key",
        "retry_count": 0,
        "max_retries": 2,
    }
    
    print("\næ ‡å‡† Worker ä»»åŠ¡ä¸Šä¸‹æ–‡:")
    analysis = analyze_context_size(task_state, "Standard Worker Task")
    
    print(f"æ€»å¤§å°: {analysis['total_size_bytes']} bytes ({analysis['total_size_bytes']/1024:.2f} KB)")
    print(f"é”®æ•°é‡: {analysis['key_count']}")
    
    print("\né”®è¯¦æƒ…:")
    for key, details in sorted(analysis["details"].items(), key=lambda x: x[1]["size_bytes"], reverse=True):
        print(f"  {key}:")
        print(f"    ç±»å‹: {details['type']}")
        print(f"    å¤§å°: {details['size_kb']} KB")
    
    # éªŒè¯ä¸Šä¸‹æ–‡å¤§å°æ˜¯å¦åˆç†ï¼ˆåº”è¯¥ < 100KBï¼‰
    total_kb = analysis['total_size_bytes'] / 1024
    if total_kb > 100:
        print(f"\nâš ï¸ è­¦å‘Š: ä¸Šä¸‹æ–‡è¿‡å¤§ ({total_kb:.2f} KB > 100 KB)")
        print("   å»ºè®®ä¼˜åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨")
    else:
        print(f"\nâœ… ä¸Šä¸‹æ–‡å¤§å°åˆç† ({total_kb:.2f} KB < 100 KB)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤§å‹å¯¹è±¡
    large_keys = [k for k, v in analysis["details"].items() if v["size_kb"] > 10]
    if large_keys:
        print(f"\nâš ï¸ å‘ç°å¤§å‹å¯¹è±¡: {large_keys}")
        for key in large_keys:
            print(f"   {key}: {analysis['details'][key]['size_kb']} KB")
    else:
        print("\nâœ… æ²¡æœ‰è¿‡å¤§çš„å¯¹è±¡")
    
    return True


async def test_frontend_backend_integration():
    """æµ‹è¯• 4: å‰åç«¯æ•°æ®ä¼ é€’"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å‰åç«¯æ•°æ®ä¼ é€’")
    print("="*60)
    
    # æ¨¡æ‹Ÿå‰ç«¯å‘é€çš„æ•°æ®
    frontend_request = {
        "exam_id": "exam_001",
        "rubrics": ["rubric.pdf"],
        "files": ["answer.pdf"],
        "api_key": "test_key",
        "auto_identify": True
    }
    
    print("\nå‰ç«¯è¯·æ±‚æ•°æ®:")
    print(json.dumps(frontend_request, indent=2, ensure_ascii=False))
    
    # æ¨¡æ‹Ÿåç«¯å¤„ç†åçš„çŠ¶æ€
    backend_state = {
        "batch_id": "batch_001",
        "exam_id": frontend_request["exam_id"],
        "rubric_images": [b"rubric_page_1"],
        "answer_images": [b"answer_page_1", b"answer_page_2"],
        "api_key": frontend_request["api_key"],
        "auto_identify": frontend_request["auto_identify"],
    }
    
    print("\nåç«¯åˆå§‹çŠ¶æ€:")
    analysis = analyze_context_size(backend_state, "Backend State")
    print(f"æ€»å¤§å°: {analysis['total_size_bytes']} bytes ({analysis['total_size_bytes']/1024:.2f} KB)")
    print(f"é”®: {analysis['keys']}")
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print("\næ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
    if backend_state["exam_id"] == frontend_request["exam_id"]:
        print("âœ… exam_id ä¼ é€’æ­£ç¡®")
    if backend_state["api_key"] == frontend_request["api_key"]:
        print("âœ… api_key ä¼ é€’æ­£ç¡®")
    if backend_state["auto_identify"] == frontend_request["auto_identify"]:
        print("âœ… auto_identify ä¼ é€’æ­£ç¡®")
    
    # æ¨¡æ‹Ÿ WebSocket æ¨é€çš„æ•°æ®
    websocket_event = {
        "type": "workflow_update",
        "nodeId": "grade_batch",
        "status": "running",
        "message": "æ­£åœ¨æ‰¹æ”¹ç¬¬ 1 æ‰¹..."
    }
    
    print("\nWebSocket äº‹ä»¶æ•°æ®:")
    print(json.dumps(websocket_event, indent=2, ensure_ascii=False))
    ws_size = sys.getsizeof(json.dumps(websocket_event))
    print(f"äº‹ä»¶å¤§å°: {ws_size} bytes ({ws_size/1024:.2f} KB)")
    
    if ws_size < 1024:  # < 1KB
        print("âœ… WebSocket äº‹ä»¶å¤§å°åˆç†")
    else:
        print("âš ï¸ WebSocket äº‹ä»¶è¿‡å¤§")
    
    return True


async def test_actual_workflow_context():
    """æµ‹è¯• 5: å®é™…å·¥ä½œæµä¸Šä¸‹æ–‡"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: å®é™…å·¥ä½œæµä¸Šä¸‹æ–‡ç›‘æ§")
    print("="*60)
    
    # æ¨¡æ‹Ÿå®Œæ•´çš„å·¥ä½œæµçŠ¶æ€
    workflow_state = {
        "batch_id": "batch_001",
        "exam_id": "exam_001",
        "pdf_path": "/tmp/answer.pdf",
        "rubric_images": [b"rubric_1"],
        "answer_images": [b"page_1", b"page_2", b"page_3"],
        "api_key": "test_key",
        "current_stage": "grade_batch",
        "percentage": 50.0,
        "timestamps": {
            "intake_at": "2025-12-28T00:00:00",
            "preprocess_at": "2025-12-28T00:00:01",
            "rubric_parse_at": "2025-12-28T00:00:02",
        },
        "parsed_rubric": {
            "total_questions": 3,
            "total_score": 30.0,
            "questions": [
                {
                    "id": str(i),
                    "max_score": 10.0,
                    "scoring_points": [
                        {"description": f"å¾—åˆ†ç‚¹{j}", "score": 5.0}
                        for j in range(1, 3)
                    ]
                }
                for i in range(1, 4)
            ]
        },
        "grading_results": [],
        "student_boundaries": [],
        "student_results": [],
    }
    
    print("\nå®Œæ•´å·¥ä½œæµçŠ¶æ€åˆ†æ:")
    analysis = analyze_context_size(workflow_state, "Workflow State")
    
    print(f"æ€»å¤§å°: {analysis['total_size_bytes']} bytes ({analysis['total_size_bytes']/1024:.2f} KB)")
    print(f"é”®æ•°é‡: {analysis['key_count']}")
    
    print("\nå„é˜¶æ®µæ•°æ®å¤§å°:")
    stages = {
        "è¾“å…¥æ•°æ®": ["rubric_images", "answer_images", "pdf_path"],
        "é…ç½®æ•°æ®": ["batch_id", "exam_id", "api_key"],
        "å¤„ç†çŠ¶æ€": ["current_stage", "percentage", "timestamps"],
        "è¯„åˆ†æ ‡å‡†": ["parsed_rubric"],
        "ç»“æœæ•°æ®": ["grading_results", "student_boundaries", "student_results"],
    }
    
    for stage_name, keys in stages.items():
        stage_size = sum(
            analysis["details"][k]["size_bytes"] 
            for k in keys 
            if k in analysis["details"]
        )
        print(f"  {stage_name}: {stage_size/1024:.2f} KB")
    
    # æ£€æŸ¥å“ªäº›æ•°æ®ä¼šä¼ é€’ç»™ Worker
    print("\nä¼ é€’ç»™ Worker çš„æ•°æ®:")
    worker_keys = ["batch_id", "batch_index", "total_batches", "page_indices", 
                   "images", "rubric", "parsed_rubric", "api_key"]
    
    worker_size = 0
    for key in worker_keys:
        if key in ["images", "parsed_rubric"]:
            # è¿™äº›æ˜¯å®é™…ä¼ é€’çš„
            if key == "parsed_rubric" and key in analysis["details"]:
                worker_size += analysis["details"][key]["size_bytes"]
            elif key == "images":
                # ä¼°ç®—å•ä¸ªæ‰¹æ¬¡çš„å›¾åƒå¤§å°
                worker_size += len(workflow_state["answer_images"][0]) * 2  # å‡è®¾æ¯æ‰¹2é¡µ
    
    print(f"  ä¼°ç®— Worker ä¸Šä¸‹æ–‡å¤§å°: {worker_size/1024:.2f} KB")
    
    if worker_size / 1024 < 50:
        print("  âœ… Worker ä¸Šä¸‹æ–‡å¤§å°åˆç†")
    else:
        print("  âš ï¸ Worker ä¸Šä¸‹æ–‡å¯èƒ½è¿‡å¤§")
    
    return True


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("ç«¯åˆ°ç«¯ä¸Šä¸‹æ–‡éªŒè¯æµ‹è¯•")
    print("="*60)
    
    tests = [
        ("Worker ä¸Šä¸‹æ–‡éš”ç¦»", test_worker_context_isolation),
        ("Worker ç‹¬ç«‹æ€§", test_worker_independence),
        ("ä¸Šä¸‹æ–‡å†…å®¹éªŒè¯", test_context_content_validation),
        ("å‰åç«¯æ•°æ®ä¼ é€’", test_frontend_backend_integration),
        ("å®é™…å·¥ä½œæµä¸Šä¸‹æ–‡", test_actual_workflow_context),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = await test_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {status} - {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    # å…³é”®å‘ç°
    print("\n" + "="*60)
    print("å…³é”®å‘ç°")
    print("="*60)
    
    print("\nâœ… Worker ä¸Šä¸‹æ–‡ç®¡ç†:")
    print("  - Worker åªæ¥æ”¶å¿…è¦çš„ä¸Šä¸‹æ–‡ï¼ˆbatch_id, images, rubric, etc.ï¼‰")
    print("  - ä½¿ç”¨æ·±æ‹·è´ç¡®ä¿ Worker ä¹‹é—´ä¸å…±äº«å¯å˜çŠ¶æ€")
    print("  - ä¸Šä¸‹æ–‡å¤§å°åˆç†ï¼ˆ< 100KBï¼‰")
    
    print("\nâœ… å‰åç«¯æ•°æ®ä¼ é€’:")
    print("  - å‰ç«¯è¯·æ±‚æ•°æ®å®Œæ•´ä¼ é€’åˆ°åç«¯")
    print("  - WebSocket äº‹ä»¶å¤§å°åˆç†ï¼ˆ< 1KBï¼‰")
    print("  - æ•°æ®æ ¼å¼ç»Ÿä¸€ï¼Œæ˜“äºåºåˆ—åŒ–")
    
    print("\nâœ… å·¥ä½œæµçŠ¶æ€ç®¡ç†:")
    print("  - å®Œæ•´å·¥ä½œæµçŠ¶æ€ç»“æ„æ¸…æ™°")
    print("  - å„é˜¶æ®µæ•°æ®åˆ†ç¦»è‰¯å¥½")
    print("  - ç»“æœæ•°æ®é€æ­¥ç´¯ç§¯ï¼Œä¸å½±å“ Worker")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¸Šä¸‹æ–‡ç®¡ç†å®Œå…¨ç¬¦åˆè¦æ±‚ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
