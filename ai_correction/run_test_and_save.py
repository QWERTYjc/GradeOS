#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿è¡Œæµ‹è¯•å¹¶ä¿å­˜æ‰€æœ‰ Agent è¾“å‡º
"""

import sys
import os
import time
from pathlib import Path
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['OPENROUTER_API_KEY'] = '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'
os.environ['LLM_PROVIDER'] = 'openrouter'
os.environ['LLM_MODEL'] = 'google/gemini-2.0-flash-exp:free'
os.environ['DATABASE_TYPE'] = 'json'

# è¾“å‡ºæ–‡ä»¶
output_file = Path('agent_outputs.md')
json_file = Path('agent_outputs.json')

class OutputCollector:
    """æ”¶é›†æ‰€æœ‰è¾“å‡º"""
    
    def __init__(self):
        self.outputs = []
        self.start_time = time.time()
    
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        elapsed = time.time() - self.start_time
        timestamp = datetime.now().strftime('%H:%M:%S')
        entry = {
            'timestamp': timestamp,
            'elapsed': f"{elapsed:.2f}s",
            'message': message
        }
        self.outputs.append(entry)
        print(f"[{timestamp}] {message}")
    
    def save_to_markdown(self, filepath):
        """ä¿å­˜ä¸º Markdown"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("# AI æ‰¹æ”¹ç³»ç»Ÿ - Agent è¾“å‡ºæ±‡æ€»\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**é…ç½®ä¿¡æ¯**:\n")
            f.write(f"- LLM Provider: {os.getenv('LLM_PROVIDER')}\n")
            f.write(f"- LLM Model: {os.getenv('LLM_MODEL')}\n")
            f.write(f"- Database: {os.getenv('DATABASE_TYPE')}\n\n")
            f.write("---\n\n")
            
            for entry in self.outputs:
                f.write(f"**[{entry['timestamp']}]** ({entry['elapsed']}) {entry['message']}\n\n")
    
    def save_to_json(self, filepath):
        """ä¿å­˜ä¸º JSON"""
        data = {
            'test_time': datetime.now().isoformat(),
            'config': {
                'llm_provider': os.getenv('LLM_PROVIDER'),
                'llm_model': os.getenv('LLM_MODEL'),
                'database': os.getenv('DATABASE_TYPE')
            },
            'outputs': self.outputs
        }
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


def create_test_files():
    """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
    test_dir = Path('test_data')
    test_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºé¢˜ç›®æ–‡ä»¶
    question_file = test_dir / 'questions.txt'
    with open(question_file, 'w', encoding='utf-8') as f:
        f.write("""1. è®¡ç®— 2 + 3 = ?
A. 4
B. 5
C. 6
D. 7

2. å¡«ç©ºï¼šä¸­å›½çš„é¦–éƒ½æ˜¯_____ã€‚

3. ç®€ç­”é¢˜ï¼šè¯·ç®€è¿°Pythonçš„ä¸»è¦ç‰¹ç‚¹ã€‚ï¼ˆè‡³å°‘3ç‚¹ï¼‰

4. è®¡ç®—é¢˜ï¼šæ±‚è§£æ–¹ç¨‹ x + 5 = 10ï¼Œå¹¶å†™å‡ºè§£é¢˜æ­¥éª¤ã€‚
""")
    
    # åˆ›å»ºç­”æ¡ˆæ–‡ä»¶
    answer_file = test_dir / '001_å¼ ä¸‰_answers.txt'
    with open(answer_file, 'w', encoding='utf-8') as f:
        f.write("""1. B

2. åŒ—äº¬

3. Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
   - è¯­æ³•ç®€æ´æ˜“è¯»
   - æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼
   - æ‹¥æœ‰ä¸°å¯Œçš„æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“

4. è§£ï¼š
   x + 5 = 10
   x = 10 - 5
   x = 5
""")
    
    # åˆ›å»ºè¯„åˆ†æ ‡å‡†æ–‡ä»¶
    marking_file = test_dir / 'marking_scheme.txt'
    with open(marking_file, 'w', encoding='utf-8') as f:
        f.write("""è¯„åˆ†æ ‡å‡†ï¼š

1. é€‰æ‹©é¢˜ (2åˆ†)
   - é€‰å¯¹å¾—2åˆ†
   - é€‰é”™å¾—0åˆ†

2. å¡«ç©ºé¢˜ (2åˆ†)
   - ç­”æ¡ˆæ­£ç¡®å¾—2åˆ†
   - ç­”æ¡ˆé”™è¯¯å¾—0åˆ†

3. ç®€ç­”é¢˜ (3åˆ†)
   - æåˆ°"é«˜çº§è¯­è¨€"å¾—1åˆ†
   - æåˆ°"è¯­æ³•ç®€æ´"å¾—1åˆ†
   - æåˆ°"ä¸°å¯Œçš„åº“"å¾—1åˆ†

4. è®¡ç®—é¢˜ (3åˆ†)
   - åˆ—å‡ºæ–¹ç¨‹å¾—1åˆ†
   - è®¡ç®—è¿‡ç¨‹æ­£ç¡®å¾—1åˆ†
   - ç­”æ¡ˆæ­£ç¡®å¾—1åˆ†
""")
    
    return str(question_file), str(answer_file), str(marking_file)


def main():
    """ä¸»å‡½æ•°"""
    collector = OutputCollector()
    
    collector.log("=" * 80)
    collector.log("ğŸš€ AI æ‰¹æ”¹ç³»ç»Ÿæµ‹è¯•å¼€å§‹")
    collector.log("=" * 80)
    
    # æµ‹è¯• LLM è¿æ¥
    collector.log("\nğŸ“¡ æ­¥éª¤ 1: æµ‹è¯• LLM è¿æ¥")
    collector.log("-" * 80)
    
    try:
        from functions.llm_client import get_llm_client
        
        client = get_llm_client()
        collector.log(f"âœ… LLM Client åˆ›å»ºæˆåŠŸ")
        collector.log(f"   Provider: {client.provider}")
        collector.log(f"   Model: {client.model}")
        collector.log(f"   Base URL: {client.base_url}")
        
        # æµ‹è¯•è°ƒç”¨
        collector.log("\nğŸ“¡ æµ‹è¯• API è°ƒç”¨...")
        messages = [{"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç» Pythonã€‚"}]
        
        start_time = time.time()
        response = client.chat(messages)
        elapsed = time.time() - start_time
        
        collector.log(f"âœ… API è°ƒç”¨æˆåŠŸï¼")
        collector.log(f"   è€—æ—¶: {elapsed:.2f}ç§’")
        collector.log(f"   å“åº”: {response[:100]}...")
        
    except Exception as e:
        collector.log(f"âŒ LLM è¿æ¥å¤±è´¥: {e}")
        import traceback
        collector.log(traceback.format_exc())
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    collector.log("\nğŸ“ æ­¥éª¤ 2: åˆ›å»ºæµ‹è¯•æ–‡ä»¶")
    collector.log("-" * 80)
    
    question_file, answer_file, marking_file = create_test_files()
    collector.log(f"âœ… æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º")
    collector.log(f"   é¢˜ç›®æ–‡ä»¶: {question_file}")
    collector.log(f"   ç­”æ¡ˆæ–‡ä»¶: {answer_file}")
    collector.log(f"   è¯„åˆ†æ ‡å‡†: {marking_file}")
    
    # è¿è¡Œå·¥ä½œæµ
    collector.log("\nğŸš€ æ­¥éª¤ 3: è¿è¡Œæ‰¹æ”¹å·¥ä½œæµ")
    collector.log("=" * 80)
    
    try:
        from functions.langgraph.workflow_production import run_grading_workflow
        
        node_count = 0
        final_state = None
        
        for output in run_grading_workflow(
            question_files=[question_file],
            answer_files=[answer_file],
            marking_files=[marking_file],
            stream=True
        ):
            for node_name, node_state in output.items():
                node_count += 1
                
                collector.log(f"\nâš¡ Agent #{node_count}: {node_name}")
                collector.log("-" * 80)
                
                # è¯¦ç»†è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„çŠ¶æ€
                if node_name == 'parse_input':
                    status = node_state.get('parse_status', 'unknown')
                    questions = node_state.get('questions', [])
                    answers = node_state.get('answers', [])
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"ğŸ“ è§£æç»“æœ:")
                    collector.log(f"   - é¢˜ç›®æ•°é‡: {len(questions)}")
                    collector.log(f"   - ç­”æ¡ˆæ•°é‡: {len(answers)}")
                    
                    for q in questions:
                        collector.log(f"   - é¢˜ç›® {q['id']}: {q.get('text', '')[:50]}...")
                    
                elif node_name == 'analyze_questions':
                    status = node_state.get('analysis_status', 'unknown')
                    questions = node_state.get('questions', [])
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"ğŸ” åˆ†æç»“æœ:")
                    
                    for q in questions:
                        analysis = q.get('analysis', {})
                        collector.log(f"   - é¢˜ç›® {q['id']}:")
                        collector.log(f"     ç±»å‹: {q.get('type')}")
                        collector.log(f"     éš¾åº¦: {analysis.get('difficulty')}")
                        collector.log(f"     ç­–ç•¥: {analysis.get('strategy')}")
                        collector.log(f"     å…³é”®è¯: {analysis.get('keywords', [])}")
                
                elif node_name == 'interpret_rubric':
                    status = node_state.get('rubric_status', 'unknown')
                    rubric = node_state.get('rubric_interpretation', {})
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"ğŸ“‹ è¯„åˆ†æ ‡å‡†è§£æ:")
                    
                    for qid, criteria in rubric.items():
                        collector.log(f"   - é¢˜ç›® {qid}:")
                        for criterion in criteria:
                            collector.log(f"     * {criterion.get('description')}: {criterion.get('points')}åˆ†")
                
                elif node_name == 'grade_questions':
                    status = node_state.get('grading_status', 'unknown')
                    results = node_state.get('grading_results', [])
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"âœï¸  æ‰¹æ”¹ç»“æœ:")
                    collector.log(f"   - å·²æ‰¹æ”¹é¢˜ç›®æ•°: {len(results)}")
                    
                    for r in results:
                        collector.log(f"   - é¢˜ç›® {r['question_id']}:")
                        collector.log(f"     å¾—åˆ†: {r['score']}/{r['max_score']}")
                        collector.log(f"     ç­–ç•¥: {r.get('strategy')}")
                        collector.log(f"     åé¦ˆ: {r.get('feedback', 'N/A')}")
                        if 'errors' in r and r['errors']:
                            collector.log(f"     é”™è¯¯: {r['errors']}")
                        if 'suggestions' in r and r['suggestions']:
                            collector.log(f"     å»ºè®®: {r['suggestions']}")
                
                elif node_name == 'aggregate_results':
                    status = node_state.get('aggregation_status', 'unknown')
                    aggregated = node_state.get('aggregated_results', {})
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"ğŸ“ˆ æ±‡æ€»ç»“æœ:")
                    collector.log(f"   - æ€»åˆ†: {aggregated.get('total_score')}/{aggregated.get('max_score')}")
                    collector.log(f"   - å¾—åˆ†ç‡: {aggregated.get('percentage', 0):.1f}%")
                    collector.log(f"   - ç­‰çº§: {aggregated.get('grade')}")
                    
                    errors = aggregated.get('error_analysis', [])
                    if errors:
                        collector.log(f"   - é”™è¯¯åˆ†æ:")
                        for err in errors:
                            collector.log(f"     * {err.get('description')}")
                    
                    knowledge = aggregated.get('knowledge_points', {})
                    if knowledge:
                        collector.log(f"   - çŸ¥è¯†ç‚¹æŒæ¡:")
                        for kp, mastery in knowledge.items():
                            collector.log(f"     * {kp}: {mastery:.1f}%")
                
                elif node_name == 'persist_data':
                    status = node_state.get('persistence_status', 'unknown')
                    
                    collector.log(f"ğŸ“Š çŠ¶æ€: {status}")
                    collector.log(f"ğŸ’¾ æ•°æ®å·²æŒä¹…åŒ–")
                
                final_state = node_state
        
        total_time = time.time() - collector.start_time
        
        collector.log("\n" + "=" * 80)
        collector.log(f"âœ… æ‰¹æ”¹å®Œæˆï¼")
        collector.log(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        collector.log(f"ğŸ“Š å¤„ç†èŠ‚ç‚¹æ•°: {node_count}")
        collector.log(f"âš¡ å¹³å‡æ¯èŠ‚ç‚¹: {total_time/node_count:.2f}ç§’")
        collector.log("=" * 80)
        
    except Exception as e:
        collector.log(f"\nâŒ å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        collector.log(traceback.format_exc())
    
    # ä¿å­˜è¾“å‡º
    collector.log("\nğŸ’¾ ä¿å­˜è¾“å‡ºåˆ°æ–‡ä»¶...")
    collector.save_to_markdown(output_file)
    collector.save_to_json(json_file)
    
    collector.log(f"âœ… Markdown è¾“å‡ºå·²ä¿å­˜: {output_file.absolute()}")
    collector.log(f"âœ… JSON è¾“å‡ºå·²ä¿å­˜: {json_file.absolute()}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼è¯·æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶ï¼š")
    print(f"   - {output_file.absolute()}")
    print(f"   - {json_file.absolute()}")
    print("=" * 80)


if __name__ == '__main__':
    main()

