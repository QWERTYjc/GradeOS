#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§çº§ LangGraph é›†æˆ - Streamlit æ¥å£
"""

import streamlit as st
from typing import List, Dict, Any
from pathlib import Path
import time
import os
from datetime import datetime


def run_production_grading(
    question_files: List[str],
    answer_files: List[str],
    marking_files: List[str] = None,
    llm_api_key: str = None
) -> Dict[str, Any]:
    """
    è¿è¡Œç”Ÿäº§çº§æ‰¹æ”¹

    Args:
        question_files: é¢˜ç›®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        answer_files: ç­”æ¡ˆæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        marking_files: è¯„åˆ†æ ‡å‡†æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        llm_api_key: LLM API å¯†é’¥

    Returns:
        æ‰¹æ”¹ç»“æœ
    """
    from .workflow_production import run_grading_workflow, format_grading_result

    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()

    with progress_container:
        st.info("ğŸš€ å¼€å§‹æ‰¹æ”¹æµç¨‹...")

        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆ›å»º Agent è¾“å‡ºå±•ç¤ºåŒºåŸŸ
        agent_outputs_container = st.expander("ğŸ“Š æŸ¥çœ‹ Agent æ‰§è¡Œè¯¦æƒ…", expanded=True)

        # æµå¼è¿è¡Œå·¥ä½œæµ
        total_steps = 6
        current_step = 0

        final_state = None
        agent_outputs = []

        try:
            for output in run_grading_workflow(
                question_files=question_files,
                answer_files=answer_files,
                marking_files=marking_files,
                stream=True
            ):
                # æ›´æ–°è¿›åº¦
                if output:
                    current_step += 1
                    progress = min(current_step / total_steps, 1.0)
                    progress_bar.progress(progress)

                    # è·å–å½“å‰æ­¥éª¤
                    for node_name, node_state in output.items():
                        stream_outputs = node_state.get('stream_output', [])

                        for stream_output in stream_outputs:
                            step = stream_output.get('step', 'unknown')
                            status = stream_output.get('status', 'unknown')

                            # æ›´æ–°çŠ¶æ€æ–‡æœ¬
                            if step == 'parse':
                                status_text.text("ğŸ“„ Agent #1: è§£æè¾“å…¥æ–‡ä»¶...")
                                agent_outputs.append({
                                    'agent': 'InputParserAgent',
                                    'step': 'parse',
                                    'status': status,
                                    'data': node_state
                                })
                            elif step == 'analyze':
                                status_text.text("ğŸ” Agent #2: åˆ†æé¢˜ç›®ç‰¹å¾...")
                                agent_outputs.append({
                                    'agent': 'QuestionAnalyzerAgent',
                                    'step': 'analyze',
                                    'status': status,
                                    'data': node_state
                                })
                            elif step == 'rubric':
                                status_text.text("ğŸ“‹ Agent #3: è§£æè¯„åˆ†æ ‡å‡†...")
                                agent_outputs.append({
                                    'agent': 'RubricInterpreterAgent',
                                    'step': 'rubric',
                                    'status': status,
                                    'data': node_state
                                })
                            elif step == 'grading':
                                q_id = stream_output.get('question_id')
                                progress_info = stream_output.get('progress', '')
                                status_text.text(f"âœï¸ Agent #4: æ‰¹æ”¹ç¬¬ {q_id} é¢˜ ({progress_info})...")
                                agent_outputs.append({
                                    'agent': 'QuestionGraderAgent',
                                    'step': 'grading',
                                    'status': status,
                                    'question_id': q_id,
                                    'data': node_state
                                })
                            elif step == 'aggregate':
                                status_text.text("ğŸ“Š Agent #5: èšåˆç»“æœ...")
                                agent_outputs.append({
                                    'agent': 'ResultAggregatorAgent',
                                    'step': 'aggregate',
                                    'status': status,
                                    'data': node_state
                                })
                            elif step == 'persist':
                                status_text.text("ğŸ’¾ Agent #6: ä¿å­˜æ•°æ®...")
                                agent_outputs.append({
                                    'agent': 'DataPersistenceAgent',
                                    'step': 'persist',
                                    'status': status,
                                    'data': node_state
                                })

                        final_state = node_state

                        # å®æ—¶æ˜¾ç¤º Agent è¾“å‡º
                        with agent_outputs_container:
                            for i, agent_output in enumerate(agent_outputs[-3:]):  # åªæ˜¾ç¤ºæœ€è¿‘3ä¸ª
                                agent_name = agent_output['agent']
                                agent_status = agent_output['status']

                                status_icon = "âœ…" if agent_status == "success" else "â³" if agent_status == "running" else "âŒ"
                                st.markdown(f"**{status_icon} {agent_name}**: {agent_status}")

            # å®Œæˆ
            progress_bar.progress(1.0)
            status_text.text("âœ… æ‰¹æ”¹å®Œæˆï¼")

            # æ ¼å¼åŒ–ç»“æœ
            if final_state:
                result_md = format_grading_result(final_state)

                # ä¿å­˜ Agent è¾“å‡ºåˆ°æ–‡ä»¶
                save_agent_outputs_to_file(agent_outputs, final_state)

                return {
                    'status': 'success',
                    'result': result_md,
                    'state': final_state,
                    'agent_outputs': agent_outputs
                }
            else:
                return {
                    'status': 'error',
                    'message': 'æ‰¹æ”¹æµç¨‹æœªå®Œæˆ'
                }

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            progress_bar.progress(0)
            status_text.text(f"âŒ æ‰¹æ”¹å¤±è´¥: {str(e)}")

            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯
            with st.expander("ğŸ” æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                st.code(error_details)

            return {
                'status': 'error',
                'message': str(e),
                'error_details': error_details
            }


def save_agent_outputs_to_file(agent_outputs: List[Dict], final_state: Dict):
    """ä¿å­˜ Agent è¾“å‡ºåˆ°æ–‡ä»¶"""
    try:
        output_dir = Path("ai_correction")
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        output_file = output_dir / f"agent_outputs_{timestamp}.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"# ğŸ“ AI æ‰¹æ”¹ç³»ç»Ÿ - Agent è¾“å‡ºè®°å½•\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")

            # å†™å…¥æ¯ä¸ª Agent çš„è¾“å‡º
            for i, output in enumerate(agent_outputs, 1):
                f.write(f"## Agent #{i}: {output['agent']}\n\n")
                f.write(f"- **çŠ¶æ€**: {output['status']}\n")
                f.write(f"- **æ­¥éª¤**: {output['step']}\n")

                if 'question_id' in output:
                    f.write(f"- **é¢˜ç›®ID**: {output['question_id']}\n")

                f.write("\n")

            # å†™å…¥æœ€ç»ˆç»“æœ
            if final_state:
                f.write("\n---\n\n")
                f.write("## ğŸ“Š æœ€ç»ˆç»“æœ\n\n")

                aggregated = final_state.get('aggregated_results', {})
                if aggregated:
                    f.write(f"- **æ€»åˆ†**: {aggregated.get('total_score', 0)}/{aggregated.get('max_score', 0)}\n")
                    f.write(f"- **å¾—åˆ†ç‡**: {aggregated.get('score_percentage', 0):.1f}%\n")
                    f.write(f"- **ç­‰çº§**: {aggregated.get('grade', 'N/A')}\n")

        st.success(f"âœ… Agent è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")

    except Exception as e:
        st.warning(f"âš ï¸ ä¿å­˜ Agent è¾“å‡ºå¤±è´¥: {str(e)}")


def show_production_grading_ui():
    """æ˜¾ç¤ºç”Ÿäº§çº§æ‰¹æ”¹ UI"""
    st.header("ğŸ“ ç”Ÿäº§çº§ AI æ‰¹æ”¹ç³»ç»Ÿ")
    
    st.markdown("""
    ### âœ¨ åŠŸèƒ½ç‰¹ç‚¹
    - ğŸ“ **é€é¢˜æ‰¹æ”¹**: ç²¾ç¡®å®šä½æ¯é“é¢˜çš„é”™è¯¯
    - ğŸ“Š **æ•°æ®åˆ†æ**: å¤šç»´åº¦ç»Ÿè®¡åˆ†æ
    - ğŸ’¾ **æ•°æ®æŒä¹…åŒ–**: è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“
    - ğŸ”„ **æµå¼å¤„ç†**: å®æ—¶åé¦ˆæ‰¹æ”¹è¿›åº¦
    - ğŸ¯ **æ™ºèƒ½ç­–ç•¥**: æ ¹æ®é¢˜å‹é€‰æ‹©æ‰¹æ”¹æ–¹æ³•
    """)
    
    # æ–‡ä»¶ä¸Šä¼ 
    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("ğŸ“„ é¢˜ç›®æ–‡ä»¶")
        question_files = st.file_uploader(
            "ä¸Šä¼ é¢˜ç›®æ–‡ä»¶",
            type=['txt', 'md', 'json', 'pdf', 'docx', 'jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'],
            accept_multiple_files=True,
            key='question_files',
            help="ğŸ“Œ æ¨èä½¿ç”¨å›¾ç‰‡æ ¼å¼ï¼ˆjpg/pngï¼‰ä»¥è·å¾—æœ€ä½³è¯†åˆ«æ•ˆæœ\nğŸ’¡ PDFéœ€è¦å®‰è£…PyPDF2åº“ï¼Œæ‰«æç‰ˆPDFè¯·è½¬æ¢ä¸ºå›¾ç‰‡"
        )

    with col2:
        st.subheader("âœï¸ ç­”æ¡ˆæ–‡ä»¶")
        answer_files = st.file_uploader(
            "ä¸Šä¼ ç­”æ¡ˆæ–‡ä»¶",
            type=['txt', 'md', 'json', 'pdf', 'docx', 'jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'],
            accept_multiple_files=True,
            key='answer_files',
            help="æ”¯æŒæ–‡æœ¬ã€PDFã€Wordã€å›¾ç‰‡æ ¼å¼"
        )

    with col3:
        st.subheader("ğŸ“‹ è¯„åˆ†æ ‡å‡†ï¼ˆå¯é€‰ï¼‰")
        marking_files = st.file_uploader(
            "ä¸Šä¼ è¯„åˆ†æ ‡å‡†",
            type=['txt', 'md', 'json', 'pdf', 'docx', 'jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'],
            accept_multiple_files=True,
            key='marking_files',
            help="æ”¯æŒæ–‡æœ¬ã€PDFã€Wordã€å›¾ç‰‡æ ¼å¼ï¼ˆå¯é€‰ï¼‰"
        )
    
    # API é…ç½®
    with st.expander("âš™ï¸ é«˜çº§é…ç½®"):
        llm_api_key = st.text_input(
            "LLM API å¯†é’¥ï¼ˆå¯é€‰ï¼‰",
            type="password",
            help="å¦‚æœä¸æä¾›ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…ç­‰ç®€å•ç­–ç•¥"
        )
        
        db_type = st.selectbox(
            "æ•°æ®åº“ç±»å‹",
            ['postgresql', 'mysql', 'json'],
            help="é€‰æ‹©æ•°æ®å­˜å‚¨æ–¹å¼"
        )
        
        if db_type != 'json':
            db_url = st.text_input(
                "æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²",
                help="ä¾‹å¦‚: postgresql://user:pass@localhost/dbname"
            )
    
    # å¼€å§‹æ‰¹æ”¹
    if st.button("ğŸš€ å¼€å§‹æ‰¹æ”¹", type="primary", use_container_width=True):
        if not question_files or not answer_files:
            st.error("âŒ è¯·è‡³å°‘ä¸Šä¼ é¢˜ç›®æ–‡ä»¶å’Œç­”æ¡ˆæ–‡ä»¶")
            return
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        import tempfile
        import os
        
        temp_dir = tempfile.mkdtemp()
        
        question_paths = []
        for f in question_files:
            path = os.path.join(temp_dir, f.name)
            with open(path, 'wb') as fp:
                fp.write(f.read())
            question_paths.append(path)
        
        answer_paths = []
        for f in answer_files:
            path = os.path.join(temp_dir, f.name)
            with open(path, 'wb') as fp:
                fp.write(f.read())
            answer_paths.append(path)
        
        marking_paths = []
        if marking_files:
            for f in marking_files:
                path = os.path.join(temp_dir, f.name)
                with open(path, 'wb') as fp:
                    fp.write(f.read())
                marking_paths.append(path)
        
        # è¿è¡Œæ‰¹æ”¹
        result = run_production_grading(
            question_files=question_paths,
            answer_files=answer_paths,
            marking_files=marking_paths if marking_paths else None,
            llm_api_key=llm_api_key
        )
        
        # æ˜¾ç¤ºç»“æœ
        if result['status'] == 'success':
            st.success("âœ… æ‰¹æ”¹å®Œæˆï¼")

            # æ˜¾ç¤ºæ‰¹æ”¹ç»“æœï¼ˆç®€å• Markdown æ ¼å¼ï¼‰
            st.markdown("---")
            st.markdown(result.get('result', ''))

            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ‰¹æ”¹ç»“æœ",
                data=result.get('result', ''),
                file_name=f"æ‰¹æ”¹ç»“æœ_{result.get('state', {}).get('student_info', {}).get('name', 'unknown')}_{result.get('timestamp', '')}.md",
                mime="text/markdown",
                use_container_width=True
            )

            # æ˜¾ç¤ºè¯¦ç»†æ•°æ®ï¼ˆå¯æŠ˜å ï¼‰
            with st.expander("ğŸ“Š æŸ¥çœ‹ Agent æ‰§è¡Œè¯¦æƒ…"):
                st.json(result.get('state', {}))
        else:
            st.error(f"âŒ æ‰¹æ”¹å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            if 'error' in result:
                st.code(result['error'])


def show_history_ui():
    """æ˜¾ç¤ºå†å²è®°å½• UI"""
    st.header("ğŸ“š æ‰¹æ”¹å†å²")
    
    from ..database import DatabaseManager
    
    db = DatabaseManager()
    
    # å­¦ç”ŸæŸ¥è¯¢
    student_id = st.text_input("è¾“å…¥å­¦å·æŸ¥è¯¢å†å²è®°å½•")
    
    if student_id:
        history = db.get_student_history(student_id)
        
        if history:
            st.success(f"æ‰¾åˆ° {len(history)} æ¡è®°å½•")
            
            for record in history:
                with st.expander(f"ğŸ“ {record['subject']} - {record['created_at']}"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("å¾—åˆ†", f"{record['total_score']}/{record['max_score']}")
                    
                    with col2:
                        st.metric("ç­‰çº§", record['grade'])
                    
                    with col3:
                        st.metric("ä»»åŠ¡ID", record['task_id'])
        else:
            st.info("æš‚æ— å†å²è®°å½•")


def show_class_statistics_ui():
    """æ˜¾ç¤ºç­çº§ç»Ÿè®¡ UI"""
    st.header("ğŸ“Š ç­çº§ç»Ÿè®¡")
    
    from ..database import DatabaseManager
    
    db = DatabaseManager()
    
    # ç­çº§æŸ¥è¯¢
    class_name = st.text_input("è¾“å…¥ç­çº§åç§°")
    
    if class_name:
        stats = db.get_class_statistics(class_name)
        
        if stats['student_count'] > 0:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("å­¦ç”Ÿäººæ•°", stats['student_count'])
            
            with col2:
                st.metric("æ‰¹æ”¹ä»»åŠ¡æ•°", stats['total_tasks'])
            
            with col3:
                st.metric("å¹³å‡åˆ†", f"{stats['average_score']:.1f}%")
            
            with col4:
                st.metric("ç­çº§", class_name)
        else:
            st.info("æš‚æ— æ•°æ®")


# å·²åˆ é™¤ _display_grading_result_enhanced() å‡½æ•°
# ç°åœ¨ä½¿ç”¨ç®€å•çš„ Markdown æ˜¾ç¤º

