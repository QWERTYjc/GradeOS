#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§çº§ LangGraph é›†æˆ - Streamlit æ¥å£
"""

import streamlit as st
from typing import List, Dict, Any
from pathlib import Path
import time


def run_production_grading(
    question_files: List[str],
    answer_files: List[str],
    marking_files: List[str] = None,
    llm_api_key: str = None
) -> Dict[str, Any]:
    """
    è¿è¡Œç”Ÿäº§çº§æ‰¹æ”¹
    
    Args:
        question_files: é¢˜ç›®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        answer_files: ç­”æ¡ˆæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        marking_files: è¯„åˆ†æ ‡å‡†æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        llm_api_key: LLM API å¯†é’¥
        
    Returns:
        æ‰¹æ”¹ç»“æœ
    """
    from .workflow_production import run_grading_workflow, format_grading_result
    
    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()
    
    with progress_container:
        st.info("ğŸš€ å¼€å§‹æ‰¹æ”¹æµç¨‹...")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # æµå¼è¿è¡Œå·¥ä½œæµ
        total_steps = 6
        current_step = 0
        
        final_state = None
        
        try:
            for output in run_grading_workflow(
                question_files=question_files,
                answer_files=answer_files,
                marking_files=marking_files,
                stream=True
            ):
                # æ›´æ–°è¿›åº¦
                if output:
                    current_step += 1
                    progress = current_step / total_steps
                    progress_bar.progress(progress)
                    
                    # è·å–å½“å‰æ­¥éª¤
                    for node_name, node_state in output.items():
                        stream_outputs = node_state.get('stream_output', [])
                        
                        for stream_output in stream_outputs:
                            step = stream_output.get('step', 'unknown')
                            
                            if step == 'parse':
                                status_text.text("ğŸ“„ è§£æè¾“å…¥æ–‡ä»¶...")
                            elif step == 'analyze':
                                status_text.text("ğŸ” åˆ†æé¢˜ç›®ç‰¹å¾...")
                            elif step == 'rubric':
                                status_text.text("ğŸ“‹ è§£æè¯„åˆ†æ ‡å‡†...")
                            elif step == 'grading':
                                q_id = stream_output.get('question_id')
                                progress_info = stream_output.get('progress', '')
                                status_text.text(f"âœï¸ æ‰¹æ”¹ç¬¬ {q_id} é¢˜ ({progress_info})...")
                            elif step == 'aggregate':
                                status_text.text("ğŸ“Š èšåˆç»“æœ...")
                            elif step == 'persist':
                                status_text.text("ğŸ’¾ ä¿å­˜æ•°æ®...")
                        
                        final_state = node_state
            
            # å®Œæˆ
            progress_bar.progress(1.0)
            status_text.text("âœ… æ‰¹æ”¹å®Œæˆï¼")
            
            # æ ¼å¼åŒ–ç»“æœ
            if final_state:
                result_md = format_grading_result(final_state)
                return {
                    'status': 'success',
                    'result': result_md,
                    'state': final_state
                }
            else:
                return {
                    'status': 'error',
                    'message': 'æ‰¹æ”¹æµç¨‹æœªå®Œæˆ'
                }
                
        except Exception as e:
            progress_bar.progress(0)
            status_text.text(f"âŒ æ‰¹æ”¹å¤±è´¥: {str(e)}")
            return {
                'status': 'error',
                'message': str(e)
            }


def show_production_grading_ui():
    """æ˜¾ç¤ºç”Ÿäº§çº§æ‰¹æ”¹ UI"""
    st.header("ğŸ“ ç”Ÿäº§çº§ AI æ‰¹æ”¹ç³»ç»Ÿ")
    
    st.markdown("""
    ### âœ¨ åŠŸèƒ½ç‰¹ç‚¹
    - ğŸ“ **é€é¢˜æ‰¹æ”¹**: ç²¾ç¡®å®šä½æ¯é“é¢˜çš„é”™è¯¯
    - ğŸ“Š **æ•°æ®åˆ†æ**: å¤šç»´åº¦ç»Ÿè®¡åˆ†æ
    - ğŸ’¾ **æ•°æ®æŒä¹…åŒ–**: è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“
    - ğŸ”„ **æµå¼å¤„ç†**: å®æ—¶åé¦ˆæ‰¹æ”¹è¿›åº¦
    - ğŸ¯ **æ™ºèƒ½ç­–ç•¥**: æ ¹æ®é¢˜å‹é€‰æ‹©æ‰¹æ”¹æ–¹æ³•
    """)
    
    # æ–‡ä»¶ä¸Šä¼ 
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("ğŸ“„ é¢˜ç›®æ–‡ä»¶")
        question_files = st.file_uploader(
            "ä¸Šä¼ é¢˜ç›®æ–‡ä»¶",
            type=['txt', 'md', 'json'],
            accept_multiple_files=True,
            key='question_files'
        )
    
    with col2:
        st.subheader("âœï¸ ç­”æ¡ˆæ–‡ä»¶")
        answer_files = st.file_uploader(
            "ä¸Šä¼ ç­”æ¡ˆæ–‡ä»¶",
            type=['txt', 'md', 'json'],
            accept_multiple_files=True,
            key='answer_files'
        )
    
    with col3:
        st.subheader("ğŸ“‹ è¯„åˆ†æ ‡å‡†ï¼ˆå¯é€‰ï¼‰")
        marking_files = st.file_uploader(
            "ä¸Šä¼ è¯„åˆ†æ ‡å‡†",
            type=['txt', 'md', 'json'],
            accept_multiple_files=True,
            key='marking_files'
        )
    
    # API é…ç½®
    with st.expander("âš™ï¸ é«˜çº§é…ç½®"):
        llm_api_key = st.text_input(
            "LLM API å¯†é’¥ï¼ˆå¯é€‰ï¼‰",
            type="password",
            help="å¦‚æœä¸æä¾›ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…ç­‰ç®€å•ç­–ç•¥"
        )
        
        db_type = st.selectbox(
            "æ•°æ®åº“ç±»å‹",
            ['postgresql', 'mysql', 'json'],
            help="é€‰æ‹©æ•°æ®å­˜å‚¨æ–¹å¼"
        )
        
        if db_type != 'json':
            db_url = st.text_input(
                "æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²",
                help="ä¾‹å¦‚: postgresql://user:pass@localhost/dbname"
            )
    
    # å¼€å§‹æ‰¹æ”¹
    if st.button("ğŸš€ å¼€å§‹æ‰¹æ”¹", type="primary", use_container_width=True):
        if not question_files or not answer_files:
            st.error("âŒ è¯·è‡³å°‘ä¸Šä¼ é¢˜ç›®æ–‡ä»¶å’Œç­”æ¡ˆæ–‡ä»¶")
            return
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        import tempfile
        import os
        
        temp_dir = tempfile.mkdtemp()
        
        question_paths = []
        for f in question_files:
            path = os.path.join(temp_dir, f.name)
            with open(path, 'wb') as fp:
                fp.write(f.read())
            question_paths.append(path)
        
        answer_paths = []
        for f in answer_files:
            path = os.path.join(temp_dir, f.name)
            with open(path, 'wb') as fp:
                fp.write(f.read())
            answer_paths.append(path)
        
        marking_paths = []
        if marking_files:
            for f in marking_files:
                path = os.path.join(temp_dir, f.name)
                with open(path, 'wb') as fp:
                    fp.write(f.read())
                marking_paths.append(path)
        
        # è¿è¡Œæ‰¹æ”¹
        result = run_production_grading(
            question_files=question_paths,
            answer_files=answer_paths,
            marking_files=marking_paths if marking_paths else None,
            llm_api_key=llm_api_key
        )
        
        # æ˜¾ç¤ºç»“æœ
        if result['status'] == 'success':
            st.success("âœ… æ‰¹æ”¹å®Œæˆï¼")
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown(result['result'])
            
            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ‰¹æ”¹ç»“æœ",
                data=result['result'],
                file_name="grading_result.md",
                mime="text/markdown"
            )
            
            # æ˜¾ç¤ºè¯¦ç»†æ•°æ®
            with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
                st.json(result['state'].get('aggregated_results', {}))
        else:
            st.error(f"âŒ æ‰¹æ”¹å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")


def show_history_ui():
    """æ˜¾ç¤ºå†å²è®°å½• UI"""
    st.header("ğŸ“š æ‰¹æ”¹å†å²")
    
    from ..database import DatabaseManager
    
    db = DatabaseManager()
    
    # å­¦ç”ŸæŸ¥è¯¢
    student_id = st.text_input("è¾“å…¥å­¦å·æŸ¥è¯¢å†å²è®°å½•")
    
    if student_id:
        history = db.get_student_history(student_id)
        
        if history:
            st.success(f"æ‰¾åˆ° {len(history)} æ¡è®°å½•")
            
            for record in history:
                with st.expander(f"ğŸ“ {record['subject']} - {record['created_at']}"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("å¾—åˆ†", f"{record['total_score']}/{record['max_score']}")
                    
                    with col2:
                        st.metric("ç­‰çº§", record['grade'])
                    
                    with col3:
                        st.metric("ä»»åŠ¡ID", record['task_id'])
        else:
            st.info("æš‚æ— å†å²è®°å½•")


def show_class_statistics_ui():
    """æ˜¾ç¤ºç­çº§ç»Ÿè®¡ UI"""
    st.header("ğŸ“Š ç­çº§ç»Ÿè®¡")
    
    from ..database import DatabaseManager
    
    db = DatabaseManager()
    
    # ç­çº§æŸ¥è¯¢
    class_name = st.text_input("è¾“å…¥ç­çº§åç§°")
    
    if class_name:
        stats = db.get_class_statistics(class_name)
        
        if stats['student_count'] > 0:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("å­¦ç”Ÿäººæ•°", stats['student_count'])
            
            with col2:
                st.metric("æ‰¹æ”¹ä»»åŠ¡æ•°", stats['total_tasks'])
            
            with col3:
                st.metric("å¹³å‡åˆ†", f"{stats['average_score']:.1f}%")
            
            with col4:
                st.metric("ç­çº§", class_name)
        else:
            st.info("æš‚æ— æ•°æ®")

