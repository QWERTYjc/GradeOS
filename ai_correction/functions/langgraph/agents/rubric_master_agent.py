#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RubricMasterAgent - è¯„åˆ†æ ‡å‡†ä¸»æ§Agent
èŒè´£ï¼šæ·±åº¦ç†è§£è¯„åˆ†æ ‡å‡†ï¼Œä¸ºæ¯ä¸ªæ‰¹æ¬¡ç”Ÿæˆå®šåˆ¶åŒ–ç†è§£
æ ¸å¿ƒä»·å€¼ï¼šä¸€æ¬¡æ€§æ·±åº¦ç†è§£ï¼Œä¸ºå¤šä¸ªæ‰¹æ”¹Agentæä¾›å‹ç¼©ç‰ˆæŒ‡å¯¼ï¼Œå¤§å¹…å‡å°‘tokenæ¶ˆè€—
"""

import logging
import json
from typing import Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class RubricMasterAgent:
    """è¯„åˆ†æ ‡å‡†ä¸»æ§Agent"""
    
    def __init__(self):
        self.agent_name = "RubricMasterAgent"
    
    async def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè¯„åˆ†æ ‡å‡†æ·±åº¦ç†è§£"""
        logger.info(f"ğŸ“ [{self.agent_name}] å¼€å§‹æ·±åº¦ç†è§£è¯„åˆ†æ ‡å‡†...")
        
        try:
            # è·å–è¯„åˆ†æ ‡å‡†ç†è§£ç»“æœï¼ˆç”±RubricInterpreterAgentæä¾›ï¼‰
            rubric_understanding = state.get('rubric_understanding')
            
            if not rubric_understanding:
                logger.warning("æœªæ‰¾åˆ°è¯„åˆ†æ ‡å‡†ç†è§£ç»“æœï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†")
                rubric_understanding = {
                    'criteria': [],
                    'total_score': 100.0,
                    'summary': 'é»˜è®¤è¯„åˆ†æ ‡å‡†'
                }
            
            batches_info = state.get('batches_info', [])
            
            if not batches_info:
                logger.warning("æœªæ‰¾åˆ°æ‰¹æ¬¡ä¿¡æ¯ï¼Œåˆ›å»ºé»˜è®¤æ‰¹æ¬¡")
                batches_info = [{'batch_id': 'default_batch', 'question_ids': []}]
            
            batch_rubric_packages = {}
            
            for batch in batches_info:
                batch_id = batch.get('batch_id', 'default_batch')
                
                # ?????????
                rubric_package = self._generate_batch_rubric_package(
                    batch_id,
                    rubric_understanding,
                    batch
                )
                
                batch_rubric_packages[batch_id] = rubric_package
            
            logger.info(f"   ? {len(batches_info)} ????????")
            logger.info(f"[{self.agent_name}] ????????")

            
            # åªè¿”å›éœ€è¦æ›´æ–°çš„å­—æ®µï¼Œé¿å…å¹¶å‘æ›´æ–°å†²çª
            # æ³¨æ„ï¼šä¸è¿”å›progress_percentageå’Œcurrent_stepï¼Œå› ä¸ºå¹¶è¡ŒèŠ‚ç‚¹ä¼šå†²çª
            return {
                'batch_rubric_packages': batch_rubric_packages
            }
            
        except Exception as e:
            error_msg = f"[{self.agent_name}] æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            return {
                'errors': [{
                    'agent': self.agent_name,
                    'error': error_msg,
                    'timestamp': str(datetime.now())
                }],
                'batch_rubric_packages': {}
            }
    
    def _generate_batch_rubric_package(
        self,
        batch_id: str,
        rubric_understanding: Dict[str, Any],
        batch_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä¸ºæ‰¹æ¬¡ç”Ÿæˆå‹ç¼©ç‰ˆè¯„åˆ†åŒ…
        
        Tokenä¼˜åŒ–ç­–ç•¥ï¼š
        - æå–å†³ç­–æ ‘è€Œéå®Œæ•´æè¿°
        - ä½¿ç”¨ç®€å†™ä»£æ›¿å®Œæ•´æœ¯è¯­
        - æä¾›å¿«é€Ÿæ£€æŸ¥æ–¹æ³•
        
        å¦‚æœæ‰¹æ¬¡æœ‰question_idsï¼ŒåªåŒ…å«è¿™äº›é¢˜ç›®çš„è¯„åˆ†ç‚¹
        """
        all_criteria = rubric_understanding.get('criteria', [])
        if not all_criteria:
            logger.warning("è¯„åˆ†æ ‡å‡†ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†ç‚¹ç¡®ä¿æµç¨‹å¯ç»§ç»­")
            all_criteria = [{
                'criterion_id': 'C1',
                'question_id': 'UNKNOWN',
                'description': rubric_understanding.get('summary', 'é»˜è®¤è¯„åˆ†ç‚¹'),
                'points': rubric_understanding.get('total_score', 100.0) or 100.0,
                'evaluation_method': 'semantic'
            }]
        
        # å¦‚æœæ‰¹æ¬¡æŒ‡å®šäº†question_idsï¼ŒåªåŒ…å«è¿™äº›é¢˜ç›®çš„è¯„åˆ†ç‚¹
        question_ids = batch_info.get('question_ids', [])
        if question_ids:
            # è¿‡æ»¤å‡ºå±äºè¿™äº›é¢˜ç›®çš„è¯„åˆ†ç‚¹
            criteria = []
            for criterion in all_criteria:
                criterion_question_id = criterion.get('question_id', '')
                if not criterion_question_id:
                    # å¦‚æœæ²¡æœ‰question_idï¼Œå°è¯•ä»criterion_idæå–
                    criterion_id = criterion.get('criterion_id', '')
                    if '_' in criterion_id:
                        criterion_question_id = criterion_id.split('_')[0]
                    else:
                        # ä¿ç•™æœªçŸ¥é¢˜ç›®ï¼Œé¿å…ç›´æ¥ä¸¢å¼ƒè¯„åˆ†ç‚¹
                        criterion_question_id = 'UNKNOWN'
                
                if criterion_question_id in question_ids:
                    criteria.append(criterion)
            
            logger.info(f"æ‰¹æ¬¡ {batch_id}: ä» {len(all_criteria)} ä¸ªè¯„åˆ†ç‚¹ä¸­ç­›é€‰å‡º {len(criteria)} ä¸ªï¼ˆé¢˜ç›®: {question_ids}ï¼‰")
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šquestion_idsï¼ŒåŒ…å«æ‰€æœ‰è¯„åˆ†ç‚¹
            criteria = all_criteria
        
        # æ£€æŸ¥æ˜¯å¦åªæœ‰é»˜è®¤è¯„åˆ†ç‚¹
        if len(criteria) == 1 and criteria[0].get('points', 0) == 100.0:
            logger.warning(f"æ£€æµ‹åˆ°é»˜è®¤è¯„åˆ†æ ‡å‡†ï¼ˆåªæœ‰1ä¸ªè¯„åˆ†ç‚¹ï¼‰ï¼Œæ‰¹æ”¹æ ‡å‡†è§£æå¯èƒ½å¤±è´¥")
            logger.warning(f"   è¯„åˆ†ç‚¹ID: {criteria[0].get('criterion_id', 'N/A')}")
            logger.warning(f"   æè¿°: {criteria[0].get('description', 'N/A')[:100]}")
        
        compressed_criteria = []
        decision_trees = {}
        quick_checks = {}
        
        logger.info(f"ä¸ºæ‰¹æ¬¡ {batch_id} ç”Ÿæˆè¯„åˆ†åŒ…ï¼Œå…± {len(criteria)} ä¸ªè¯„åˆ†ç‚¹")
        
        for criterion in criteria:
            if not criterion or not isinstance(criterion, dict):
                continue
                
            cid = criterion.get('criterion_id', '')
            
            # å‹ç¼©ç‰ˆè¯„åˆ†ç‚¹
            description = criterion.get('description', '')
            compressed = {
                'id': cid,
                'desc': description[:50] if description else '',  # æˆªæ–­æè¿°
                'pts': criterion.get('points', 0),
                'method': criterion.get('evaluation_method', 'semantic')
            }
            compressed_criteria.append(compressed)
            
            # ç”Ÿæˆå†³ç­–æ ‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
            keywords_list = criterion.get('keywords', []) or []
            required_elements = criterion.get('required_elements', []) or []
            decision_trees[cid] = {
                'keywords': keywords_list[:5],  # é™åˆ¶å…³é”®è¯æ•°é‡
                'required': required_elements[:3]
            }
            
            # å¿«é€Ÿæ£€æŸ¥æ–¹æ³•
            if keywords_list:
                quick_checks[cid] = f"æŸ¥æ‰¾å…³é”®è¯: {', '.join(keywords_list[:3])}"
            else:
                quick_checks[cid] = "æ£€æŸ¥æè¿°å†…å®¹"
        
        logger.info(f"   ç”Ÿæˆäº† {len(compressed_criteria)} ä¸ªå‹ç¼©è¯„åˆ†ç‚¹")
        
        return {
            'batch_id': batch_id,
            'compressed_criteria': compressed_criteria,
            'decision_trees': decision_trees,
            'quick_checks': quick_checks,
            'total_points': rubric_understanding.get('total_points', 100)
        }
