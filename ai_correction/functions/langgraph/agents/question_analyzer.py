#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QuestionAnalyzer Agent - åˆ†æé¢˜ç›®ç‰¹å¾ï¼Œè¯†åˆ«é¢˜å‹ã€éš¾åº¦ã€æ‰¹æ”¹ç­–ç•¥
"""

import sys
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from functions.llm_client import get_llm_client


class QuestionAnalyzerAgent:
    """é¢˜ç›®åˆ†æ Agent"""
    
    # é¢˜å‹é…ç½®
    QUESTION_TYPES = {
        'choice': {
            'features': ['é€‰é¡¹', 'A.', 'B.', 'C.', 'D.'],
            'strategy': 'keyword_match',
            'expected_answer_length': 'short',
            'base_difficulty': 1
        },
        'fill': {
            'features': ['___', 'ç©ºç™½', 'å¡«ç©º'],
            'strategy': 'semantic',
            'expected_answer_length': 'short',
            'base_difficulty': 2
        },
        'essay': {
            'features': ['è®ºè¿°', 'åˆ†æ', 'è¯´æ˜', 'æè¿°', 'ç®€ç­”'],
            'strategy': 'rubric',
            'expected_answer_length': 'long',
            'base_difficulty': 4
        },
        'calculation': {
            'features': ['è®¡ç®—', 'æ±‚', 'è§£', 'è¯æ˜'],
            'strategy': 'step_by_step',
            'expected_answer_length': 'medium',
            'base_difficulty': 3
        }
    }
    
    def __init__(self):
        pass
    
    def analyze(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æé¢˜ç›®ç‰¹å¾
        
        Args:
            state: åŒ…å« questions çš„çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€ï¼Œquestions ä¸­æ·»åŠ  analysis å­—æ®µ
        """
        try:
            questions = state.get('questions', [])
            
            for question in questions:
                # åˆ†æé¢˜å‹
                q_type = question.get('type', 'unknown')
                
                # è¯„ä¼°éš¾åº¦
                difficulty = self._estimate_difficulty(question)
                
                # ç¡®å®šæ‰¹æ”¹ç­–ç•¥
                strategy = self._determine_strategy(q_type, difficulty)
                
                # æå–å…³é”®è¯
                keywords = self._extract_keywords(question['text'])
                
                # æ·»åŠ åˆ†æç»“æœ
                question['analysis'] = {
                    'difficulty': difficulty,
                    'strategy': strategy,
                    'keywords': keywords,
                    'expected_answer_length': self.QUESTION_TYPES.get(q_type, {}).get('expected_answer_length', 'medium')
                }
            
            state.update({
                'questions': questions,
                'analysis_status': 'success'
            })
            
            return state
            
        except Exception as e:
            state.update({
                'analysis_status': 'failed',
                'analysis_errors': [str(e)]
            })
            return state
    
    def _estimate_difficulty(self, question: Dict) -> str:
        """
        è¯„ä¼°é¢˜ç›®éš¾åº¦
        
        å› ç´ ï¼š
        1. é¢˜ç›®é•¿åº¦ï¼ˆé•¿ = éš¾ï¼‰
        2. å…³é”®è¯å¤æ‚åº¦
        3. é¢˜å‹åŸºç¡€éš¾åº¦
        """
        q_type = question.get('type', 'unknown')
        text = question.get('text', '')
        
        # åŸºç¡€éš¾åº¦
        base_difficulty = self.QUESTION_TYPES.get(q_type, {}).get('base_difficulty', 2)
        
        # é•¿åº¦å› ç´ 
        length_factor = 0
        if len(text) > 200:
            length_factor = 2
        elif len(text) > 100:
            length_factor = 1
        
        # å¤æ‚è¯æ±‡å› ç´ 
        complex_keywords = ['ç»¼åˆ', 'åˆ†æ', 'è¯„ä»·', 'è®ºè¯', 'æ¨å¯¼', 'è¯æ˜']
        complexity_factor = sum(1 for kw in complex_keywords if kw in text)
        
        # è®¡ç®—æ€»éš¾åº¦
        total_difficulty = base_difficulty + length_factor + complexity_factor
        
        # æ˜ å°„åˆ°éš¾åº¦ç­‰çº§
        if total_difficulty <= 2:
            return 'easy'
        elif total_difficulty <= 4:
            return 'medium'
        else:
            return 'hard'
    
    def _determine_strategy(self, q_type: str, difficulty: str) -> str:
        """
        ç¡®å®šæ‰¹æ”¹ç­–ç•¥
        
        ç­–ç•¥ï¼š
        - keyword_match: å…³é”®è¯åŒ¹é…ï¼ˆé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ï¼‰
        - semantic: è¯­ä¹‰ç†è§£ï¼ˆå¡«ç©ºé¢˜ã€ç®€ç­”é¢˜ï¼‰
        - rubric: è¯„åˆ†æ ‡å‡†ï¼ˆè§£ç­”é¢˜ã€è®ºè¿°é¢˜ï¼‰
        - step_by_step: æ­¥éª¤åˆ†æï¼ˆè®¡ç®—é¢˜ã€è¯æ˜é¢˜ï¼‰
        """
        base_strategy = self.QUESTION_TYPES.get(q_type, {}).get('strategy', 'semantic')
        
        # æ ¹æ®éš¾åº¦è°ƒæ•´ç­–ç•¥
        if difficulty == 'hard' and base_strategy == 'keyword_match':
            return 'semantic'  # éš¾é¢˜ä½¿ç”¨è¯­ä¹‰ç†è§£
        
        return base_strategy
    
    def _extract_keywords(self, text: str) -> List[str]:
        """
        æå–å…³é”®è¯
        
        ç®€å•å®ç°ï¼šæå–åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯
        """
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„è§„åˆ™ï¼Œå®é™…å¯ä»¥ä½¿ç”¨ NLP åº“
        keywords = []
        
        # å¸¸è§å…³é”®è¯æ¨¡å¼
        important_words = [
            'è®¡ç®—', 'æ±‚', 'è§£', 'è¯æ˜', 'åˆ†æ', 'è¯´æ˜', 'æè¿°', 'è®ºè¿°',
            'æ¯”è¾ƒ', 'è¯„ä»·', 'æ€»ç»“', 'å½’çº³', 'æ¨å¯¼', 'åˆ¤æ–­', 'é€‰æ‹©'
        ]
        
        for word in important_words:
            if word in text:
                keywords.append(word)
        
        return keywords[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®è¯


class QuestionGraderAgent:
    """é¢˜ç›®æ‰¹æ”¹ Agent - é€é¢˜æ‰¹æ”¹"""
    
    def __init__(self, llm_client=None):
        """
        Args:
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆGemini/GPT/OpenRouterï¼‰
        """
        try:
            self.llm_client = llm_client or get_llm_client()
            print(f"ğŸ¯ QuestionGrader åˆå§‹åŒ–: LLM={self.llm_client.provider}")
        except Exception as e:
            print(f"âš ï¸ LLM åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•ç­–ç•¥: {e}")
            self.llm_client = None
    
    def grade(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        é€é¢˜æ‰¹æ”¹
        
        Args:
            state: åŒ…å« questions, answers, marking_scheme çš„çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€ï¼Œæ·»åŠ  grading_results
        """
        try:
            answers = state.get('answers', [])
            marking_scheme = state.get('marking_scheme', {})
            
            grading_results = []
            
            for answer in answers:
                question = answer.get('question', {})
                analysis = question.get('analysis', {})
                strategy = analysis.get('strategy', 'semantic')
                
                # æ ¹æ®ç­–ç•¥æ‰¹æ”¹
                if strategy == 'keyword_match':
                    result = self._grade_by_keywords(question, answer, marking_scheme)
                elif strategy == 'semantic':
                    result = self._grade_by_semantic(question, answer, marking_scheme)
                elif strategy == 'rubric':
                    result = self._grade_by_rubric(question, answer, marking_scheme)
                elif strategy == 'step_by_step':
                    result = self._grade_by_steps(question, answer, marking_scheme)
                else:
                    result = self._grade_by_semantic(question, answer, marking_scheme)
                
                grading_results.append(result)
            
            state.update({
                'grading_results': grading_results,
                'grading_status': 'success'
            })
            
            return state
            
        except Exception as e:
            state.update({
                'grading_status': 'failed',
                'grading_errors': [str(e)]
            })
            return state
    
    def _grade_by_keywords(self, question: Dict, answer: Dict, marking_scheme: Dict) -> Dict:
        """å…³é”®è¯åŒ¹é…æ‰¹æ”¹"""
        keywords = question.get('analysis', {}).get('keywords', [])
        answer_text = answer.get('text', '')
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
        matched_keywords = [kw for kw in keywords if kw in answer_text]
        match_rate = len(matched_keywords) / len(keywords) if keywords else 0
        
        # ç®€å•è¯„åˆ†
        score = int(match_rate * 10)
        
        return {
            'question_id': question['id'],
            'student_id': answer.get('student_id'),
            'score': score,
            'max_score': 10,
            'matched_keywords': matched_keywords,
            'feedback': f"å…³é”®è¯åŒ¹é…åº¦: {match_rate*100:.1f}%",
            'strategy': 'keyword_match'
        }
    
    def _grade_by_semantic(self, question: Dict, answer: Dict, marking_scheme: Dict) -> Dict:
        """è¯­ä¹‰ç†è§£æ‰¹æ”¹ï¼ˆéœ€è¦ LLMï¼‰"""
        if not self.llm_client:
            print("âš ï¸ æ—  LLMï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…")
            return self._grade_by_keywords(question, answer, marking_scheme)

        try:
            # ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰åˆ†æ
            prompt = f"""è¯·æ‰¹æ”¹ä»¥ä¸‹ç­”æ¡ˆï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼š

é¢˜ç›®ï¼š{question.get('text', '')}
å­¦ç”Ÿç­”æ¡ˆï¼š{answer.get('text', '')}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
    "score": å¾—åˆ†ï¼ˆ0-10åˆ†çš„æ•´æ•°ï¼‰,
    "feedback": "è¯¦ç»†åé¦ˆ",
    "errors": ["é”™è¯¯ç‚¹1", "é”™è¯¯ç‚¹2"],
    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"]
}}
"""

            print(f"ğŸ“¡ è°ƒç”¨ LLM æ‰¹æ”¹é¢˜ç›® {question.get('id')}")

            messages = [{"role": "user", "content": prompt}]
            response = self.llm_client.chat(messages, temperature=0.3)

            # è§£æ LLM å“åº”
            import json
            import re

            # æå– JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result_data = json.loads(json_match.group())
                score = result_data.get('score', 7)
                feedback = result_data.get('feedback', 'ç­”æ¡ˆåŸºæœ¬æ­£ç¡®')
                errors = result_data.get('errors', [])
                suggestions = result_data.get('suggestions', [])
            else:
                # å¦‚æœæ— æ³•è§£æ JSONï¼Œä½¿ç”¨é»˜è®¤å€¼
                score = 7
                feedback = response[:200]  # å–å‰200å­—ç¬¦
                errors = []
                suggestions = []

            print(f"âœ… LLM æ‰¹æ”¹å®Œæˆ: å¾—åˆ†={score}/10")

            return {
                'question_id': question['id'],
                'student_id': answer.get('student_id'),
                'score': score,
                'max_score': 10,
                'feedback': feedback,
                'errors': errors,
                'suggestions': suggestions,
                'strategy': 'semantic'
            }

        except Exception as e:
            print(f"âŒ LLM æ‰¹æ”¹å¤±è´¥: {e}ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…")
            return self._grade_by_keywords(question, answer, marking_scheme)
    
    def _grade_by_rubric(self, question: Dict, answer: Dict, marking_scheme: Dict) -> Dict:
        """è¯„åˆ†æ ‡å‡†æ‰¹æ”¹"""
        criteria = marking_scheme.get('criteria', [])
        
        # ä½¿ç”¨ LLM æ ¹æ®è¯„åˆ†æ ‡å‡†æ‰¹æ”¹
        return self._grade_by_semantic(question, answer, marking_scheme)
    
    def _grade_by_steps(self, question: Dict, answer: Dict, marking_scheme: Dict) -> Dict:
        """æ­¥éª¤åˆ†ææ‰¹æ”¹"""
        # åˆ†æç­”æ¡ˆæ­¥éª¤
        return self._grade_by_semantic(question, answer, marking_scheme)

