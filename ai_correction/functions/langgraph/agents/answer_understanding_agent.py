#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AnswerUnderstandingAgent - ç­”æ¡ˆç†è§£Agent
æ”¯æŒæ–‡æœ¬å’ŒVisionä¸¤ç§æ¨¡æ€
"""

import logging
import json
from typing import Dict, Any
from datetime import datetime

from ..state import GradingState
from ..multimodal_models import AnswerUnderstanding
from ..prompts.multimodal_prompts import format_answer_understanding_prompt
from ...llm_client import get_llm_client

logger = logging.getLogger(__name__)


class AnswerUnderstandingAgent:
    """ç­”æ¡ˆç†è§£Agent - æ”¯æŒå¤šæ¨¡æ€è¾“å…¥"""
    
    def __init__(self):
        self.name = "AnswerUnderstandingAgent"
        self.llm_client = get_llm_client()
    
    async def __call__(self, state: GradingState) -> GradingState:
        """æ‰§è¡Œç­”æ¡ˆç†è§£"""
        logger.info(f"ğŸ”„ {self.name} å¼€å§‹å¤„ç†...")
        
        try:
            state['current_step'] = "ç­”æ¡ˆç†è§£"
            state['progress_percentage'] = 35.0
            
            # è·å–å¤šæ¨¡æ€ç­”æ¡ˆæ–‡ä»¶
            answer_files = state.get('answer_multimodal_files', [])
            if not answer_files:
                logger.warning("æ²¡æœ‰ç­”æ¡ˆæ–‡ä»¶")
                return state
            
            # å¤„ç†ç¬¬ä¸€ä¸ªç­”æ¡ˆæ–‡ä»¶
            answer_file = answer_files[0]
            modality_type = answer_file['modality_type']
            content = answer_file['content_representation']
            
            logger.info(f"å¤„ç†ç­”æ¡ˆæ–‡ä»¶ï¼Œæ¨¡æ€ç±»å‹: {modality_type}")
            
            # æ ¹æ®æ¨¡æ€ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
            if modality_type == 'text':
                understanding = await self._understand_text_answer(content['text'])
            elif modality_type == 'image':
                understanding = await self._understand_image_answer(content)
            elif modality_type == 'pdf_text':
                understanding = await self._understand_text_answer(content['text'])
            elif modality_type == 'pdf_image':
                if content['pages']:
                    understanding = await self._understand_image_answer(content['pages'][0])
                else:
                    understanding = self._default_understanding()
            else:
                understanding = self._default_understanding()
            
            # æ›´æ–°çŠ¶æ€
            state['answer_understanding'] = understanding
            state['progress_percentage'] = 40.0
            
            logger.info(f"âœ… {self.name} å¤„ç†å®Œæˆ")
            return state
            
        except Exception as e:
            logger.error(f"{self.name} å¤±è´¥: {e}")
            state['errors'].append({
                'step': 'answer_understanding',
                'error': str(e),
                'timestamp': str(datetime.now())
            })
            return state
    
    async def _understand_text_answer(self, answer_text: str) -> AnswerUnderstanding:
        """ç†è§£æ–‡æœ¬ç­”æ¡ˆ"""
        prompt = format_answer_understanding_prompt(answer_text, is_vision=False)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±æ•™è‚²ä¸“å®¶ï¼Œæ“…é•¿ç†è§£å’Œåˆ†æå­¦ç”Ÿç­”æ¡ˆã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = self.llm_client.chat(messages, temperature=0.3, max_tokens=2000)
            return self._parse_understanding(response, answer_text, "text")
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._create_simple_understanding(answer_text, "text")
    
    async def _understand_image_answer(self, image_content: Dict[str, Any]) -> AnswerUnderstanding:
        """ç†è§£å›¾ç‰‡ç­”æ¡ˆï¼ˆä½¿ç”¨Vision APIï¼‰"""
        prompt = format_answer_understanding_prompt("", is_vision=True)
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{image_content['mime_type']};base64,{image_content['base64_data']}"
                        }
                    }
                ]
            }
        ]
        
        try:
            response = self.llm_client.chat(messages, temperature=0.3, max_tokens=2000)
            return self._parse_understanding(response, "", "vision")
        except Exception as e:
            logger.error(f"Vision APIè°ƒç”¨å¤±è´¥: {e}")
            return self._default_understanding()
    
    def _parse_understanding(self, response: str, answer_text: str, modality: str) -> AnswerUnderstanding:
        """è§£æLLMå“åº”"""
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                result = json.loads(response[json_start:json_end])
                return AnswerUnderstanding(
                    answer_id=result.get('answer_id', 'A1'),
                    answer_text=result.get('answer_text', answer_text),
                    key_points=result.get('key_points', []),
                    structure=result.get('structure', {}),
                    completeness=result.get('completeness'),
                    modality_source=modality
                )
        except:
            pass
        return self._create_simple_understanding(answer_text, modality)
    
    def _create_simple_understanding(self, answer_text: str, modality: str) -> AnswerUnderstanding:
        """åˆ›å»ºç®€å•çš„ç†è§£ç»“æœ"""
        return AnswerUnderstanding(
            answer_id='A1',
            answer_text=answer_text,
            key_points=[],
            structure={},
            modality_source=modality
        )
    
    def _default_understanding(self) -> AnswerUnderstanding:
        """é»˜è®¤ç†è§£ç»“æœ"""
        return self._create_simple_understanding("", "unknown")
