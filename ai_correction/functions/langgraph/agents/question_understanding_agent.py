#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QuestionUnderstandingAgent - é¢˜ç›®ç†è§£Agent
æ”¯æŒæ–‡æœ¬å’ŒVisionä¸¤ç§æ¨¡æ€
"""

import logging
import json
import os
from typing import Dict, Any
from datetime import datetime

from ..state import GradingState
from ..multimodal_models import QuestionUnderstanding
from ..prompts.multimodal_prompts import format_question_understanding_prompt
from ...llm_client import get_llm_client, LLMClient

logger = logging.getLogger(__name__)


class QuestionUnderstandingAgent:
    """é¢˜ç›®ç†è§£Agent - æ”¯æŒå¤šæ¨¡æ€è¾“å…¥"""

    def __init__(self):
        self.name = "QuestionUnderstandingAgent"
        # ä½¿ç”¨ Gemini åŸç”Ÿ API
        self.llm_client = LLMClient(
            provider='gemini',
            model='gemini-2.0-flash-exp'
        )
    
    async def __call__(self, state: GradingState) -> GradingState:
        """æ‰§è¡Œé¢˜ç›®ç†è§£"""
        logger.info(f"{self.name} å¼€å§‹å¤„ç†...")
        
        try:
            state['current_step'] = "é¢˜ç›®ç†è§£"
            state['progress_percentage'] = 25.0
            
            # è·å–å¤šæ¨¡æ€é¢˜ç›®æ–‡ä»¶
            question_files = state.get('question_multimodal_files', [])
            if not question_files:
                logger.warning("æ²¡æœ‰é¢˜ç›®æ–‡ä»¶")
                return state
            
            # å¤„ç†ç¬¬ä¸€ä¸ªé¢˜ç›®æ–‡ä»¶ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            question_file = question_files[0]
            modality_type = question_file['modality_type']
            content = question_file['content_representation']
            
            logger.info(f"å¤„ç†é¢˜ç›®æ–‡ä»¶ï¼Œæ¨¡æ€ç±»å‹: {modality_type}")
            
            # æ ¹æ®æ¨¡æ€ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
            # PDFç°åœ¨ç›´æ¥ä½¿ç”¨Vision APIå¤„ç†ï¼Œä¸æå–æ–‡æœ¬
            if modality_type == 'text':
                understanding = await self._understand_text_question(content['text'])
            elif modality_type == 'image':
                understanding = await self._understand_image_question(content)
            elif modality_type == 'pdf':
                understanding = await self._understand_pdf_question(question_file.get('file_path') or content.get('file_path'))
            elif modality_type == 'pdf_text':
                # PDFæ–‡æœ¬æ ¼å¼ï¼ˆå·²åºŸå¼ƒï¼Œç°åœ¨PDFéƒ½ä½¿ç”¨Vision APIï¼‰
                understanding = await self._understand_text_question(content['text'])
            elif modality_type == 'pdf_image':
                # PDFå›¾ç‰‡æ ¼å¼ï¼šä½¿ç”¨Vision APIå¤„ç†ç¬¬ä¸€é¡µ
                if content.get('pages'):
                    understanding = await self._understand_image_question(content['pages'][0])
                else:
                    understanding = self._default_understanding()
            else:
                understanding = self._default_understanding()
            
            # åªè¿”å›éœ€è¦æ›´æ–°çš„å­—æ®µï¼Œé¿å…å¹¶å‘æ›´æ–°å†²çª
            # æ³¨æ„ï¼šä¸è¿”å›progress_percentageå’Œcurrent_stepï¼Œå› ä¸ºå¹¶è¡ŒèŠ‚ç‚¹ä¼šå†²çª
            logger.info(f"{self.name} å¤„ç†å®Œæˆ")
            return {
                'question_understanding': understanding
            }
            
        except Exception as e:
            logger.error(f"{self.name} å¤±è´¥: {e}")
            return {
                'errors': [{
                    'step': 'question_understanding',
                    'error': str(e),
                    'timestamp': str(datetime.now())
                }],
                'question_understanding': self._default_understanding()
            }
    
    async def _understand_text_question(self, question_text: str) -> QuestionUnderstanding:
        """ç†è§£æ–‡æœ¬é¢˜ç›®"""
        prompt = format_question_understanding_prompt(question_text, is_vision=False)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±æ•™è‚²ä¸“å®¶ï¼Œæ“…é•¿ç†è§£å’Œåˆ†æé¢˜ç›®ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = self.llm_client.chat(messages, temperature=0.3, max_tokens=2000)
            return self._parse_understanding(response, question_text, "text")
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._create_simple_understanding(question_text, "text")
    
    async def _understand_image_question(self, image_content: Dict[str, Any]) -> QuestionUnderstanding:
        """ç†è§£å›¾ç‰‡é¢˜ç›®ï¼ˆä½¿ç”¨ Gemini åŸç”Ÿå¤šæ¨¡æ€ APIï¼‰"""
        # è·å–æ–‡ä»¶è·¯å¾„
        file_path = image_content.get('file_path')
        if not file_path:
            logger.warning("å›¾ç‰‡é¢˜ç›®ç¼ºå°‘æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤ç†è§£")
            return self._default_understanding()
        
        logger.info(f"ğŸ–¼ï¸  ä½¿ç”¨ Gemini è§£æå›¾ç‰‡é¢˜ç›®: {file_path}")
        prompt = format_question_understanding_prompt("", is_vision=True)
        messages = [{"role": "user", "content": prompt}]
        
        try:
            response = self.llm_client.chat(
                messages,
                temperature=0.3,
                max_tokens=2000,
                files=[file_path],  # ç›´æ¥ä¼ æ–‡ä»¶è·¯å¾„
                thinking_level="medium",
                timeout=self._get_llm_timeout()
            )
            return self._parse_understanding(response, "", "vision_image")
        except Exception as e:
            logger.error(f"âŒ Gemini è§£æå›¾ç‰‡é¢˜ç›®å¤±è´¥: {e}")
            return self._default_understanding()
    
    async def _understand_pdf_question(self, pdf_path: str | None) -> QuestionUnderstanding:
        """ä½¿ç”¨ Gemini åŸç”Ÿå¤šæ¨¡æ€ç†è§£ PDF é¢˜ç›®"""
        if not pdf_path:
            logger.warning("PDF é¢˜ç›®ç¼ºå°‘æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤ç†è§£")
            return self._default_understanding()
        
        logger.info(f"ğŸ“„ ä½¿ç”¨ Gemini è§£æ PDF é¢˜ç›®: {pdf_path}")
        prompt = format_question_understanding_prompt("", is_vision=True)
        messages = [{"role": "user", "content": prompt}]
        
        try:
            response = self.llm_client.chat(
                messages,
                temperature=0.2,
                max_tokens=2000,
                files=[pdf_path],
                thinking_level="high",
                timeout=self._get_llm_timeout()
            )
            return self._parse_understanding(response, "", "vision_pdf")
        except Exception as e:
            logger.error(f"Gemini è§£æ PDF é¢˜ç›®å¤±è´¥: {e}")
            return self._default_understanding()

    def _parse_understanding(self, response: str, question_text: str, modality: str) -> QuestionUnderstanding:
        """è§£æLLMå“åº”"""
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                result = json.loads(response[json_start:json_end])
                return QuestionUnderstanding(
                    question_id=result.get('question_id', 'Q1'),
                    question_text=result.get('question_text', question_text),
                    key_requirements=result.get('key_requirements', []),
                    context=result.get('context', {}),
                    difficulty_level=result.get('context', {}).get('difficulty_level'),
                    subject=result.get('context', {}).get('subject'),
                    modality_source=modality
                )
        except:
            pass
        return self._create_simple_understanding(question_text, modality)
    
    def _create_simple_understanding(self, question_text: str, modality: str) -> QuestionUnderstanding:
        """åˆ›å»ºç®€å•çš„ç†è§£ç»“æœ"""
        return QuestionUnderstanding(
            question_id='Q1',
            question_text=question_text,
            key_requirements=[],
            context={},
            modality_source=modality
        )
    
    def _get_llm_timeout(self) -> int:
        """è·å–LLMè¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰"""
        try:
            return int(os.getenv("QUESTION_LLM_TIMEOUT", os.getenv("LLM_REQUEST_TIMEOUT", "90")))
        except Exception:
            return 90
    
    def _default_understanding(self) -> QuestionUnderstanding:
        """é»˜è®¤ç†è§£ç»“æœ"""
        return self._create_simple_understanding("", "unknown")
