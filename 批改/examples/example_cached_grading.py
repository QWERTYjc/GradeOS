"""
Gemini Context Caching ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç¼“å­˜æ‰¹æ”¹æœåŠ¡æ¥èŠ‚çœ Token æˆæœ¬
"""

import asyncio
from pathlib import Path
from typing import List

import fitz
from PIL import Image
from io import BytesIO

from src.services.rubric_parser import RubricParserService
from src.services.cached_grading import CachedGradingService
from src.services.student_identification import StudentIdentificationService


# é…ç½®
API_KEY = "YOUR_API_KEY_HERE"  # æ›¿æ¢ä¸ºä½ çš„ API Key
RUBRIC_PDF = "æ‰¹æ”¹æ ‡å‡†.pdf"
ANSWER_PDF = "å­¦ç”Ÿä½œç­”.pdf"


def pdf_to_images(pdf_path: str) -> List[bytes]:
    """å°† PDF è½¬æ¢ä¸ºå›¾åƒåˆ—è¡¨"""
    doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        img_bytes = BytesIO()
        img.save(img_bytes, format='PNG')
        images.append(img_bytes.getvalue())
    
    return images


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 70)
    print("Gemini Context Caching æ‰¹æ”¹ç¤ºä¾‹")
    print("=" * 70)
    
    # ç¬¬ä¸€æ­¥ï¼šåŠ è½½ PDF
    print("\nğŸ“„ åŠ è½½ PDF æ–‡ä»¶...")
    rubric_images = pdf_to_images(RUBRIC_PDF)
    answer_images = pdf_to_images(ANSWER_PDF)
    print(f"   æ‰¹æ”¹æ ‡å‡†: {len(rubric_images)} é¡µ")
    print(f"   å­¦ç”Ÿä½œç­”: {len(answer_images)} é¡µ")
    
    # ç¬¬äºŒæ­¥ï¼šè§£æè¯„åˆ†æ ‡å‡†
    print("\nğŸ“‹ è§£æè¯„åˆ†æ ‡å‡†...")
    rubric_parser = RubricParserService(api_key=API_KEY)
    parsed_rubric = await rubric_parser.parse_rubric(
        rubric_images=rubric_images,
        expected_total_score=105
    )
    rubric_context = rubric_parser.format_rubric_context(parsed_rubric)
    print(f"   âœ… è§£æå®Œæˆ: {parsed_rubric.total_questions} é¢˜, æ€»åˆ† {parsed_rubric.total_score}")
    
    # ç¬¬ä¸‰æ­¥ï¼šè¯†åˆ«å­¦ç”Ÿ
    print("\nğŸ‘¥ è¯†åˆ«å­¦ç”Ÿ...")
    student_service = StudentIdentificationService(api_key=API_KEY)
    students = await student_service.identify_students(
        answer_images=answer_images,
        total_questions=parsed_rubric.total_questions
    )
    print(f"   âœ… è¯†åˆ«åˆ° {len(students)} åå­¦ç”Ÿ")
    for student in students:
        print(f"      - {student.student_name}: ç¬¬ {student.start_page}-{student.end_page} é¡µ")
    
    # ç¬¬å››æ­¥ï¼šåˆ›å»ºç¼“å­˜æ‰¹æ”¹æœåŠ¡
    print("\nğŸ’¾ åˆ›å»ºç¼“å­˜æ‰¹æ”¹æœåŠ¡...")
    cached_service = CachedGradingService(
        api_key=API_KEY,
        model_name="gemini-2.5-flash",
        cache_ttl_hours=1
    )
    
    # ç¬¬äº”æ­¥ï¼šåˆ›å»ºè¯„åˆ†æ ‡å‡†ç¼“å­˜
    print("   æ­£åœ¨åˆ›å»ºè¯„åˆ†æ ‡å‡†ç¼“å­˜...")
    await cached_service.create_rubric_cache(parsed_rubric, rubric_context)
    
    cache_info = cached_service.get_cache_info()
    print(f"   âœ… ç¼“å­˜åˆ›å»ºæˆåŠŸï¼")
    print(f"      ç¼“å­˜åç§°: {cache_info['cache_name']}")
    print(f"      æœ‰æ•ˆæœŸ: {cache_info['ttl_hours']} å°æ—¶")
    print(f"      å‰©ä½™æ—¶é—´: {cache_info['remaining_hours']:.2f} å°æ—¶")
    
    # ç¬¬å…­æ­¥ï¼šæ‰¹æ”¹æ‰€æœ‰å­¦ç”Ÿï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    print("\nğŸ“ å¼€å§‹æ‰¹æ”¹ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰...")
    results = []
    
    for i, student in enumerate(students, 1):
        print(f"\n   [{i}/{len(students)}] æ‰¹æ”¹ {student.student_name}...")
        
        # æå–å­¦ç”Ÿé¡µé¢
        student_pages = answer_images[student.start_page-1:student.end_page]
        
        # ä½¿ç”¨ç¼“å­˜æ‰¹æ”¹
        result = await cached_service.grade_student_with_cache(
            student_pages=student_pages,
            student_name=student.student_name
        )
        
        results.append(result)
        
        print(f"      âœ… æ‰¹æ”¹å®Œæˆ: {result.total_score}/{result.max_total_score} åˆ†")
        print(f"         æ‰¹æ”¹é¢˜æ•°: {len(result.question_results)} é¢˜")
    
    # ç¬¬ä¸ƒæ­¥ï¼šæ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 70)
    print("æ‰¹æ”¹ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    for result in results:
        print(f"\n{result.student_name}:")
        print(f"   æ€»åˆ†: {result.total_score}/{result.max_total_score}")
        print(f"   æ‰¹æ”¹é¢˜æ•°: {len(result.question_results)}")
        
        # æ˜¾ç¤ºå‰ 3 é¢˜
        for q in result.question_results[:3]:
            print(f"   - ç¬¬ {q.question_id} é¢˜: {q.awarded_score}/{q.max_score} åˆ†")
    
    # ç¬¬å…«æ­¥ï¼šæ˜¾ç¤º Token èŠ‚çœä¿¡æ¯
    print("\n" + "=" * 70)
    print("Token èŠ‚çœåˆ†æ")
    print("=" * 70)
    
    # ä¼°ç®— Token æ¶ˆè€—
    rubric_tokens = 15000  # è¯„åˆ†æ ‡å‡†çº¦ 15,000 tokens
    per_student_tokens = 38000  # æ¯ä¸ªå­¦ç”Ÿçº¦ 38,000 tokensï¼ˆä¸å«è¯„åˆ†æ ‡å‡†ï¼‰
    
    # ä¼ ç»Ÿæ–¹å¼
    traditional_tokens = len(students) * (rubric_tokens + per_student_tokens)
    
    # ä½¿ç”¨ç¼“å­˜
    cached_tokens = rubric_tokens + len(students) * per_student_tokens
    
    # èŠ‚çœ
    saved_tokens = traditional_tokens - cached_tokens
    saved_percentage = (saved_tokens / traditional_tokens) * 100
    
    print(f"\nä¼ ç»Ÿæ–¹å¼:")
    print(f"   è¯„åˆ†æ ‡å‡†: {rubric_tokens:,} tokens Ã— {len(students)} = {rubric_tokens * len(students):,} tokens")
    print(f"   å­¦ç”Ÿä½œç­”: {per_student_tokens:,} tokens Ã— {len(students)} = {per_student_tokens * len(students):,} tokens")
    print(f"   æ€»è®¡: {traditional_tokens:,} tokens")
    
    print(f"\nä½¿ç”¨ç¼“å­˜:")
    print(f"   è¯„åˆ†æ ‡å‡†: {rubric_tokens:,} tokens Ã— 1 = {rubric_tokens:,} tokens (ç¼“å­˜)")
    print(f"   å­¦ç”Ÿä½œç­”: {per_student_tokens:,} tokens Ã— {len(students)} = {per_student_tokens * len(students):,} tokens")
    print(f"   æ€»è®¡: {cached_tokens:,} tokens")
    
    print(f"\nèŠ‚çœ:")
    print(f"   Token èŠ‚çœ: {saved_tokens:,} tokens ({saved_percentage:.1f}%)")
    print(f"   æˆæœ¬èŠ‚çœ: çº¦ ${saved_tokens * 0.000001:.2f}")
    
    # ç¬¬ä¹æ­¥ï¼šæ¸…ç†ç¼“å­˜
    print("\nğŸ—‘ï¸  æ¸…ç†ç¼“å­˜...")
    cached_service.delete_cache()
    print("   âœ… ç¼“å­˜å·²åˆ é™¤")
    
    print("\n" + "=" * 70)
    print("âœ… æ‰¹æ”¹å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(main())
